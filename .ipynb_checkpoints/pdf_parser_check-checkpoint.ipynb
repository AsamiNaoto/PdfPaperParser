{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDFパーサーの使い方 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下のサイトを参考にしました．  \n",
    "[【PDFMiner】PDFからテキストの抽出](https://qiita.com/mczkzk/items/894110558fb890c930b5)  \n",
    "[Programming with PDFMine](https://www.unixuser.org/~euske/python/pdfminer/programming.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T14:37:46.345938Z",
     "start_time": "2020-05-05T14:37:44.532878Z"
    }
   },
   "outputs": [],
   "source": [
    "from pdfminer.converter import PDFPageAggregator\n",
    "from pdfminer.layout import LAParams, LTContainer, LTTextBox\n",
    "from pdfminer.pdfinterp import PDFPageInterpreter, PDFResourceManager\n",
    "from pdfminer.pdfpage import PDFPage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T14:37:46.364742Z",
     "start_time": "2020-05-05T14:37:46.354766Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LayoutオブジェクトからLTTextBoxのリストを取得する関数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`device`オブジェクトの`get_result`メソッドが返す`layout`オブジェクトのうち，`LTTextBox`(テキストが入っている)のみ取り出し，リストにする．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T14:37:46.415607Z",
     "start_time": "2020-05-05T14:37:46.381695Z"
    }
   },
   "outputs": [],
   "source": [
    "def find_textboxes_recursively(layout):\n",
    "    \"\"\"\n",
    "    再帰的にテキストボックス（LTTextBox）を探して、テキストボックスのリストを取得する。\n",
    "    \"\"\"\n",
    "    # LTTextBoxを継承するオブジェクトの場合は1要素のリストを返す。\n",
    "    if isinstance(layout, LTTextBox):\n",
    "        text_boxes = [layout]\n",
    "        return text_boxes  # 返すのはリスト\n",
    "\n",
    "    # LTContainerを継承するオブジェクトは子要素を含むので、再帰的に探す。\n",
    "    if isinstance(layout, LTContainer):\n",
    "        text_boxes = []\n",
    "        for child in layout:\n",
    "            text_boxes.extend(find_textboxes_recursively(child))  # 再帰的にリストをextend\n",
    "            \n",
    "        return text_boxes\n",
    "\n",
    "    return []  # 何も取得できなかった場合は空リストを返す"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## パースに必要なクラスの作成 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T14:37:46.471459Z",
     "start_time": "2020-05-05T14:37:46.448516Z"
    }
   },
   "outputs": [],
   "source": [
    "# Layout Analysisのパラメーターを設定。縦書きの検出を有効にする。\n",
    "laparams = LAParams(detect_vertical=True)\n",
    "\n",
    "# 共有のリソースを管理するリソースマネージャーを作成。\n",
    "resource_manager = PDFResourceManager(caching=False)  # この引数によってエラーが出なくなる\n",
    "\n",
    "# ページを集めるPageAggregatorオブジェクトを作成。\n",
    "device = PDFPageAggregator(resource_manager, laparams=laparams)\n",
    "\n",
    "# Interpreterオブジェクトを作成。\n",
    "interpreter = PDFPageInterpreter(resource_manager, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二段組専用のソート方法 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T14:37:46.520326Z",
     "start_time": "2020-05-05T14:37:46.486416Z"
    }
   },
   "outputs": [],
   "source": [
    "class Sort2Column():\n",
    "    def __init__(self, layout_x0, layout_x1):\n",
    "        self.half_x = (layout_x0 + layout_x1)/2\n",
    "    \n",
    "    def __call__(self, text_box):\n",
    "        if text_box.x0 < self.half_x:\n",
    "            left_or_right = -1  # it mean left\n",
    "            \n",
    "        else:\n",
    "            left_or_right = 1  # it mean right\n",
    "            \n",
    "        return (left_or_right, -text_box.y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T14:37:46.609090Z",
     "start_time": "2020-05-05T14:37:46.534287Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([0,2,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ファイルを読み込み，パースを行う"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "qiitaの記事では，documentオブジェクトは必要ない`PDFPage.get_pages`メソッドを利用する．このメソッドはファイルオブジェクトを引数にとる．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T14:48:25.676555Z",
     "start_time": "2020-05-05T14:48:25.651851Z"
    }
   },
   "outputs": [],
   "source": [
    "#file_path = Path(\"./PDFs/IS1-20.pdf\")\n",
    "#file_path = Path(\"/home/umelab-server2020/workspace/paper_parse/paper_example/ロボット学会/rsj_2010.pdf\")\n",
    "#file_path = Path(\"/home/umelab-server2020/workspace/paper_parse/paper_example/SSII/ssii_2018.pdf\")\n",
    "#file_path = Path(\"/home/umelab-server2020/workspace/paper_parse/paper_example/robomech/robomech_2015.pdf\")\n",
    "#file_path = Path(\"/home/umelab-server2020/workspace/paper_parse/paper_example/MiRU/miru_2019.pdf\")\n",
    "#file_path = Path(\"/home/umelab-server2020/workspace/paper_parse/paper_example/ViEW/view_2017.pdf\")\n",
    "file_path = Path(\"/home/umelab-server2020/workspace/paper_parse/paper_example/robotics_symposia/robosym_2020.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T14:48:33.896232Z",
     "start_time": "2020-05-05T14:48:25.691516Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      "コンテキストに基づく画素レベル凹型障害物検出\n",
      "x0:148.63,x1:452.3179999999999\n",
      "y0:730.4291159999999,y1:747.1595639999999\n",
      "------------------\n",
      "∗1, 阪野 貴彦\n",
      "x0:286.52,x1:353.95100092800004\n",
      "y0:708.1077769999999,y1:730.77601\n",
      "------------------\n",
      "堀内 英一\n",
      "x0:235.13,x1:284.121000928\n",
      "y0:708.1077769999999,y1:722.302479\n",
      "------------------\n",
      "Context-based Pixel-level Negative Obstacle Detection\n",
      "x0:162.95000000000005,x1:437.98556999999994\n",
      "y0:677.1957649999999,y1:690.9798800000001\n",
      "------------------\n",
      "∗1\n",
      "∗1 and Atsuhiko BANNO\n",
      "x0:279.98999999999995,x1:410.44599999999997\n",
      "y0:655.4557649999999,y1:677.94601\n",
      "------------------\n",
      "Eiichi HORIUCHI\n",
      "x0:189.99999999999997,x1:279.97333\n",
      "y0:655.4557649999999,y1:668.7975449999999\n",
      "------------------\n",
      "∗1 Robot Innovation Research Center, AIST\n",
      "x0:221.63999999999996,x1:379.29793910199993\n",
      "y0:637.554378,y1:654.85989\n",
      "------------------\n",
      "Central 2, 1-1-1 Umezono, Tsukuba, Ibaraki 305-8568, Japan\n",
      "x0:190.02999999999997,x1:410.8984440000001\n",
      "y0:628.2443780000001,y1:638.250434\n",
      "------------------\n",
      "Negative obstacles in urban environment, e.g. ditches, downward stairs, and curb drop-\n",
      "offs, behind surroundings make their detection difﬁcult. They also pose a hazard to mobile\n",
      "robots; falls from the stairs will result in severe damage of the robot and its passengers. We\n",
      "argue that the exact choice of the negative obstacle to be avoided requires semantic judgement\n",
      "on reachability in addition to geometric conditions. The present paper introduces a real-\n",
      "time semantic segmentation approach for detecting negative obstacles using depth cameras.\n",
      "The models that have learned the images from a consumer-grade depth camera will segment\n",
      "negative obstacles in pixel level. The issues of annotating hardly visible negative obstacles and\n",
      "encoding depth information for feature learning are addressed.\n",
      "x0:113.38999999999997,x1:487.58038388899996\n",
      "y0:513.1580289999997,y1:615.926737\n",
      "------------------\n",
      "Key Words : Negative Obstacles, Depth Camera, Semantic Segmentation, Context Augmentation\n",
      "x0:112.88999999999997,x1:465.01550771400014\n",
      "y0:493.1443779999997,y1:503.3566519999997\n",
      "------------------\n",
      "1. は じ め に\n",
      "x0:132.25999999999996,x1:224.898009586\n",
      "y0:454.9121939999997,y1:467.7208239999997\n",
      "------------------\n",
      "周囲の事物に隠れて直接には観測しにくい凹型障害\n",
      "物（negative obstacles）は検出の難しさと転落リスク\n",
      "の重大性で移動ロボットの障害物検出の研究課題とさ\n",
      "れてきた．近年，歩道や公共スペースを走行する自律\n",
      "ロボットが移動支援や物資配送の手段として注目され\n",
      "ているが，そこでは下り段差や下り階段は普通に見ら\n",
      "れるハザードである．通常の障害物と異なり減速して\n",
      "もリスク軽減は小さく，その検出の重要性から本報告\n",
      "は凹型障害物に焦点をあてた手法を提案する．\n",
      "x0:65.19999999999997,x1:291.9699636560001\n",
      "y0:315.46977399999975,y1:446.8488979999997\n",
      "------------------\n",
      "従来研究は凹型障害物を幾何学的条件で定義する．\n",
      "例えば，地面より下の障害物(1) (5)，歩道縁石や下り階\n",
      "段(2)，著しい負の勾配斜面をもつ溝や地面(3)，地面の\n",
      "落ち込み(4)，路面の穴(6)などの定義が見られる．しか\n",
      "し図 1 のシーンが含む段差すべてがハザードになるわ\n",
      "けではなく，実際に避けるべき段差はロボットが到達\n",
      "するかなどの判断をさらに加えて指定する必要がある．\n",
      "x0:65.19999999999996,x1:298.03436358600004\n",
      "y0:210.8597739999998,y1:312.3588979999997\n",
      "------------------\n",
      "本報告は都市環境を対象にデプスカメラのデータに\n",
      "セマンティックセグメンテーションを適用して凹型障\n",
      "害物を検出する手法を提案する．凹型障害物は画像と\n",
      "して観測されて，二値セグメンテーションモデルが各\n",
      "画素を障害物とそれ以外に分類する．デプスカメラか\n",
      "x0:65.19999999999996,x1:291.9699636560001\n",
      "y0:136.13977399999982,y1:207.7488979999998\n",
      "------------------\n",
      "∗1 産業技術総合研究所ロボットイノベーション研究セン\n",
      "ター（〒 305-8568 茨城県つくば市梅園 1-1-1 中央第二）\n",
      "horiuchi.e@aist.go.jp atsuhiko.banno@aist.go.jp\n",
      "この成果の一部は国立研究開発法人新エネルギー・産業技\n",
      "術総合開発機構 (NEDO) の委託業務の結果得られた．\n",
      "x0:70.29,x1:287.108209338\n",
      "y0:36.941770999999974,y1:89.91183000000001\n",
      "------------------\n",
      "∗1\n",
      "x0:356.35,x1:365.32300000000004\n",
      "y0:713.2743780000001,y1:730.77601\n",
      "------------------\n",
      "Fig. 1 Not all down-steps make real hazard.\n",
      "x0:331.73,x1:512.9961943310001\n",
      "y0:357.138029,y1:368.256737\n",
      "------------------\n",
      "R\n",
      "x0:330.76,x1:340.723\n",
      "y0:331.58,y1:343.23670999999996\n",
      "------------------\n",
      "Observations\n",
      "x0:349.62,x1:386.254896232\n",
      "y0:327.736642,y1:335.519626\n",
      "------------------\n",
      "Observations\n",
      "-(cid:27)\n",
      "x0:408.58,x1:445.214896232\n",
      "y0:317.97,y1:335.519626\n",
      "------------------\n",
      "Observations\n",
      "-(cid:27)\n",
      "x0:467.54,x1:504.17489623200004\n",
      "y0:317.97,y1:335.519626\n",
      "------------------\n",
      "Edge model\n",
      "x0:342.11,x1:375.619972364\n",
      "y0:301.236642,y1:309.019626\n",
      "------------------\n",
      "Depression model\n",
      "x0:451.51000000000005,x1:502.0650281280001\n",
      "y0:301.236642,y1:309.019626\n",
      "------------------\n",
      "Transition model\n",
      "x0:394.03,x1:441.62701997599993\n",
      "y0:300.51664200000005,y1:308.29962600000005\n",
      "------------------\n",
      "Fig. 2 Negative obstacle observation models.\n",
      "x0:329.21000000000004,x1:515.5166539630001\n",
      "y0:276.74802900000003,y1:287.866737\n",
      "------------------\n",
      "らの形状情報は豊富な特徴を含んでおり，屋内外で使\n",
      "える市販の赤外線ステレオカメラ(7)を採用するが，こ\n",
      "れは赤外光の投射で LiDAR と同様夜も利用できる．人\n",
      "の認識能力が下がる夜間の検出は有用性が高く，昼夜\n",
      "別にデータセットを用意して精度を比較する．\n",
      "x0:308.98,x1:535.7519096560001\n",
      "y0:188.47977400000005,y1:260.08889800000003\n",
      "------------------\n",
      "図 2 は検出アプローチの違いを表す．提案手法が\n",
      "用いるエッジモデルは画像で唯一観測できる凹型障害\n",
      "物のエッジに着目したモデルである．遷移モデル(1)と\n",
      "陥没モデルは LiDAR で想定されるモデルであり，3D\n",
      "マップを真上から見ることで観測されない領域が分か\n",
      "る．エッジモデルではエッジ画素を指定してセグメン\n",
      "テーションの学習に用いる真値を人手で与える必要が\n",
      "x0:308.98,x1:535.7463872420001\n",
      "y0:83.86977400000006,y1:185.36889800000006\n",
      "-------pages---------\n",
      "------------------\n",
      "Depth camera\n",
      "x0:95.63,x1:134.54489210399998\n",
      "y0:765.726642,y1:773.509626\n",
      "------------------\n",
      "Depth camera\n",
      "x0:159.12,x1:198.041894\n",
      "y0:765.726642,y1:773.509626\n",
      "------------------\n",
      "Depth camera\n",
      "x0:227.15,x1:266.071894\n",
      "y0:765.726642,y1:773.509626\n",
      "------------------\n",
      "Edge\n",
      "x0:94.30999999999999,x1:108.64156999999999\n",
      "y0:736.246642,y1:744.029626\n",
      "------------------\n",
      "Edge\n",
      "x0:157.81000000000003,x1:172.14157000000003\n",
      "y0:736.246642,y1:744.029626\n",
      "------------------\n",
      "Edge\n",
      "x0:234.91000000000003,x1:249.24157000000002\n",
      "y0:736.246642,y1:744.029626\n",
      "------------------\n",
      "Occluder\n",
      "x0:88.69999999999999,x1:114.25971\n",
      "y0:717.3966419999999,y1:725.179626\n",
      "------------------\n",
      "Occluder\n",
      "x0:152.20000000000002,x1:177.75971\n",
      "y0:717.3966419999999,y1:725.179626\n",
      "------------------\n",
      "Occluder\n",
      "x0:229.3,x1:254.85971\n",
      "y0:717.3966419999999,y1:725.179626\n",
      "------------------\n",
      "Fig. 3 Context-based negative obstacle detection.\n",
      "x0:77.08,x1:280.085634074\n",
      "y0:693.628029,y1:704.7467369999999\n",
      "------------------\n",
      "あるが，対象物だけでなく近傍の物体を含めたコンテ\n",
      "キストの利用が物体検出の精度を向上すること(8)が報\n",
      "告されている．ここで利用するこのアイデアを図 3 に\n",
      "示す．コンテキストは真値画素の膨張処理で得られる．\n",
      "これを検出対象とすれば精度向上に加えて，後で示す\n",
      "ようにアノテーションの労力の軽減が期待できる．ま\n",
      "た障害物回避にはこれを収縮処理して利用できる．\n",
      "x0:65.19999999999999,x1:298.03438275800016\n",
      "y0:575.4697739999997,y1:676.958898\n",
      "------------------\n",
      "デプス情報を画像化して特徴を学習する方法を説明\n",
      "する．畳み込みニューラルネットワーク（CNN）のエ\n",
      "ンコーダ・デコーダアーキテクチャ(9)はセグメンテー\n",
      "ションで優れた性能を持つことが多数報告されている．\n",
      "そして残差学習(10)は多層ネットワークの学習でよく知\n",
      "られた勾配消失問題の一つの解決策をもたらした．こ\n",
      "の手法にはネットワークを多層化して高精度化する方\n",
      "向と効率化して実時間化する方向がある．畳み込み層\n",
      "は因子分解で，例えば 3x3 の層を 3x1 と 1x3 の二層\n",
      "に分解して，パラメータを減らして精度と効率が両立\n",
      "できる可能性がある．Erfnet(11) (12)はこのアイデアの有\n",
      "効性を屋外データセットで実証しており，この特徴学\n",
      "習モデルを提案手法でも採用する．屋外データでのデ\n",
      "プス情報の有効性は未知であるが，一つのデプス情報\n",
      "の 3 チャンネル画像化手法（HHA）(13)が屋内データ\n",
      "の物体検出精度を改善することが報告されている．屋\n",
      "外データでの有効性を示すことと新規画像化手法の提\n",
      "案が本報告の課題である．\n",
      "x0:65.19999999999999,x1:298.03436358600015\n",
      "y0:306.4797739999995,y1:572.3588979999996\n",
      "------------------\n",
      "本報告のロボット工学に対する主要な貢献は，（i）直\n",
      "接の観測が難しい凹型障害物をコンテキストとして把\n",
      "握する画素レベル定義手法，（ii）新規デプス情報画像\n",
      "化手法の提案とその定量的評価，（iii）上記を包含した\n",
      "日中と夜間のデータセット公開の三点にある．\n",
      "x0:65.20000000000002,x1:291.9790151020002\n",
      "y0:231.75977399999954,y1:303.3588979999995\n",
      "------------------\n",
      "2. 関 連 研 究\n",
      "x0:132.26000000000002,x1:224.89800958600006\n",
      "y0:209.05219399999953,y1:221.86082399999952\n",
      "------------------\n",
      "凹型障害物検出は都市環境を対象とした報告(2) (4)\n",
      "もあるが，主にオフロードの走行可能性の文脈で研\n",
      "究(1) (3) (5) (6)が進められてきた．センサは信頼性が高い\n",
      "LiDAR が主に用いられるが，スパースな観測値を蓄\n",
      "積する 3D や 2.5D のマップが必要であり，これらは画\n",
      "素と比較して分解能で劣る．ステレオビジョンで 2.5D\n",
      "マップを用いる手法(2)も同様である．また従来研究で\n",
      "定量的評価まで行う報告は少ないが，画素レベルで真\n",
      "x0:65.20000000000003,x1:291.97288075800003\n",
      "y0:84.55977399999954,y1:202.6796259999995\n",
      "------------------\n",
      "N\n",
      "N\n",
      "N\n",
      "x0:473.53,x1:478.491658\n",
      "y0:764.466642,y1:772.3680420000001\n",
      "------------------\n",
      "2D LiDAR\n",
      "x0:406.91,x1:437.818726156\n",
      "y0:764.4066419999995,y1:772.1896259999995\n",
      "------------------\n",
      "p\n",
      "p\n",
      "p\n",
      "(cid:27)\n",
      "x0:394.02,x1:403.983\n",
      "y0:732.87,y1:759.5980420000001\n",
      "------------------\n",
      "?6\n",
      "x0:394.02,x1:403.983\n",
      "y0:737.12,y1:756.7133799999999\n",
      "------------------\n",
      "h\n",
      "x0:386.59999999999997,x1:390.087\n",
      "y0:741.746642,y1:749.418042\n",
      "------------------\n",
      "-\n",
      "x0:426.57,x1:436.533\n",
      "y0:732.87,y1:745.42338\n",
      "------------------\n",
      "q\n",
      "q\n",
      "q\n",
      "x0:438.89,x1:442.687\n",
      "y0:730.446642,y1:738.3580420000001\n",
      "------------------\n",
      "?\n",
      "x0:476.22,x1:486.18300000000005\n",
      "y0:725.78,y1:738.3333799999999\n",
      "------------------\n",
      "l\n",
      "x0:414.13,x1:416.06877199999997\n",
      "y0:724.736642,y1:732.408042\n",
      "------------------\n",
      "Fig. 4 HLD classiﬁer (4) detecting a drop-off.\n",
      "x0:329.28000000000003,x1:515.457793963\n",
      "y0:702.698029,y1:716.059626\n",
      "------------------\n",
      "値を与えれば定量的評価に利用できる．\n",
      "x0:308.98,x1:481.5280000000001\n",
      "y0:674.2097739999999,y1:686.038898\n",
      "------------------\n",
      "HLD 分類器(4)は観測値の最近接ペア 2 点の間の高\n",
      "さと距離の変化量 h,l と観測値密度 d を用いて障害物\n",
      "を検出する手法である．図 4 はペア p,q，変数 h, l，重\n",
      "力方向 NNN を表す．LiDAR のデータを 2 次元セルで離\n",
      "散化してセルの h, l,d を求め，この HLD 空間上で分\n",
      "類モデルが障害物セルを分類する．しかしモデルは機\n",
      "械学習ではなく人の手で与え，分類は障害物を凹型と\n",
      "それ以外とに区別はしない．本報告はこの 2.5D マッ\n",
      "プ領域のアイデアをデプス情報の画像化に利用し，画\n",
      "素領域の機械学習アプローチに拡張する．\n",
      "x0:308.98,x1:536.8220000000001\n",
      "y0:524.7697739999994,y1:672.7696259999999\n",
      "------------------\n",
      "機械学習でのデプス情報画像化について，屋内デー\n",
      "タの RGB-D 画像から物体認識する CNN アーキテク\n",
      "チャ(14)で調査されている．認識精度をデプスレンダリ\n",
      "ング画像（DPT），面法線画像(15)，HHA(13)，デプス\n",
      "Jet 色マップ画像で比較しているが，本報告ではこの\n",
      "うち DPT と HHA を比較対象に用いる．また Erfnet は\n",
      "視覚障害者の移動支援(16)にも適用されている．本報告\n",
      "のデプスカメラと性能が近いカメラを用いて RGB-D\n",
      "画像で人や車などの対象物と移動可能路面のセグメン\n",
      "テーションを実現しているが，凹型障害物の検出とデ\n",
      "プス情報の画像化は触れていない．\n",
      "x0:308.9800000000001,x1:535.7537088280001\n",
      "y0:360.3797739999995,y1:521.6488979999995\n",
      "------------------\n",
      "提案手法は最新の LiDAR の結果との比較が適切で\n",
      "あり，文献(6)の 2.5D 領域の陥没モデルを画素領域に\n",
      "用いてエッジ検出に帰着して精度を比較する．\n",
      "x0:308.98000000000013,x1:535.7412095860002\n",
      "y0:315.5497739999995,y1:357.26889799999947\n",
      "------------------\n",
      "Fig. 5 Realsense depth camera on a robot frame.\n",
      "x0:322.29,x1:522.4365981850001\n",
      "y0:203.318029,y1:214.43673700000002\n",
      "------------------\n",
      "3. コンテキスト情報\n",
      "x0:376.04,x1:468.678\n",
      "y0:168.94219400000003,y1:181.75082400000002\n",
      "------------------\n",
      "車いす視点からの凹型障害物検出に焦点をあて，\n",
      "x0:318.56,x1:541.7988159300002\n",
      "y0:149.059774,y1:160.888898\n",
      "------------------\n",
      "Realsense デプスカメラを図 5 の取付で固定して日中\n",
      "と夜間のデータセットを収集した．用いたカメラは慣\n",
      "性計測機能がないので，ロボットの水平路面での使用\n",
      "を仮定して，事前に水平で平坦な路面で得た観測値か\n",
      "ら面法線を求めて重力方向の推定値 ˜NNN に用いる．デー\n",
      "x0:308.98,x1:535.7514048280002\n",
      "y0:74.33977400000002,y1:145.93889800000002\n",
      "-------pages---------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      "Daytime IR\n",
      "x0:106.63,x1:139.36595599999998\n",
      "y0:680.2666419999999,y1:688.049626\n",
      "------------------\n",
      "Nighttime IR\n",
      "x0:215.67000000000002,x1:252.667\n",
      "y0:680.2666419999999,y1:688.049626\n",
      "------------------\n",
      "Fig. 6 Context augmentation.\n",
      "x0:116.62,x1:240.54972711099995\n",
      "y0:661.368029,y1:672.486737\n",
      "------------------\n",
      "タ収集は，歩車道段差を主に含む歩道環境（SW），側\n",
      "溝を主に含む通路環境（PSG），下り階段を主に含むテ\n",
      "ラス環境（TCE）の異なる環境でデータの多様性の確\n",
      "保を考慮して行った．各フレームはロボット直前の路\n",
      "面と凹型障害物を少なくとも一つ含む．日中データは\n",
      "好天時のものである．本報告が用いたデータセット\n",
      "は https://staff.aist.go.jp/horiuchi.e/から\n",
      "アクセスできる．\n",
      "x0:65.2,x1:291.9691762420001\n",
      "y0:528.2697739999996,y1:644.708898\n",
      "------------------\n",
      "アノテーションはロボットの直進を想定して，直前\n",
      "の路面からの延長上に存在して実際にロボットが遭遇\n",
      "する可能性がある段差や溝などの凹型障害物を対象に\n",
      "行う．この指針は従来の幾何学的条件に到達可能性の\n",
      "判断を加えたものである．前述のエッジモデルに従い，\n",
      "ツールを利用して人手で赤外線画像（IR）上でエッジ\n",
      "画素を 1 画素幅の折れ線でアノテーションする．この\n",
      "アノテーションに膨張処理を 4 近傍（菱形カーネル），\n",
      "処理回数 0 から 128 で適用した拡張されたコンテキス\n",
      "トを検出対象として障害物検出を行う．図 6 に日中，\n",
      "夜間 IR にその一部を重ねて示すが，後者には投射さ\n",
      "れた赤外光パターンが映っている．フレームは多数の\n",
      "エッジを含むが上記指針より対象は 2 箇所の段差だけ\n",
      "である．また元のアノテーションが真の画素からぶれ\n",
      "てもコンテキストは障害物を捉えることができる．\n",
      "x0:65.2,x1:298.03438275800016\n",
      "y0:304.1097739999996,y1:525.1588979999996\n",
      "------------------\n",
      "セグメンテーションの評価指標には，1 フレームの\n",
      "障害物画素の正答/誤答数を TP/FN，非障害物の正答/誤\n",
      "答数を TN/FP として指標 IoU =\n",
      "が標準的に使\n",
      "われる．一方でハザード検出の点から評価を考えると，\n",
      "ハザードの見逃しは避けるべき事象である．そこで予\n",
      "測できた障害物画素の比率を表す再現率 recall = TP\n",
      "TP+FN\n",
      "が一定水準を満たす条件を追加する．本報告は一定の\n",
      "再現率で絞った範囲で IoU が最大のモデルを最適とす\n",
      "る基準を用いる．\n",
      "x0:65.19999999999999,x1:298.0344211020001\n",
      "y0:169.61977399999995,y1:300.9988979999996\n",
      "------------------\n",
      "TP\n",
      "x0:211.24000000000012,x1:218.4325580000001\n",
      "y0:263.38277399999964,y1:272.52947599999965\n",
      "------------------\n",
      "TP+FP+FN\n",
      "x0:197.24,x1:232.067326\n",
      "y0:255.512774,y1:265.7063\n",
      "------------------\n",
      "4. デプス情報画像化手法\n",
      "x0:122.68000000000004,x1:234.49000000000004\n",
      "y0:146.91219399999994,y1:159.72082399999994\n",
      "------------------\n",
      "デプス情報は IR と位置合わせされ，ノイズ処理後\n",
      "に内部パラメータを用いて画素と一対一に対応した 3\n",
      "次元点群に変換される．提案手法はこれを図 7 のよう\n",
      "に 3 チャンネル画像化して利用する．HHA は画素ご\n",
      "x0:65.20000000000002,x1:291.9715\n",
      "y0:82.18977399999991,y1:138.85889799999993\n",
      "------------------\n",
      "∗\n",
      "HHA\n",
      "x0:468.9,x1:486.4905\n",
      "y0:680.2666419999999,y1:693.162035\n",
      "------------------\n",
      "DPT\n",
      "x0:360.19,x1:373.36388600000004\n",
      "y0:680.2666419999999,y1:688.049626\n",
      "------------------\n",
      "hHLD\n",
      "x0:357.87,x1:375.68857\n",
      "y0:586.436642,y1:594.2196260000001\n",
      "------------------\n",
      "wHLD\n",
      "x0:468.26,x1:487.626798\n",
      "y0:586.436642,y1:594.2196260000001\n",
      "------------------\n",
      "Fig. 7 Images created by depth encoding.\n",
      "x0:336.4,x1:508.331219\n",
      "y0:567.538029,y1:578.656737\n",
      "------------------\n",
      "とに水平視差，路面からの標高 e，面法線の重力方向\n",
      "との角度の 3 要素を用いるが，ここでは視差をデプス，\n",
      "を用\n",
      "効率化のため角度をコサインに置き換えた HHA\n",
      "いる．標高 e は事前に観測した路面データと重力方向\n",
      "推定値 ˜NNN より 3 次元座標から求まる．面法線は画像\n",
      "上の 3x3 近傍の点群に PCA を適用して計算する．\n",
      "x0:308.98,x1:541.8147003440001\n",
      "y0:464.319774,y1:550.8688980000001\n",
      "------------------\n",
      "∗\n",
      "x0:510.66,x1:514.346\n",
      "y0:515.28,y1:528.07042\n",
      "------------------\n",
      "HLD 分類器は隣接セルのペアを用いるが，画素領域\n",
      "では高さ方向と幅方向の画素の並びが利用でき，それ\n",
      "ぞれ新規画像化手法 hHLD と wHLD を導入する．画\n",
      "素のペアからその 3 次元座標と重力方向を用いて変数\n",
      "h,l が計算できる．図 4 に示す ppp, qqq をペアの 3 次元座\n",
      "標とすると，変数 h,l は式（1）で計算され，画素 u の\n",
      "密度 d(u) は文献(4)に従い式（2）で与える．\n",
      "h = | ˜NNN · (qqq− ppp)|, l = |qqq− ppp− ˜NNN · (qqq− ppp)|\n",
      "x0:308.98,x1:535.753974898\n",
      "y0:335.36802900000004,y1:461.208898\n",
      "------------------\n",
      "(1)\n",
      "x0:524.1300000000006,x1:535.7468580000005\n",
      "y0:335.36802900000004,y1:346.486737\n",
      "------------------\n",
      "exp{−0.5D(u,v)/s 2}\n",
      "x0:405.03000000000065,x1:494.1315\n",
      "y0:310.878029,y1:330.335805\n",
      "------------------\n",
      "d(u) = (cid:229)\n",
      "x0:350.5900000000006,x1:387.3300000000006\n",
      "y0:310.878029,y1:329.602838\n",
      "------------------\n",
      "(2)\n",
      "ここで N(u) は画素 u の 5x5 近傍, v(̸= u) は N(u) の画\n",
      "素，D(u,v) は u, v の 3 次元座標の距離二乗値を表し，\n",
      "密度計算のスケール s = 0.1 を実験的に選んだ．\n",
      "x0:308.98,x1:541.8051031720001\n",
      "y0:253.659774,y1:321.996737\n",
      "------------------\n",
      "v∈N(u)\n",
      "x0:380.9700000000006,x1:403.9277080000006\n",
      "y0:300.580276,y1:314.97042\n",
      "------------------\n",
      "屋外データではカメラ視野角や取付に依存して遠景\n",
      "が入るため，変数 h, l と標高 e は広い値域をとる．こ\n",
      "れらはガウス分布に従うと仮定できず平均値と標準偏\n",
      "差で適切に正規化できないので，画像化にはデータ依\n",
      "存の外れ値処理が求められる．そこで訓練データにお\n",
      "ける実際の分布を調べて上限・下限を決定し，データ\n",
      "セット全体について超える値を上限・下限で置き換え\n",
      "て画像の 0 から 255 の範囲にエンコードする．昼夜別\n",
      "に，フレームごとに h の 90 パーセンタイル値と l の\n",
      "80 パーセンタイル値を求め，訓練データ全体の中央値\n",
      "を h, l それぞれの上限とする．標高 e の上限はカメラ\n",
      "の標高 0.65m，下限は −1.00m の固定値を使用する．\n",
      "x0:308.98,x1:537.7800000000002\n",
      "y0:74.32977400000004,y1:250.548898\n",
      "-------pages---------\n",
      "------------------\n",
      "5. 実\n",
      "x0:146.64,x1:172.17600000000002\n",
      "y0:760.792194,y1:773.600824\n",
      "------------------\n",
      "験\n",
      "x0:200.94000083600002,x1:210.52600083600004\n",
      "y0:760.792194,y1:772.410426\n",
      "------------------\n",
      "5·1 実験条件\n",
      "x0:74.61,x1:135.299503516\n",
      "y0:740.612194,y1:760.495805\n",
      "------------------\n",
      "表 1 に日中・夜間データの区分\n",
      "（訓練/検証/テスト），環境別（歩道/通路/テラス），全\n",
      "体のフレーム数を示す．全フレームは時間順に整列さ\n",
      "れ，環境ごとに時間順に 5 : 1 : 4 の比率で区分してデー\n",
      "タ全体を区分した．画像サイズは 640x480 として 1 個\n",
      "x0:60.629999999999995,x1:291.96871807\n",
      "y0:681.1297739999998,y1:752.7288980000001\n",
      "------------------\n",
      "Table 1 Daytime/nighttime dataset frames.\n",
      "x0:90.41,x1:266.75509999999997\n",
      "y0:667.1180289999999,y1:678.2367369999998\n",
      "------------------\n",
      "Train/Val/Test\n",
      "511/101/412\n",
      "560/111/450\n",
      "x0:135.18,x1:174.74302707799998\n",
      "y0:642.696642,y1:666.819626\n",
      "------------------\n",
      "SW/PSG/TCE\n",
      "183/387/454\n",
      "340/516/265\n",
      "x0:186.689530922,x1:226.992276922\n",
      "y0:642.696642,y1:666.819626\n",
      "------------------\n",
      "Total\n",
      "1024\n",
      "1121\n",
      "x0:238.945678052,x1:253.11689487\n",
      "y0:642.696642,y1:666.819626\n",
      "------------------\n",
      "Dataset\n",
      "Day\n",
      "Night\n",
      "x0:102.31,x1:123.225026\n",
      "y0:642.696642,y1:666.8196259999999\n",
      "------------------\n",
      "∗\n",
      "x0:285.28999999999996,x1:288.97599999999994\n",
      "y0:626.09,y1:638.8804200000001\n",
      "------------------\n",
      "のフレームから同一サイズで画像化（IR, DPT, HHA\n",
      ",\n",
      "hHLD, wHLD）する．前述のアノテーションを実施し\n",
      "てフレームと同数のラベル画像を用意し，1 個のラベ\n",
      "ル画像から膨張処理 0 から 128 の範囲で複数の拡張ラ\n",
      "ベル画像を生成する．画素数には障害物（P）と非障害\n",
      "物（N）で偏りがあるので，訓練時に最小化すべき目\n",
      "的関数である交差エントロピー損失関数に，偏りに応\n",
      "じて損失に乗じる重み wP，wN を与える．昼（D）夜\n",
      "（N）別に訓練データ全体の障害物と非障害物の画素\n",
      "数の比率をラベル画像から求め，その比率に重み計算\n",
      "法(17)を適用した結果を表 2 に示す．実験は PyTorch プ\n",
      "x0:60.62999999999994,x1:291.97242517200004\n",
      "y0:470.52977399999975,y1:631.7988980000001\n",
      "------------------\n",
      "Table 2 Training weights for augmented context.\n",
      "Context\n",
      "48\n",
      "D wN\n",
      "D wP\n",
      "N wN\n",
      "N wP\n",
      "Context\n",
      "D wN\n",
      "D wP\n",
      "N wN\n",
      "N wP\n",
      "x0:73.19999999999999,x1:278.974432926\n",
      "y0:373.72912299999996,y1:466.8667369999997\n",
      "------------------\n",
      "0\n",
      "x0:120.21,x1:123.69699999999999\n",
      "y0:447.266642,y1:455.049626\n",
      "------------------\n",
      "8\n",
      "x0:160.06,x1:163.547\n",
      "y0:447.266642,y1:455.049626\n",
      "------------------\n",
      "32\n",
      "x0:232.79000486400003,x1:239.764004864\n",
      "y0:447.266642,y1:455.049626\n",
      "------------------\n",
      "16\n",
      "x0:196.420002074,x1:203.39400207399999\n",
      "y0:447.266642,y1:455.049626\n",
      "------------------\n",
      "0.50065\n",
      "382.58123\n",
      "0.50072\n",
      "347.12004\n",
      "x0:107.13,x1:136.7695\n",
      "y0:414.986642,y1:446.67962600000004\n",
      "------------------\n",
      "0.51153\n",
      "22.18202\n",
      "0.51271\n",
      "20.15445\n",
      "x0:148.722998766,x1:174.875498766\n",
      "y0:414.986642,y1:446.67962600000004\n",
      "------------------\n",
      "0.52326\n",
      "11.24688\n",
      "0.52567\n",
      "10.23733\n",
      "x0:186.829,x1:212.9815\n",
      "y0:414.986642,y1:446.67962600000004\n",
      "------------------\n",
      "0.57957\n",
      "3.64166\n",
      "0.58783\n",
      "3.34629\n",
      "x0:259.56090179200004,x1:282.228901792\n",
      "y0:414.986642,y1:446.67962600000004\n",
      "------------------\n",
      "0.54940\n",
      "5.56003\n",
      "0.55457\n",
      "5.08079\n",
      "x0:224.93749876599998,x1:247.60740302600001\n",
      "y0:414.986642,y1:446.67962600000004\n",
      "------------------\n",
      "128\n",
      "x0:265.660015038,x1:276.121015038\n",
      "y0:406.616642,y1:414.399626\n",
      "------------------\n",
      "112\n",
      "x0:231.040012016,x1:241.50101201599998\n",
      "y0:406.616642,y1:414.399626\n",
      "------------------\n",
      "96\n",
      "x0:196.420008994,x1:203.39400899400002\n",
      "y0:406.616642,y1:414.399626\n",
      "------------------\n",
      "64\n",
      "x0:118.47,x1:125.44399999999999\n",
      "y0:406.616642,y1:414.399626\n",
      "------------------\n",
      "80\n",
      "x0:158.320007868,x1:165.294007868\n",
      "y0:406.616642,y1:414.399626\n",
      "------------------\n",
      "0.81954\n",
      "1.28236\n",
      "0.85159\n",
      "1.21103\n",
      "x0:259.563401792,x1:282.228901792\n",
      "y0:374.34664200000003,y1:406.039626\n",
      "------------------\n",
      "0.65480\n",
      "2.11497\n",
      "0.67029\n",
      "1.96800\n",
      "x0:150.469003612,x1:173.134503612\n",
      "y0:374.34664200000003,y1:406.039626\n",
      "------------------\n",
      "0.75618\n",
      "1.47586\n",
      "0.78203\n",
      "1.38640\n",
      "x0:224.93749876599998,x1:247.60299876599998\n",
      "y0:374.34664200000003,y1:406.039626\n",
      "------------------\n",
      "0.61442\n",
      "2.68478\n",
      "0.62604\n",
      "2.48340\n",
      "x0:110.62,x1:133.28549999999998\n",
      "y0:374.34664200000003,y1:406.039626\n",
      "------------------\n",
      "0.70171\n",
      "1.73938\n",
      "0.72190\n",
      "1.62661\n",
      "x0:188.575,x1:211.24049999999997\n",
      "y0:374.34664200000003,y1:406.039626\n",
      "------------------\n",
      "ラットフォーム上で特徴学習モデルに前述の Erfnet(12)\n",
      "を用いて行う．訓練とテストはすべての画像化／コン\n",
      "テキスト拡張の組合せで行い，訓練中に検証データで\n",
      "最高の IoU を得たモデルでテストを行う．\n",
      "x0:65.19999999999996,x1:291.96868399999994\n",
      "y0:307.559774,y1:365.899626\n",
      "------------------\n",
      "訓練に関する設定は文献(12)のベストプラクティス\n",
      "“from scratch” に従った．具体的には，エンコーダー単\n",
      "独とエンコーダー＋デコーダーの 2 段階の訓練，Adam\n",
      "最適化による確率的勾配降下法，訓練時のオンライン\n",
      "データ拡張としてランダムな左右反転と 2 画素までの\n",
      "高さと幅方向の平行移動を適用する．本報告で変更し\n",
      "たのは，二値クラス，上記損失関数の重み，バッチサ\n",
      "イズ 8，正則化を高めたドロップアウトの確率 0.5，エ\n",
      "ポック数 80 の箇所である．\n",
      "5·2 結果\n",
      "すべてのモデルのテストデータの結\n",
      "果について昼夜別に IoU を図 8 と図 9，再現率を表 3\n",
      "と表 4 に示す．これら定量的評価は，コンテキスト拡\n",
      "張による精度向上，IR と比較したデプス情報の有効性，\n",
      "提案する画像化 wHLD と hHLD の優位性，および昼よ\n",
      "りも夜の精度の高さを示す．昼ではモデル wHLD/128\n",
      "x0:65.19999999999996,x1:298.0328983440001\n",
      "y0:83.39977400000008,y1:306.12962600000003\n",
      "------------------\n",
      "∗\n",
      "DPT HHA\n",
      "x0:408.97,x1:449.0505\n",
      "y0:753.486642,y1:766.382035\n",
      "------------------\n",
      "100.0\n",
      "x0:357.83,x1:373.5215\n",
      "y0:758.216642,y1:765.999626\n",
      "------------------\n",
      "hHLD wHLD\n",
      "x0:456.54,x1:500.076798\n",
      "y0:753.6366419999999,y1:761.519626\n",
      "------------------\n",
      "IR\n",
      "x0:389.4,x1:396.37399999999997\n",
      "y0:753.686642,y1:761.4696260000001\n",
      "------------------\n",
      "80.0\n",
      "x0:359.57,x1:371.77450000000005\n",
      "y0:741.8966419999999,y1:749.679626\n",
      "------------------\n",
      "IoUintestdata[%]\n",
      "x0:338.56037399999997,x1:346.34335799999997\n",
      "y0:693.74,y1:748.7365960000001\n",
      "------------------\n",
      "60.0\n",
      "x0:359.57,x1:371.77450000000005\n",
      "y0:725.5666419999999,y1:733.349626\n",
      "------------------\n",
      "40.0\n",
      "x0:359.57,x1:371.77450000000005\n",
      "y0:709.2366419999998,y1:717.0196259999999\n",
      "------------------\n",
      "20.0\n",
      "x0:359.57,x1:371.77450000000005\n",
      "y0:692.9166419999998,y1:700.6996259999999\n",
      "------------------\n",
      "0.0\n",
      "x0:361.31,x1:370.02750000000003\n",
      "y0:676.5866419999998,y1:684.3696259999998\n",
      "------------------\n",
      "96\n",
      "x0:468.76,x1:475.73400000000004\n",
      "y0:672.076642,y1:679.859626\n",
      "------------------\n",
      "32\n",
      "x0:405.270006982,x1:412.24400698200003\n",
      "y0:672.046642,y1:679.8296260000001\n",
      "------------------\n",
      "64\n",
      "x0:437.020013732,x1:443.99401373200004\n",
      "y0:672.046642,y1:679.8296260000001\n",
      "------------------\n",
      "128\n",
      "x0:498.77,x1:509.231\n",
      "y0:672.046642,y1:679.8296260000001\n",
      "------------------\n",
      "0\n",
      "x0:375.27,x1:378.757\n",
      "y0:672.046642,y1:679.8296260000001\n",
      "------------------\n",
      "Context augmentation\n",
      "x0:409.66,x1:471.344456\n",
      "y0:663.686642,y1:671.4696260000001\n",
      "------------------\n",
      "Fig. 8 Daytime test IoU of negative obstacles.\n",
      "x0:327.42,x1:517.304564926\n",
      "y0:639.208029,y1:650.326737\n",
      "------------------\n",
      "∗\n",
      "DPT HHA\n",
      "x0:408.97,x1:449.0505\n",
      "y0:609.606642,y1:622.502035\n",
      "------------------\n",
      "100.0\n",
      "x0:357.83,x1:373.5215\n",
      "y0:614.336642,y1:622.119626\n",
      "------------------\n",
      "hHLD wHLD\n",
      "x0:456.54,x1:500.076798\n",
      "y0:609.7566419999999,y1:617.639626\n",
      "------------------\n",
      "IR\n",
      "x0:389.4,x1:396.37399999999997\n",
      "y0:609.806642,y1:617.5896260000001\n",
      "------------------\n",
      "80.0\n",
      "x0:359.57,x1:371.77450000000005\n",
      "y0:598.0166419999999,y1:605.799626\n",
      "------------------\n",
      "IoUintestdata[%]\n",
      "x0:338.56037399999997,x1:346.34335799999997\n",
      "y0:549.86,y1:604.856596\n",
      "------------------\n",
      "60.0\n",
      "x0:359.57,x1:371.77450000000005\n",
      "y0:581.6866419999999,y1:589.469626\n",
      "------------------\n",
      "40.0\n",
      "x0:359.57,x1:371.77450000000005\n",
      "y0:565.3566419999999,y1:573.1396259999999\n",
      "------------------\n",
      "20.0\n",
      "x0:359.57,x1:371.77450000000005\n",
      "y0:549.0266419999998,y1:556.8096259999999\n",
      "------------------\n",
      "0.0\n",
      "x0:361.31,x1:370.02750000000003\n",
      "y0:532.7066419999998,y1:540.4896259999998\n",
      "------------------\n",
      "96\n",
      "x0:468.76,x1:475.73400000000004\n",
      "y0:528.1966419999999,y1:535.9796259999999\n",
      "------------------\n",
      "32\n",
      "x0:405.270006982,x1:412.24400698200003\n",
      "y0:528.1666419999999,y1:535.949626\n",
      "------------------\n",
      "64\n",
      "x0:437.020013732,x1:443.99401373200004\n",
      "y0:528.1666419999999,y1:535.949626\n",
      "------------------\n",
      "128\n",
      "x0:498.77,x1:509.231\n",
      "y0:528.1666419999999,y1:535.949626\n",
      "------------------\n",
      "0\n",
      "x0:375.27,x1:378.757\n",
      "y0:528.1666419999999,y1:535.949626\n",
      "------------------\n",
      "Context augmentation\n",
      "x0:409.66,x1:471.344456\n",
      "y0:519.8066419999999,y1:527.5896260000001\n",
      "------------------\n",
      "Fig. 9 Nightime test IoU of negative obstacles.\n",
      "x0:325.76,x1:518.972206926\n",
      "y0:495.318029,y1:506.436737\n",
      "------------------\n",
      "Table 3 Daytime test recall [%] of negative obstacles.\n",
      "x0:312.64000000000004,x1:532.0950109630002\n",
      "y0:474.41802900000005,y1:485.536737\n",
      "------------------\n",
      "∗\n",
      "x0:442.101,x1:444.5915\n",
      "y0:470.58000000000004,y1:479.22203500000006\n",
      "------------------\n",
      "wHLD\n",
      "78.82\n",
      "77.40\n",
      "81.08\n",
      "84.97\n",
      "81.36\n",
      "84.68\n",
      "81.91\n",
      "87.21\n",
      "86.15\n",
      "88.45\n",
      "x0:486.811,x1:506.958886\n",
      "y0:386.236642,y1:474.37766400000004\n",
      "------------------\n",
      "Context\n",
      "x0:337.76000000000005,x1:359.74905687\n",
      "y0:466.33664200000004,y1:474.11962600000004\n",
      "------------------\n",
      "IR\n",
      "x0:376.06,x1:383.034\n",
      "y0:466.33664200000004,y1:474.11962600000004\n",
      "------------------\n",
      "DPT\n",
      "75.37\n",
      "73.09\n",
      "72.83\n",
      "76.49\n",
      "73.86\n",
      "78.05\n",
      "78.17\n",
      "77.71\n",
      "79.83\n",
      "77.86\n",
      "x0:399.344998766,x1:415.036498766\n",
      "y0:386.236642,y1:474.11962600000004\n",
      "------------------\n",
      "HHA\n",
      "75.13\n",
      "77.29\n",
      "80.44\n",
      "79.47\n",
      "81.81\n",
      "74.65\n",
      "83.80\n",
      "81.52\n",
      "82.93\n",
      "84.57\n",
      "x0:426.992,x1:443.88050000000004\n",
      "y0:386.236642,y1:474.11962600000004\n",
      "------------------\n",
      "hHLD\n",
      "73.90\n",
      "73.77\n",
      "77.46\n",
      "80.42\n",
      "83.39\n",
      "79.80\n",
      "84.28\n",
      "82.07\n",
      "82.69\n",
      "77.03\n",
      "x0:457.041,x1:474.85957\n",
      "y0:386.236642,y1:474.11962600000004\n",
      "------------------\n",
      "0\n",
      "8\n",
      "16\n",
      "32\n",
      "48\n",
      "64\n",
      "80\n",
      "96\n",
      "112\n",
      "128\n",
      "x0:343.52000000000004,x1:353.98100000000005\n",
      "y0:386.236642,y1:465.74962600000003\n",
      "------------------\n",
      "43.61\n",
      "45.01\n",
      "44.66\n",
      "49.00\n",
      "48.20\n",
      "52.41\n",
      "64.48\n",
      "63.31\n",
      "60.36\n",
      "63.00\n",
      "x0:371.7,x1:387.3915\n",
      "y0:386.236642,y1:465.74962600000003\n",
      "------------------\n",
      "Table 4 Nighttime test recall [%] of negative obstacles.\n",
      "x0:309.59000000000003,x1:535.1423769260001\n",
      "y0:370.418029,y1:381.53673699999996\n",
      "------------------\n",
      "∗\n",
      "x0:442.101,x1:444.5915\n",
      "y0:366.59000000000003,y1:375.23203500000005\n",
      "------------------\n",
      "wHLD\n",
      "91.04\n",
      "93.34\n",
      "94.55\n",
      "94.93\n",
      "95.00\n",
      "94.89\n",
      "95.23\n",
      "95.75\n",
      "95.85\n",
      "94.84\n",
      "x0:486.811,x1:506.958886\n",
      "y0:282.236642,y1:370.37766400000004\n",
      "------------------\n",
      "IR\n",
      "x0:376.06,x1:383.034\n",
      "y0:362.33664200000004,y1:370.11962600000004\n",
      "------------------\n",
      "DPT\n",
      "90.00\n",
      "90.92\n",
      "92.64\n",
      "94.44\n",
      "94.32\n",
      "94.53\n",
      "95.65\n",
      "95.20\n",
      "95.10\n",
      "94.45\n",
      "x0:399.344998766,x1:415.0415\n",
      "y0:282.236642,y1:370.11962600000004\n",
      "------------------\n",
      "HHA\n",
      "85.81\n",
      "89.39\n",
      "91.79\n",
      "94.15\n",
      "94.20\n",
      "93.69\n",
      "93.77\n",
      "93.33\n",
      "95.35\n",
      "92.63\n",
      "x0:426.992,x1:443.88149999999996\n",
      "y0:282.236642,y1:370.11962600000004\n",
      "------------------\n",
      "hHLD\n",
      "92.01\n",
      "92.90\n",
      "94.91\n",
      "95.63\n",
      "95.28\n",
      "95.67\n",
      "95.67\n",
      "96.02\n",
      "94.32\n",
      "95.75\n",
      "x0:457.041,x1:474.85957\n",
      "y0:282.236642,y1:370.11962600000004\n",
      "------------------\n",
      "Context\n",
      "x0:337.76000000000005,x1:359.74905687\n",
      "y0:362.336642,y1:370.119626\n",
      "------------------\n",
      "0\n",
      "8\n",
      "16\n",
      "32\n",
      "48\n",
      "64\n",
      "80\n",
      "96\n",
      "112\n",
      "128\n",
      "x0:343.52,x1:353.981\n",
      "y0:282.236642,y1:361.74962600000003\n",
      "------------------\n",
      "69.10\n",
      "81.58\n",
      "86.80\n",
      "72.32\n",
      "75.77\n",
      "76.14\n",
      "75.43\n",
      "79.15\n",
      "81.71\n",
      "75.25\n",
      "x0:371.7,x1:387.3915\n",
      "y0:282.236642,y1:361.74962600000003\n",
      "------------------\n",
      "で IoU と再現率の最大値 79.21% と 88.45% が得られ，\n",
      "夜では一つの目安となる再現率 95% の水準をとるとモ\n",
      "デル wHLD/112 で IoU の最大値 86.54% が得られ，こ\n",
      "れらを最適モデルと考える．夜ではモデル hHLD/112\n",
      "が IoU87.44% を得るが再現率不足で除外した．一方，\n",
      "コンテキスト拡張のデメリットは誤検出画素の増加で\n",
      "ある．夜間テストデータの誤検出の指標 FPR = FP\n",
      "FP+TN\n",
      "を示した図 10 から確認できる．FP は IoU の分母に現\n",
      "れるので拡張で IoU が単調増加するわけではなく，図\n",
      "8 と図 9 は IoU が飽和する傾向を示している．\n",
      "x0:308.9799999999999,x1:541.8110948280001\n",
      "y0:124.34977399999997,y1:270.66889799999996\n",
      "------------------\n",
      "提案手法の結果を，学習を使わず観測値から路面陥\n",
      "没部を凹型障害物として検出する文献(6)の LiDAR を\n",
      "用いる手法と比較する．陥没部は前述の標高 e を用い\n",
      "x0:308.97999999999996,x1:535.7562991719999\n",
      "y0:79.50977399999995,y1:121.22889799999996\n",
      "-------pages---------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      "∗\n",
      "DPT HHA\n",
      "x0:165.19,x1:205.2705\n",
      "y0:753.486642,y1:766.382035\n",
      "------------------\n",
      "20.0\n",
      "x0:115.79,x1:127.9945\n",
      "y0:758.216642,y1:765.999626\n",
      "------------------\n",
      "hHLD wHLD\n",
      "x0:212.76,x1:256.296798\n",
      "y0:753.6366419999999,y1:761.519626\n",
      "------------------\n",
      "IR\n",
      "x0:145.62,x1:152.594\n",
      "y0:753.686642,y1:761.4696260000001\n",
      "------------------\n",
      "FPRintestdata[%]\n",
      "x0:94.780374,x1:102.56335800000001\n",
      "y0:692.96,y1:749.518596\n",
      "------------------\n",
      "15.0\n",
      "x0:115.79,x1:127.9945\n",
      "y0:737.816642,y1:745.5996260000001\n",
      "------------------\n",
      "10.0\n",
      "x0:115.79,x1:127.9945\n",
      "y0:717.406642,y1:725.1896260000001\n",
      "------------------\n",
      "5.0\n",
      "x0:117.53,x1:126.2475\n",
      "y0:696.9966420000001,y1:704.7796260000001\n",
      "------------------\n",
      "0.0\n",
      "x0:117.53,x1:126.2475\n",
      "y0:676.5866420000001,y1:684.3696260000002\n",
      "------------------\n",
      "96\n",
      "x0:224.98000000000002,x1:231.954\n",
      "y0:672.076642,y1:679.859626\n",
      "------------------\n",
      "0\n",
      "x0:131.49,x1:134.977\n",
      "y0:672.046642,y1:679.8296260000001\n",
      "------------------\n",
      "32\n",
      "x0:161.490006982,x1:168.464006982\n",
      "y0:672.046642,y1:679.8296260000001\n",
      "------------------\n",
      "64\n",
      "x0:193.24001373200002,x1:200.214013732\n",
      "y0:672.046642,y1:679.8296260000001\n",
      "------------------\n",
      "128\n",
      "x0:254.99,x1:265.451\n",
      "y0:672.046642,y1:679.8296260000001\n",
      "------------------\n",
      "Context augmentation\n",
      "x0:165.88,x1:227.564456\n",
      "y0:663.686642,y1:671.4696260000001\n",
      "------------------\n",
      "Fig. 10 Nighttime test FPR of negative obstacles.\n",
      "x0:76.99,x1:280.175632926\n",
      "y0:639.208029,y1:650.326737\n",
      "------------------\n",
      "て e < −a を満たす画素で切り出せて，オープニング\n",
      "処理後に輪郭線を求める（a = 0.07m）．輪郭は陥没前\n",
      "後のエッジを含むので，輪郭の画素から画像上の各列\n",
      "で最も下の 1 画素だけを集めて，手前のエッジの予測\n",
      "値とする．比較のため最適モデルと同じ膨張処理を行\n",
      "い同じラベル画像で精度を求めた．昼では IoU62.60%\n",
      "と再現率 85.18%，夜では IoU61.26% と再現率 86.52%\n",
      "となり，昼夜とも提案手法が IoU と再現率で上回る．\n",
      "x0:65.19999999999999,x1:295.9040000000001\n",
      "y0:506.1097739999998,y1:630.305805\n",
      "------------------\n",
      "Table 5 Performance gap between day and night.\n",
      "x0:77.8600000000001,x1:279.31137196300006\n",
      "y0:492.09802899999977,y1:503.21673699999997\n",
      "------------------\n",
      "IoU\n",
      "x0:144.52,x1:155.36457\n",
      "y0:484.016642,y1:491.799626\n",
      "------------------\n",
      "Recall\n",
      "x0:228.48,x1:246.29856999999998\n",
      "y0:484.016642,y1:491.799626\n",
      "------------------\n",
      "Day\n",
      "x0:122.27,x1:133.88868399999998\n",
      "y0:475.64664200000004,y1:483.42962600000004\n",
      "------------------\n",
      "Night\n",
      "x0:163.859985998,x1:179.746757998\n",
      "y0:475.64664200000004,y1:483.42962600000004\n",
      "------------------\n",
      "Day\n",
      "x0:209.72,x1:221.338684\n",
      "y0:475.64664200000004,y1:483.42962600000004\n",
      "------------------\n",
      "Night\n",
      "x0:251.299985282,x1:267.18675728200003\n",
      "y0:475.64664200000004,y1:483.42962600000004\n",
      "------------------\n",
      "wHLD/128\n",
      "x0:112.2,x1:143.96657\n",
      "y0:467.676642,y1:475.459626\n",
      "------------------\n",
      "wHLD/112\n",
      "x0:155.91997113000002,x1:187.68654113\n",
      "y0:467.676642,y1:475.459626\n",
      "------------------\n",
      "wHLD/128\n",
      "x0:199.64,x1:231.40657\n",
      "y0:467.676642,y1:475.459626\n",
      "------------------\n",
      "wHLD/112\n",
      "x0:243.35997113,x1:275.12654113\n",
      "y0:467.676642,y1:475.459626\n",
      "------------------\n",
      "Model\n",
      "SW\n",
      "PSG\n",
      "TCE\n",
      "Total\n",
      "x0:82.03999999999999,x1:100.24911399999999\n",
      "y0:435.396642,y1:475.459626\n",
      "------------------\n",
      "78.30\n",
      "80.89\n",
      "78.14\n",
      "79.21\n",
      "x0:120.24,x1:135.9315\n",
      "y0:435.39664200000004,y1:467.089626\n",
      "------------------\n",
      "84.91\n",
      "87.03\n",
      "87.65\n",
      "86.54\n",
      "x0:163.960006,x1:179.65150599999998\n",
      "y0:435.39664200000004,y1:467.089626\n",
      "------------------\n",
      "97.16\n",
      "88.11\n",
      "85.21\n",
      "88.45\n",
      "x0:207.68,x1:223.3715\n",
      "y0:435.39664200000004,y1:467.089626\n",
      "------------------\n",
      "94.62\n",
      "95.04\n",
      "98.98\n",
      "95.85\n",
      "x0:251.40000600000002,x1:267.09150600000004\n",
      "y0:435.39664200000004,y1:467.089626\n",
      "------------------\n",
      "(a) TCE daytime wHLD/128\n",
      "x0:82.81,x1:163.18529800000002\n",
      "y0:331.696642,y1:339.479626\n",
      "------------------\n",
      "(b) TCE nighttime wHLD/112\n",
      "x0:191.649999804,x1:276.683953908\n",
      "y0:331.696642,y1:339.479626\n",
      "------------------\n",
      "Fig. 11 Day/night TCE qualitative results.\n",
      "x0:91.28,x1:265.891518074\n",
      "y0:312.798029,y1:323.91673699999996\n",
      "------------------\n",
      "(a) SW nighttime wHLD/112\n",
      "x0:82.03,x1:163.967386\n",
      "y0:204.00664199999997,y1:211.789626\n",
      "------------------\n",
      "(b) PSG nighttime wHLD/112\n",
      "x0:191.839890594,x1:276.49027469799995\n",
      "y0:204.00664199999997,y1:211.78962599999997\n",
      "------------------\n",
      "Fig. 12 Nighttime wHLD/112 qualitative results.\n",
      "x0:77.719,x1:279.449804074\n",
      "y0:185.108029,y1:196.22673699999999\n",
      "------------------\n",
      "次に上記の昼夜の精度差の原因を調べるため，最適\n",
      "モデルの環境別の IoU と再現率を表 5 に示す．テラス\n",
      "環境（TCE）で差が大きいので，テラス環境のほぼ同\n",
      "じシーンから昼夜で取得したテストデータで定性的評\n",
      "価を行い，結果を図 11 に示す．正解（true positive），\n",
      "誤検出（false positive），失報（false negative）をそれ\n",
      "x0:65.199,x1:298.038376492\n",
      "y0:82.56977399999998,y1:169.11889799999997\n",
      "------------------\n",
      "(a) TCE nighttime wHLD/112\n",
      "x0:323.02,x1:407.66338600000006\n",
      "y0:680.2666419999999,y1:688.049626\n",
      "------------------\n",
      "(b) SW nighttime wHLD/112\n",
      "x0:436.779989428,x1:519.1080594279999\n",
      "y0:680.2666419999999,y1:688.049626\n",
      "------------------\n",
      "(c) PSG nighttime wHLD/112\n",
      "x0:323.21,x1:407.470386\n",
      "y0:586.436642,y1:594.2196260000001\n",
      "------------------\n",
      "(d) PSG nighttime wHLD/112 at 3m\n",
      "x0:426.899991844,x1:528.992377844\n",
      "y0:586.436642,y1:594.2196260000001\n",
      "------------------\n",
      "Fig. 13 Nighttime wHLD/112 detection results.\n",
      "x0:324.07,x1:520.6598861110001\n",
      "y0:567.538029,y1:578.656737\n",
      "------------------\n",
      "ぞれ青，緑，赤で表し，収縮処理しない予測結果を，モ\n",
      "デルに入力する wHLD ではなく視認のために IR に重\n",
      "ねて表示する．下り階段の落ち口をアノテーションし\n",
      "ているが，昼は反射性の高いタイル路面で直射日光に\n",
      "よりデプス情報が不確かになる．wHLD がその影響を\n",
      "受けたとみてよい．タイル路面は歩道環境に少し，通\n",
      "路環境に一部，テラス環境に最も多く現れる．昼デー\n",
      "タは太陽の南中高度が高い５，６月に取得している．\n",
      "夜間最適モデル wHLD/112 の歩道段差，通路側溝の\n",
      "テストデータの結果を図 12 に示す．図 11(b) を含め\n",
      "てコンテキストの予測が確認できる．青＋緑の画素を\n",
      "菱形カーネル，回数 96 で収縮処理した検出結果を図\n",
      "13(a) から (c) に示す．再現率 95% を満たすので収縮\n",
      "後も障害物を捕捉できている．ただし過大なコンテキ\n",
      "ストは画像端を塗り潰して収縮に影響するので，拡張\n",
      "の 0 から 128 の範囲はこれを考慮して決定している．\n",
      "処理時間を評価する．移動速度 4.0km/h では 3m 先\n",
      "の障害物の衝突時間余裕は 2.7s ある．図 13(d) は 3m\n",
      "先の段差の検出例を表す．予測と画像化を含む処理は\n",
      "CPU が Core i7-8700@3.20GHz で GeForce GTX1080\n",
      "メモリ 8GB のラップトップ PC 上で約 5Hz で実行さ\n",
      "れ，余裕はある．処理時間は 95 パーセンタイル値で\n",
      "予測 0.166s，wHLD 画像化 0.053s である．\n",
      "x0:308.9799999999999,x1:539.798\n",
      "y0:210.2797740000001,y1:550.8688980000001\n",
      "------------------\n",
      "最後にモデル wHLD/112 の過学習の有無を調べるた\n",
      "め，訓練中の訓練／検証データの IoU の推移を図 14\n",
      "に表す．訓練と検証で精度の乖離は大きくなく，過学\n",
      "習・未学習の可能性が低いことを示す．エポック数 80\n",
      "はこの結果から決定している．\n",
      "5·3 考察\n",
      "日中と比較して夜間データは季節や\n",
      "天候の影響が小さく，モデル wHLD/112 の性能は夜間\n",
      "使用で安定的である．前述したように夜間の有用性は\n",
      "高く，モデル wHLD/112 は夜間使用の条件で有効であ\n",
      "x0:308.98000000000013,x1:535.7531708980001\n",
      "y0:75.77977400000012,y1:207.1588980000001\n",
      "-------pages---------\n",
      "------------------\n",
      "100.0\n",
      "x0:117.59,x1:133.2815\n",
      "y0:758.7866419999999,y1:766.569626\n",
      "------------------\n",
      "Training/ValidationIoU[%]\n",
      "x0:99.530374,x1:107.313358\n",
      "y0:683.04,y1:765.695995948\n",
      "------------------\n",
      "80.0\n",
      "x0:119.34,x1:131.5445\n",
      "y0:743.486642,y1:751.269626\n",
      "------------------\n",
      "60.0\n",
      "x0:119.34,x1:131.5445\n",
      "y0:728.176642,y1:735.9596260000001\n",
      "------------------\n",
      "40.0\n",
      "x0:119.34,x1:131.5445\n",
      "y0:712.8666420000001,y1:720.6496260000001\n",
      "------------------\n",
      "20.0\n",
      "x0:119.34,x1:131.5445\n",
      "y0:697.5666420000001,y1:705.3496260000002\n",
      "------------------\n",
      "Training Validation\n",
      "x0:187.95,x1:248.190030312\n",
      "y0:689.9066419999999,y1:698.399626\n",
      "------------------\n",
      "0.0\n",
      "x0:121.08,x1:129.7975\n",
      "y0:682.2566420000002,y1:690.0396260000002\n",
      "------------------\n",
      "25\n",
      "x0:169.360005198,x1:176.334005198\n",
      "y0:678.0066419999999,y1:685.789626\n",
      "------------------\n",
      "50\n",
      "x0:206.130008732,x1:213.10400873199998\n",
      "y0:678.0066419999999,y1:685.789626\n",
      "------------------\n",
      "75 80\n",
      "x0:242.91001298199998,x1:258.595013214\n",
      "y0:678.0066419999999,y1:685.789626\n",
      "------------------\n",
      "0\n",
      "x0:134.32,x1:137.807\n",
      "y0:678.0066419999999,y1:685.789626\n",
      "------------------\n",
      "Epoch\n",
      "x0:186.68,x1:204.49857\n",
      "y0:670.206642,y1:677.989626\n",
      "------------------\n",
      "Fig. 14 Nighttime wHLD/112 training/validation IoU.\n",
      "x0:67.13,x1:290.04240992599995\n",
      "y0:646.008029,y1:657.1267369999999\n",
      "------------------\n",
      "ると判断し，屋外データでのデプス情報の有効性と新\n",
      "たな画像化手法の優位性が確認できたと考える．\n",
      "x0:65.19999999999999,x1:291.9664064140002\n",
      "y0:602.5797739999998,y1:629.348898\n",
      "------------------\n",
      "手法の比較結果については，デプスカメラの情報は\n",
      "LiDAR と比べて密ではあるが不確かさを多く含み，標\n",
      "高だけで求めた陥没部はその影響を受ける．一方，提\n",
      "案手法は複数の情報を含んだ画像化，コンテキストの\n",
      "利用で影響を緩和できたと考察する．加えて図 1 で指\n",
      "摘した到達可能性の条件が陥没という幾何学的条件に\n",
      "は含まれていないことも要因の一つと考える．\n",
      "x0:65.19999999999996,x1:291.976996758\n",
      "y0:497.9697739999996,y1:599.4588979999999\n",
      "------------------\n",
      "6. 結論と今後の課題\n",
      "x0:132.25999999999996,x1:224.898\n",
      "y0:475.26219399999957,y1:488.07082399999956\n",
      "------------------\n",
      "デプスカメラを用いた画素レベル凹型障害物検出手\n",
      "法を提案した．二値分類モデルを学習して画像セグメ\n",
      "ンテーションにより予測する．アノテーションに障害\n",
      "物とその周辺情報を含んだコンテキスト拡張を導入し，\n",
      "新たなデプス情報画像化手法を提案する．日中と夜間\n",
      "データで学習して定量的評価を行い，最適なコンテキ\n",
      "スト拡張と画像化の組合せによるモデルを求めた．夜\n",
      "間使用の条件で IoU86.54% と再現率 95% を達成し，\n",
      "提案手法の有効性と画像化の優位性が確認できた．\n",
      "x0:65.19999999999997,x1:298.03436358600004\n",
      "y0:335.8297739999996,y1:467.2088979999995\n",
      "------------------\n",
      "昼データの精度向上にはカメラの調整に加えて，昼\n",
      "x0:74.77999999999999,x1:291.9699636560001\n",
      "y0:320.8797739999996,y1:332.7088979999996\n",
      "------------------\n",
      "夜の変化の影響が小さい画像化手法にも可能性がある．\n",
      "通常の障害物検出も含むより完全なシステムへの拡張\n",
      "は，提案手法のカメラやソフトウェアと近いものを用\n",
      "いる文献(16)の手法との組合せが一つの手段である．\n",
      "x0:65.19999999999999,x1:298.03436358600004\n",
      "y0:261.1097739999996,y1:317.7688979999996\n",
      "------------------\n",
      "参 考 文 献\n",
      "x0:152.34,x1:204.82408948799997\n",
      "y0:238.36181199999962,y1:248.8189479999996\n",
      "------------------\n",
      "(1) N. Heckman, J. F. Lalonde, N. Vandapel, and M. Hebert,\n",
      "“Potential negative obstacle detection by occlusion\n",
      "labeling”, Proc. IEEE/RSJ Int. Conf. on Intelligent Robots\n",
      "and Systems, (2007), pp.2168–2173.\n",
      "x0:69.68,x1:291.95669775600004\n",
      "y0:182.86437799999962,y1:228.7404339999996\n",
      "------------------\n",
      "(2) A. Murarka and B. Kuipers, “A stereo vision based\n",
      "mapping algorithm for detecting inclines, drop-offs, and\n",
      "obstacles for safe local navigation”, Proc. IEEE/RSJ Int.\n",
      "Conf. on Intel. Robots and Sys., (2009), pp.1646–1653.\n",
      "x0:69.68,x1:291.95776586399995\n",
      "y0:131.06437799999964,y1:176.9304339999996\n",
      "------------------\n",
      "(3) J. Larson and M. Trivedi, “Lidar based off-road negative\n",
      "obstacle detection and analysis”, Proc. IEEE Int. Conf. on\n",
      "Intelligent Transportation Systems, (2011), pp.192–197.\n",
      "x0:69.67999999999999,x1:291.9656816880001\n",
      "y0:91.21437799999961,y1:125.13043399999962\n",
      "------------------\n",
      "(4) R. D. Morton, and E. Olson, “Positive and negative\n",
      "obstacle detection using the HLD classiﬁer”, Proc.\n",
      "IEEE/RSJ Int. Conf. on Intelligent Robots and Systems,\n",
      "(2011), pp.1579–1584.\n",
      "x0:313.46,x1:535.7515\n",
      "y0:725.5743779999996,y1:771.4504339999996\n",
      "------------------\n",
      "(5) E. Shang, X. An, J. Li, and H. He, “A novel setup\n",
      "method of 3d lidar for negative obstacle detection in\n",
      "ﬁeld environment”, Proc. IEEE Int. Conf. on Intelligent\n",
      "Transportation Systems, (2014), pp.1436–1441.\n",
      "x0:313.46,x1:535.74547083\n",
      "y0:673.7743779999994,y1:719.6404339999995\n",
      "------------------\n",
      "(6) L. Chen, J. Yang, and H. Kong, “Lidar-histogram for fast\n",
      "road and obstacle detection”, Proc. IEEE Int. Conf. on\n",
      "Robotics and Automation, (2017), pp.1343–1348.\n",
      "x0:313.46,x1:535.7456368580002\n",
      "y0:633.9243779999993,y1:667.8404339999993\n",
      "------------------\n",
      "(7) L. Keselman,\n",
      "x0:313.46,x1:382.11320892599997\n",
      "y0:617.9743779999992,y1:627.9804339999991\n",
      "------------------\n",
      "J.\n",
      "x0:391.070207062,x1:396.7994810619999\n",
      "y0:617.9743779999992,y1:627.9804339999991\n",
      "------------------\n",
      "I. Woodﬁll, A. G.-Jepsen,\n",
      "x0:404.420581062,x1:513.8237937560001\n",
      "y0:617.9743779999992,y1:627.9804339999991\n",
      "------------------\n",
      "and\n",
      "A. Bhowmik, “Intel realsense stereoscopic depth cam-\n",
      "eras”, Proc. IEEE Conf. on Computer Vision and Pattern\n",
      "Recognition Workshops, (2017), pp.1–10.\n",
      "x0:328.9,x1:535.7443151699999\n",
      "y0:582.1143779999991,y1:627.9804339999991\n",
      "------------------\n",
      "(8) R. Mottaghi, X. Chen, X. Liu, N. G. Cho, S. W. Lee,\n",
      "S. Fidler, R. Urtasun and A. Yuille, “The role of context\n",
      "for object detection and semantic segmentation in the\n",
      "wild”, Proc. IEEE Conf. on Computer Vision and Pattern\n",
      "Recognition, (2014), pp.891–898.\n",
      "x0:313.46,x1:535.75010917\n",
      "y0:518.3543779999989,y1:576.180433999999\n",
      "------------------\n",
      "(9) J. Long, E. Shelhamer, and T. Darrell, “Fully con-\n",
      "volutional networks for semantic segmentation”, Proc.\n",
      "IEEE Conf. on Computer Vision and Pattern Recognition,\n",
      "(2015), pp.3431–3440.\n",
      "x0:313.46,x1:535.7515\n",
      "y0:466.54437799999886,y1:512.4204339999989\n",
      "------------------\n",
      "(10) K. He, X. Zhang, S. Ren, and J. Sun, “Deep residual\n",
      "learning for\n",
      "image recognition”, Proc. EEE Conf.\n",
      "on Computer Vision and Pattern Recognition, (2016),\n",
      "pp.770–778.\n",
      "x0:308.97999999999996,x1:535.7489567619999\n",
      "y0:414.7443779999989,y1:460.61043399999886\n",
      "------------------\n",
      "(11) E. Romera, J. M. Alvarez, L. M. Bergasa, and R. Arroyo,\n",
      "“Efﬁcient convnet for real-time semantic segmentation”,\n",
      "Proc. IEEE Intel. Vehicles Symp., (2017), pp.1789–1794.\n",
      "x0:308.97999999999996,x1:535.745593102\n",
      "y0:374.89437799999894,y1:408.8104339999989\n",
      "------------------\n",
      "(12) E. Romera, J. M. Alvarez, L. M. Bergasa, and R. Arroyo,\n",
      "”Erfnet: Efﬁcient residual factorized convnet for real-\n",
      "time semantic segmentation”, IEEE Trans. on Intel. Trans.\n",
      "Systems, Vol.19, No.1 (2018), pp.263–272.\n",
      "x0:308.98,x1:535.752617932\n",
      "y0:323.084377999999,y1:368.96043399999894\n",
      "------------------\n",
      "(13) S. Gupta, R. Girshick, P. Arbelaez, and J. Malik,\n",
      "“Learning rich features from RGB-D images for object\n",
      "detection and segmentation”, Proc. European Conf. on\n",
      "Computer Vision, (2014), pp.345-360.\n",
      "x0:308.98,x1:535.737858\n",
      "y0:271.28437799999904,y1:317.150433999999\n",
      "------------------\n",
      "(14) A. Eitel, J. T. Springenberg, L. Spinello, M. Riedmiller,\n",
      "and W. Burgard, “Multimodal deep learning for robust\n",
      "rgb-d object recognition”, Proc. IEEE/RSJ Int. Conf. on\n",
      "Intelligent Robots and Systems, (2015), pp.681–687.\n",
      "x0:308.98,x1:535.7456379320001\n",
      "y0:219.4743779999991,y1:265.34043399999905\n",
      "------------------\n",
      "(15) L. Bo, X. Ren, and D. Fox, “Unsupervised feature learning\n",
      "recognition”, Experimental\n",
      "x0:308.98,x1:535.748808\n",
      "y0:191.5743779999991,y1:213.5404339999991\n",
      "------------------\n",
      "for RGB-D based object\n",
      "Robotics, Springer, Heidelberg, (2013), pp.387–402.\n",
      "x0:328.90000000000003,x1:517.1321860680001\n",
      "y0:179.6243779999991,y1:201.58043399999906\n",
      "------------------\n",
      "(16) K. Yang, et al, “Unifying terrain awareness for the visually\n",
      "impaired through real-time semantic segmentation”,\n",
      "Sensors, Vol.18, No.5, 1506 (2018), n.p.\n",
      "x0:308.9800000000001,x1:535.7456200000001\n",
      "y0:139.7743779999991,y1:173.69043399999907\n",
      "------------------\n",
      "(17) D. Eigen, and R. Fergus, “Predicting depth, surface\n",
      "normals and semantic labels with a common multi-scale\n",
      "convolutional architecture”, Proc. IEEE Int. Conf. on\n",
      "Computer Vision, (2015), pp.2650–2658.\n",
      "x0:308.9800000000001,x1:535.7455525540003\n",
      "y0:87.96437799999909,y1:133.8404339999991\n",
      "-------pages---------\n"
     ]
    }
   ],
   "source": [
    "with open(file_path, \"rb\") as f:\n",
    "    for page in PDFPage.get_pages(f):\n",
    "        interpreter.process_page(page)  # ページを処理する。\n",
    "        layout = device.get_result()  # LTPageオブジェクトを取得。\n",
    "        text_boxes = find_textboxes_recursively(layout)      \n",
    "\n",
    "        # text_boxの座標値毎にソート，複数キーのソート\n",
    "        #text_boxes.sort(key=lambda text_box: (-text_box.y1, text_box.x0))  # y1がy座標，x0がx座標らしい(画像座標なので，y1を負に)\n",
    "        #text_boxes.sort(key=lambda text_box: (text_box.x0, -text_box.y1)) # 正直二段組のデータでの取得は難しく，ある程度1段踏み前提\n",
    "        \n",
    "        # 二段組のソート\n",
    "        sort2column = Sort2Column(layout_x0=layout.x0, layout_x1=layout.x1)\n",
    "        text_boxes.sort(key=sort2column)\n",
    "        for box in text_boxes:\n",
    "            print(\"------------------\")\n",
    "            print(box.get_text().strip())  # 末尾の文字を削除\n",
    "            print(\"x0:{},x1:{}\".format(box.x0, box.x1))\n",
    "            print(\"y0:{},y1:{}\".format(box.y0, box.y1))\n",
    "            \n",
    "        print(\"-------pages---------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### documentオブジェクトを利用する場合 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdf_py37",
   "language": "python",
   "name": "pdf_py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
