{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-08T16:37:54.208522Z",
     "start_time": "2020-05-08T16:37:50.990231Z"
    }
   },
   "outputs": [],
   "source": [
    "from pdfminer.converter import PDFPageAggregator\n",
    "from pdfminer.layout import LAParams, LTContainer, LTTextBox\n",
    "from pdfminer.pdfinterp import PDFPageInterpreter, PDFResourceManager\n",
    "from pdfminer.pdfpage import PDFPage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-08T16:37:54.728131Z",
     "start_time": "2020-05-08T16:37:54.220491Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "from collections import OrderedDict\n",
    "from tqdm.notebook import tqdm\n",
    "import pprint\n",
    "import json\n",
    "import abc\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LayoutオブジェクトからLTTextBoxのリストを取得する関数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "抜き出すのは，textデータを前提とするのでこの関数が必要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-08T16:37:54.769024Z",
     "start_time": "2020-05-08T16:37:54.741098Z"
    }
   },
   "outputs": [],
   "source": [
    "def find_textboxes_recursively(layout):\n",
    "    \"\"\"\n",
    "    再帰的にテキストボックス（LTTextBox）を探して、テキストボックスのリストを取得する。\n",
    "    \"\"\"\n",
    "    # LTTextBoxを継承するオブジェクトの場合は1要素のリストを返す。\n",
    "    if isinstance(layout, LTTextBox):\n",
    "        text_boxes = [layout]\n",
    "        return text_boxes  # 返すのはリスト\n",
    "\n",
    "    # LTContainerを継承するオブジェクトは子要素を含むので、再帰的に探す。\n",
    "    if isinstance(layout, LTContainer):\n",
    "        text_boxes = []\n",
    "        for child in layout:\n",
    "            text_boxes.extend(find_textboxes_recursively(child))  # 再帰的にリストをextend\n",
    "            \n",
    "        return text_boxes\n",
    "\n",
    "    return []  # 何も取得できなかった場合は空リストを返す"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ソート用の関数 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "textboxのソートは，1段組みと2段組みで異なる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 二段組用のソート "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-08T16:37:54.819888Z",
     "start_time": "2020-05-08T16:37:54.782986Z"
    }
   },
   "outputs": [],
   "source": [
    "class SortTextbox2Column():\n",
    "    \"\"\"\n",
    "    2段組み用，始めのソートは左側と右側\n",
    "    \"\"\"\n",
    "    def __init__(self, layout_x0, layout_x1):\n",
    "        self.half_x = (layout_x0 + layout_x1)/2\n",
    "    \n",
    "    def __call__(self, text_box):\n",
    "        if text_box.x0 < self.half_x:\n",
    "            left_or_right = -1  # it mean left\n",
    "            \n",
    "        else:\n",
    "            left_or_right = 1  # it mean right\n",
    "            \n",
    "        return (left_or_right, -text_box.y1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1段組み用のソート "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-08T16:37:54.853797Z",
     "start_time": "2020-05-08T16:37:54.832853Z"
    }
   },
   "outputs": [],
   "source": [
    "class SortTextbox():\n",
    "    \"\"\"\n",
    "    textboxの左下の座標でソート\n",
    "    \"\"\"\n",
    "    def __init__(self,*args):\n",
    "        \"\"\"\n",
    "        2段組み用のソートクラスとの対応のため\n",
    "        \"\"\"\n",
    "        pass\n",
    "    def __call__(self, text_box):\n",
    "        return (-text_boxt.y1, text_box.x0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 論文データのベースクラス "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pdfデータをパースして保存するときと，呼び出すときに利用する？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-08T16:37:55.031688Z",
     "start_time": "2020-05-08T16:37:54.869837Z"
    }
   },
   "outputs": [],
   "source": [
    "class PaperBase(metaclass=abc.ABCMeta):\n",
    "    \"\"\"\n",
    "    論文のデータクラスとPaser用のストラテジーを一つにしたもの.正直一つにする意味はない.\n",
    "    ただ変更するクラスをまとめただけ\n",
    "    \n",
    "    \"\"\"\n",
    "    @abc.abstractmethod\n",
    "    def toDict(self):\n",
    "        pass\n",
    "    \n",
    "    @classmethod\n",
    "    def parse_by_textboxes(cls, text_boxes, parse_info):\n",
    "        \"\"\"\n",
    "        text_boxesからパースする\n",
    "        \"\"\"\n",
    "        paper_title, parse_text_dict = cls.str_from_textboxes(text_boxes, parse_info)  # スタティクメソッド\n",
    "        paper = cls.parse_by_text_dict(paper_title=paper_title, \n",
    "                                       parse_text_dict=parse_text_dict, \n",
    "                                       parse_info=parse_info)  # クラスメソッド\n",
    "        \n",
    "        return paper\n",
    "    \n",
    "    @classmethod\n",
    "    def parse_by_text_dict(cls, paper_title, parse_text_dict, parse_info):\n",
    "        raise NotImplementedError(\"Implement parse_by_text_dict\")\n",
    "        \n",
    "        \n",
    "    @classmethod\n",
    "    def parse_by_dict(cls, content):\n",
    "        raise NotImplementedError(\"Implement parse_by_content\")\n",
    "        \n",
    "    @staticmethod\n",
    "    def str_from_textboxes(text_boxes, parse_info):\n",
    "        \"\"\"\n",
    "        共通するテキスト取得プログラム\n",
    "        \"\"\"\n",
    "        #parse_text_flag = False  # このフラッグがTrueである部分を保存する        \n",
    "         \n",
    "        patterns_keys = parse_info[\"start_patterns\"].keys()  # キーのリスト(のようなもの)\n",
    "        \n",
    "        #patterns_key_iter = iter(patterns_keys)  # 長さの違うfor文内で回すので，キーをイテレーター化\n",
    "        #pattern_key = next(patterns_key_iter)  # 最初のキーを取得\n",
    "        \n",
    "        parse_text_dict = {i:\"\" for i in patterns_keys}\n",
    "        parse_text_flag_dict = {i:False for i in patterns_keys}  # このフラッグがTrueであるときに保存する\n",
    "        parse_text_started = {i:False for i in patterns_keys}  # マッチングがスタートしたらTrueになる(何度もマッチングがスタートしないように)\n",
    "        \n",
    "        for i,box in enumerate(text_boxes):\n",
    "            text = box.get_text().strip()  # 末尾の文字を削除\n",
    "            if i == parse_info[\"title_position_number\"]:\n",
    "                paper_title = text\n",
    "            \n",
    "            for pattern_key in patterns_keys:                    \n",
    "                    \n",
    "                if parse_info[\"end_patterns\"][pattern_key] is not None: # Noneなら，最後までTrue\n",
    "                    if parse_info[\"end_patterns\"][pattern_key].search(text):\n",
    "                        parse_text_flag_dict[pattern_key] = False\n",
    "                        if set(parse_text_flag_dict.values()) == {False} and set(parse_text_started.values()) == {True}:  # parse_text_flag_dictが全てFalseに\n",
    "                            break  # すでにパターンが全てスタートし，全てエンドした場合\n",
    "                        \n",
    "                if parse_text_flag_dict[pattern_key]: \n",
    "                    parse_text_dict[pattern_key] += text  # flagがTrueのとき，保存\n",
    "                    \n",
    "                if parse_info[\"start_patterns\"][pattern_key].search(text) and not parse_text_started[pattern_key]:# マッチしたらフラッグをTrueに\n",
    "                    parse_text_flag_dict[pattern_key] = True\n",
    "                    parse_text_started[pattern_key] = True  # マッチングがスタートしたかどうか\n",
    "            else:\n",
    "                continue\n",
    "            break  # 多重ループから抜ける\n",
    "                    \n",
    "        return paper_title, parse_text_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### セーブデータ保存用の Paperクラス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-08T16:37:55.100654Z",
     "start_time": "2020-05-08T16:37:55.054666Z"
    }
   },
   "outputs": [],
   "source": [
    "class PaperForSave(PaperBase):\n",
    "    \"\"\"\n",
    "    論文をテキストデータとして，保存するための論文データクラス\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 conf_name=None, \n",
    "                 pdf_name=None, \n",
    "                 paper_title=None, \n",
    "                 pdf_content=None,\n",
    "                 date=None\n",
    "                 \n",
    "                ):\n",
    "        \"\"\"\n",
    "        一つのデータで\n",
    "        Parameters\n",
    "        ----------\n",
    "        conf_name: str\n",
    "            学会や論文集を表す文字列\n",
    "        pdf_name: str\n",
    "            対応するpdfファイルの名前を表す文字列\n",
    "        paper_title: str\n",
    "            論文のタイトル\n",
    "        pdf_content: dict\n",
    "            保存するテキストのdictionaly\n",
    "        \"\"\"\n",
    "        self.conf_name = conf_name\n",
    "        self.pdf_name = pdf_name\n",
    "        self.paper_title = paper_title\n",
    "        self.pdf_content = pdf_content\n",
    "        self.date = date\n",
    "        \n",
    "    def toDict(self):\n",
    "        out_dict = {\"pdf_name\": self.pdf_name,\n",
    "                    \"paper_title\": self.paper_title,\n",
    "                    \"content\":self.pdf_content,\n",
    "                    \"date\":str(self.date),\n",
    "                    \"conf_name\": self.conf_name\n",
    "                   }\n",
    "        return out_dict\n",
    "    \n",
    "    @classmethod\n",
    "    def parse_by_text_dict(cls, paper_title, parse_text_dict, parse_info):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        text_boxes: list of textbox\n",
    "            pdfをパースしたときに得られるtextboxのリスト\n",
    "        start_patterns\n",
    "        \"\"\"\n",
    "        #from IPython.core.debugger import Pdb; Pdb().set_trace()  # PaperForSave\n",
    "        paper_conf_name = parse_info[\"conf_name\"]\n",
    "        paper_pdf_name = parse_info[\"pdf_name\"]\n",
    "        paper_date = parse_info[\"date\"]\n",
    "        \n",
    "        # Paperへのデータの付与\n",
    "        paper = cls(conf_name=paper_conf_name,\n",
    "                    paper_title=paper_title,\n",
    "                    pdf_name=paper_pdf_name,\n",
    "                    pdf_content=parse_text_dict,\n",
    "                    date=paper_date\n",
    "                   )\n",
    "\n",
    "        return paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### カウント用のPaperクラス "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paperクラスの拡張は以下のように行う，初期化メソッドはデータをアトリビュートとして保持するように実装．`toDict`と`parse_by_textboxes`,`parse_by_contents`は適宜実装する．その際，Parserクラスの`parse_info`と対応するように実装する．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-08T16:37:55.225045Z",
     "start_time": "2020-05-08T16:37:55.116641Z"
    }
   },
   "outputs": [],
   "source": [
    "class PaperForCount(PaperBase):\n",
    "    def __init__(self, conf_name=None, pdf_name=None, count_patterns=[], paper_title=None, date=None):\n",
    "        \"\"\"\n",
    "        countersは保存する文字列あるいはパターンのリスト\n",
    "        \"\"\"\n",
    "        self.conf_name = conf_name\n",
    "        self.pdf_name = pdf_name\n",
    "        self.paper_title = paper_title\n",
    "        self.date = date\n",
    "        self.counters = OrderedDict()\n",
    "        for i in count_patterns:\n",
    "            self.counters[i] = 0  # パターンオブジェクトはhashableでキーにできる．まず，0に初期化\n",
    "    \n",
    "    def toDict(self):\n",
    "        counters = {i.pattern:self.counters[i] for i in self.counters.keys()}  # キーを文字列へ\n",
    "        \n",
    "        out_dict = {\n",
    "                    \"conf_name\":self.conf_name,\n",
    "                    \"pdf_name\":self.pdf_name,\n",
    "                    \"paper_title\":self.paper_title,\n",
    "                    \"counters\":counters,\n",
    "                    \"date\":str(self.date)\n",
    "                   }\n",
    "        return out_dict\n",
    "    \n",
    "    @classmethod\n",
    "    def parse_by_text_dict(cls, paper_title, parse_text_dict, parse_info):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        text_boxes: list of textbox\n",
    "            pdfをパースしたときに得られるtextboxのリスト\n",
    "        parse_info: dict \n",
    "            パースの時に必要な情報\n",
    "        \"\"\"\n",
    "        #from IPython.core.debugger import Pdb; Pdb().set_trace()  # PaperForCount\n",
    "        \n",
    "        paper_conf_name = parse_info[\"conf_name\"]\n",
    "        paper_pdf_name = parse_info[\"pdf_name\"]\n",
    "        paper_date = parse_info[\"date\"]\n",
    "                \n",
    "        # 以下Paperへのデータの付与\n",
    "        count_patterns = parse_info[\"count_patterns\"]\n",
    "        \n",
    "        paper = cls(\n",
    "                    conf_name=paper_conf_name,\n",
    "                    pdf_name=paper_pdf_name,\n",
    "                    paper_title=paper_title,\n",
    "                    count_patterns=count_patterns,\n",
    "                    date=paper_date\n",
    "                   )\n",
    "        \n",
    "        for pattern in count_patterns:\n",
    "            for text in parse_text_dict.values():\n",
    "                m = pattern.findall(text)\n",
    "                paper.counters[pattern] += len(m)\n",
    "                \n",
    "        return paper\n",
    "    \n",
    "    @classmethod\n",
    "    def parse_by_dict(cls, paper_dict, parse_info):\n",
    "        #from IPython.core.debugger import Pdb; Pdb().set_trace()  # PaperForCount\n",
    "        paper_conf_name = paper_dict[\"conf_name\"]\n",
    "        paper_title = paper_dict[\"paper_title\"]\n",
    "        paper_pdf_name = paper_dict[\"pdf_name\"]\n",
    "        paper_date = paper_dict[\"date\"]\n",
    "        parse_text_dict = paper_dict[\"contents\"]\n",
    "        \n",
    "        count_patterns = parse_infonfo[\"count_patterns\"]\n",
    "        \n",
    "        paper = cls(\n",
    "                    conf_name=paper_conf_name,\n",
    "                    pdf_name=paper_pdf_name,\n",
    "                    paper_title=paper_title,\n",
    "                    count_patterns=count_patterns,\n",
    "                    date=paper_date\n",
    "                   )\n",
    "        \n",
    "        for pattern in count_patterns:\n",
    "            for text in parse_text_dict.values():\n",
    "                m = pattern.findall(text)\n",
    "                paper.counters[pattern] += len(m)\n",
    "                \n",
    "        return paper\n",
    "    \n",
    "    def is_counted(self):\n",
    "        # 一つも含まれていないとき\n",
    "        if set(self.counters.values()) == {0}:\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "        \n",
    "    def __repr__(self):\n",
    "        str_conf_name = str(self.conf_name)\n",
    "        str_pdf_name = str(self.pdf_name)\n",
    "        str_paper_title = str(self.paper_title)\n",
    "        str_counters = str(self.counters)\n",
    "        str_date = str(self.date)\n",
    "        return str_pdf_name+\"\\n\"+str_paper_title+\"\\n\"+str_counters+\"\\n\"+str_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## あるpdfファイルをパースし，パースした内容をPaperオブジェクトで返すオブジェクト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-08T16:37:55.354818Z",
     "start_time": "2020-05-08T16:37:55.244067Z"
    }
   },
   "outputs": [],
   "source": [
    "class PdfParser():\n",
    "    def __init__(self, \n",
    "                 conference_name,\n",
    "                 start_patterns={\"all\":re.compile(\".*\")},\n",
    "                 end_patterns={\"all\":None},\n",
    "                 title_position_number=2,\n",
    "                 parse_page_numbers=[0],\n",
    "                 column_number=2,\n",
    "                 date=datetime.datetime(2000, 1, 1, 00, 00, 00),\n",
    "                 paper_data_class=PaperForSave()\n",
    "                ):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        conference_name: str\n",
    "            学会や論文集の名前\n",
    "        start_patterns: dict of patterns\n",
    "            Paperオブジェクトに保持するテキストの開始位置の辞書\n",
    "        end_patterns: dict of pattrens\n",
    "            Paperオブジェクトに保持するテキストの終了位置の辞書，Noneは最後まで\n",
    "        title_position_number: int\n",
    "            titleが与えられるtextboxのインデックス(ソート後)\n",
    "        parse_page_numbers: list of int\n",
    "            パースするページのリスト，Noneは最後まで\n",
    "        paper_data_class: Paper class\n",
    "            ペーパークラスのオブジェクトをストラテジーとして直接与える．\n",
    "        \"\"\"\n",
    "        \n",
    "        self.conference_name = conference_name\n",
    "        \n",
    "        if set(start_patterns.keys()) != set(end_patterns.keys()):\n",
    "            raise ValueError(\"start patterns and eend patterns are not correspondding\")\n",
    "        \n",
    "        self.title_position_number = title_position_number\n",
    "        self.parse_page_numbers = parse_page_numbers  \n",
    "        self.column_number = column_number\n",
    "        self.date = date\n",
    "        \n",
    "        self.paper_data_class = paper_data_class\n",
    "        \n",
    "        self.start_patterns = start_patterns\n",
    "        self.end_patterns = end_patterns\n",
    "        \n",
    "        # パースに必要なクラスの作成\n",
    "        # Layout Analysisのパラメーターを設定。縦書きの検出を有効にする。\n",
    "        laparams = LAParams(detect_vertical=True)\n",
    "\n",
    "        # 共有のリソースを管理するリソースマネージャーを作成。\n",
    "        resource_manager = PDFResourceManager(caching=False)\n",
    "\n",
    "        # ページを集めるPageAggregatorオブジェクトを作成。\n",
    "        self.device = PDFPageAggregator(resource_manager, laparams=laparams)\n",
    "\n",
    "        # Interpreterオブジェクトを作成。\n",
    "        self.interpreter = PDFPageInterpreter(resource_manager, self.device)\n",
    "        \n",
    "        if column_number==1:\n",
    "            self.SortFuncClass = SortTextbox  # クラスを変数として保持\n",
    "        elif column_number==2:\n",
    "            self.SortFuncClass = SortTextbox2Column\n",
    "        else:\n",
    "            raise ValueError(\"The column rather than two is not defined\")\n",
    "        \n",
    "    def parse(self, pdf_file_path):\n",
    "        \"\"\"\n",
    "        オーバーライドは原則禁止\n",
    "        \"\"\"\n",
    "        self.pdf_file_name = str(pdf_file_path.stem)  # 内部メソッドからの参照用\n",
    "        \n",
    "        with open(pdf_file_path, \"rb\") as f:\n",
    "\n",
    "            parse_text = \"\"\n",
    "            parse_text_flag = False  # このフラッグがTrueである部分を序論とする\n",
    "            \n",
    "            if self.parse_page_numbers is None:\n",
    "                pages = PDFPage.get_pages(f)  # ページ指定をしない\n",
    "            else:\n",
    "                pages = PDFPage.get_pages(f, pagenos=self.parse_page_numbers)  # ページ指定\n",
    "            \n",
    "            all_page_text_boxes = []\n",
    "            \n",
    "            for page in pages:\n",
    "                self.interpreter.process_page(page)  # ページを処理する。\n",
    "                layout = self.device.get_result()  # LTPageオブジェクトを取得。\n",
    "                text_boxes = find_textboxes_recursively(layout)      \n",
    "\n",
    "                # text_boxの座標値毎にソート，複数キーのソート\n",
    "                # 少なくともこのページは全て読み込む必要があるため，非効率\n",
    "                sort_func= self.SortFuncClass(layout_x0=layout.x0, layout_x1=layout.x1)\n",
    "                text_boxes.sort(key=sort_func)\n",
    "                all_page_text_boxes.extend(text_boxes)\n",
    "                \n",
    "            info_dict = self.parse_info()\n",
    "            paper = self.paper_data_class.parse_by_textboxes(all_page_text_boxes, info_dict)\n",
    "\n",
    "        return paper    \n",
    "    \n",
    "    def parse_info(self):\n",
    "        \"\"\"\n",
    "        Paperオブジェクトによって要オーバーライド\n",
    "        \"\"\"\n",
    "        info_dict = {}\n",
    "        info_dict[\"conf_name\"] = self.conference_name\n",
    "        info_dict[\"pdf_name\"] = self.pdf_file_name\n",
    "        info_dict[\"start_patterns\"] = self.start_patterns\n",
    "        info_dict[\"end_patterns\"] = self.end_patterns\n",
    "        info_dict[\"title_position_number\"] = self.title_position_number\n",
    "        info_dict[\"date\"] = self.date\n",
    "        return info_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### テストコード "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-08T16:38:02.202644Z",
     "start_time": "2020-05-08T16:37:55.364791Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../sample_pdf/IS1-02.pdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-f5310bc8f0d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m                             )\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mpaper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpdf_paper_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../sample_pdf/IS1-02.pdf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0mpprint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpdf_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-dd8a739d0ff8>\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, pdf_file_path)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpdf_file_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdf_file_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 内部メソッドからの参照用\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdf_file_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0mparse_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../sample_pdf/IS1-02.pdf'"
     ]
    }
   ],
   "source": [
    "start_patterns = {\"序論\":re.compile(\"[1-9]*( |　)*(背景|はじめに|Abstract|序論|概要|Introduction)\"), \n",
    "                  \"序論以外\":re.compile(\"[2-9]+( |　)*(関連研究|提案手法|従来手法|従来研究)\")}  # これが当てはまらないものも多い\n",
    "end_patterns = {\"序論\":re.compile(\"[2-9]+( |　)*(関連研究|提案手法|従来手法|従来研究)\"),\n",
    "                \"序論以外\":None}  # これが当てはまらないものも多い\n",
    "#end_patterns = {\"序論\":None}\n",
    "conference_name = \"SSII2019\"\n",
    "title_position_number = 2\n",
    "parse_page_numbers = [0]  # 正直これが一番重要(1枚目まで確認)\n",
    "date = datetime.datetime(2019, 6, 10, 0, 0, 0)\n",
    "\n",
    "#parse_page_numbers = None\n",
    "pdf_paper_parser = PdfParser(\n",
    "                             conference_name=conference_name,\n",
    "                             start_patterns=start_patterns,\n",
    "                             end_patterns=end_patterns,\n",
    "                             title_position_number=title_position_number,\n",
    "                             parse_page_numbers=parse_page_numbers,\n",
    "                             paper_data_class=PaperForSave(),\n",
    "                             date=date\n",
    "                            )\n",
    "\n",
    "paper = pdf_paper_parser.parse(Path(\"../sample_pdf/IS1-02.pdf\"))\n",
    "pprint.pprint(paper.pdf_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## カウント用のパーサ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PdfParserの拡張はPdfParserを継承することによって行う．PdfParserクラスはPaperクラスと対のようになっており，対応するようにparse_infoに追加する．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-08T16:38:02.294612Z",
     "start_time": "2020-05-08T16:38:02.218593Z"
    }
   },
   "outputs": [],
   "source": [
    "class PdfParserCount(PdfParser):\n",
    "    def __init__(self, count_patterns,**kwargs):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        count_patterns: list of pattern\n",
    "            検索したいパターンのリスト\n",
    "        conference_name: str\n",
    "            学会や論文集の名前\n",
    "        start_patterns: dict of patterns\n",
    "            Paperオブジェクトに保持するテキストの開始位置の辞書\n",
    "        end_patterns: dict of pattrens\n",
    "            Paperオブジェクトに保持するテキストの終了位置の辞書，Noneは最後まで\n",
    "        title_position_number: int\n",
    "            titleが与えられるtextboxのインデックス(ソート後)\n",
    "        parse_page_numbers: list of int\n",
    "            パースするページのリスト，Noneは最後まで\n",
    "        paper_data_class: Paper class\n",
    "            ペーパークラスのオブジェクトをストラテジーとして直接与える．\n",
    "        \"\"\"\n",
    "        kwargs[\"paper_data_class\"] = PaperForCount()  # カウント用のPaperクラス\n",
    "        super(PdfParserCount, self).__init__(**kwargs)  # 引数展開\n",
    "        self.count_patterns = count_patterns\n",
    "        \n",
    "    def parse_info(self):\n",
    "        info_dict = super(PdfParserCount, self).parse_info()\n",
    "        info_dict[\"count_patterns\"] = self.count_patterns\n",
    "        \n",
    "        return info_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### テストコード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-08T16:38:09.508192Z",
     "start_time": "2020-05-08T16:38:02.306577Z"
    }
   },
   "outputs": [],
   "source": [
    "start_patterns = {\"序論\":re.compile(\"[1-9]*( |　)*(背景|はじめに|Abstract|序論|概要|Introduction)\")}  # これが当てはまらないものも多い\n",
    "end_patterns = {\"序論\":re.compile(\"[2-9]+( |　)*(関連研究|提案手法|従来手法|従来研究)\")}  # これが当てはまらないものも多い\n",
    "count_patterns = [re.compile(\"ディープラーニング|深層学習\"),\n",
    "                  re.compile(\"CNN|ニューラルネットワーク\"),\n",
    "                  re.compile(\"VAE|変分オートエンコーダ\"),\n",
    "                  re.compile(\"GAN\")\n",
    "                 ]\n",
    "\n",
    "conference_name = \"SSII2019\"\n",
    "title_position_number = 2\n",
    "parse_page_numbers = [0]  # 正直これが一番重要(1枚目まで確認)\n",
    "date = datetime.datetime(2019, 6, 10, 0, 0, 0)\n",
    "\n",
    "pdf_paper_parser = PdfParserCount(count_patterns=count_patterns,\n",
    "                                  conference_name=conference_name,\n",
    "                                  start_patterns=start_patterns,\n",
    "                                  end_patterns=end_patterns,\n",
    "                                  title_position_number=title_position_number,\n",
    "                                  parse_page_numbers=parse_page_numbers,\n",
    "                                  date = date\n",
    "                                  )\n",
    "\n",
    "paper = pdf_paper_parser.parse(Path(\"../sample_pdf/IS1-05.pdf\"))\n",
    "pprint.pprint(paper.toDict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## あるディレクトリ内のpdfをパース"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-08T14:59:52.385255Z",
     "start_time": "2020-05-08T14:59:52.252641Z"
    }
   },
   "outputs": [],
   "source": [
    "class DirectoryPdfParser:\n",
    "    def __init__(self, \n",
    "                 dir_path,\n",
    "                 pdf_parser,\n",
    "                 max_iter=5\n",
    "                ):\n",
    "        \n",
    "        self.dir_path = Path(dir_path)\n",
    "        self.pdf_list = list(self.dir_path.glob(\"./*.pdf\"))  # 複数回パースする必要があるため、リスト化\n",
    "        self.max_iter = max_iter\n",
    "        \n",
    "        self.pdf_parser = pdf_parser     \n",
    "    \n",
    "    def parse_paper_list(self):\n",
    "        \"\"\"\n",
    "        Paperオブジェクトのリストを返すジェネレーター\n",
    "        \"\"\"\n",
    "        paper_list = []\n",
    "        iter_counter = 0\n",
    "        for pdf_path in tqdm(self.pdf_list):\n",
    "            try:\n",
    "                paper = self.pdf_parser.parse(pdf_path)\n",
    "                paper_list.append(paper)\n",
    "                iter_counter += 1 # カウンターに加える\n",
    "                if iter_counter >= self.max_iter:\n",
    "                    yield paper_list\n",
    "                    paper_list = []\n",
    "                    iter_counter = 0\n",
    "            except:\n",
    "                # 累積を防ぐため\n",
    "                paper_list = []\n",
    "                iter_counter = 0\n",
    "                continue\n",
    "                \n",
    "    def parse_dict_list(self):\n",
    "        \"\"\"\n",
    "        Paperオブジェクトのリストを返すジェネレータ―\n",
    "        \"\"\"\n",
    "        paper_list = []\n",
    "        iter_counter = 0\n",
    "        for pdf_path in tqdm(self.pdf_list):\n",
    "            try:\n",
    "                paper = self.pdf_parser.parse(pdf_path)\n",
    "                paper_list.append(paper.toDict())\n",
    "                iter_counter += 1 # カウンターに加える\n",
    "                if iter_counter >= self.max_iter:\n",
    "                    yield paper_list\n",
    "                    paper_list = []\n",
    "                    iter_counter = 0\n",
    "            except:\n",
    "                # 累積を防ぐため\n",
    "                paper_list = []\n",
    "                iter_counter = 0\n",
    "                continue\n",
    "                \n",
    "    def parse_dict(self):\n",
    "        \"\"\"\n",
    "        Paperオブジェクトのリストを返すジェネレータ―\n",
    "        \"\"\"\n",
    "        paper_dict = {}\n",
    "        iter_counter = 0\n",
    "        for pdf_path in tqdm(self.pdf_list):\n",
    "            try:\n",
    "                paper = self.pdf_parser.parse(pdf_path)\n",
    "                paper_dict[paper.pdf_name] = paper.toDict()\n",
    "                iter_counter += 1 # カウンターに加える\n",
    "                if iter_counter >= self.max_iter:\n",
    "                    yield paper_dict\n",
    "                    paper_list = {}\n",
    "                    iter_counter = 0\n",
    "            except:\n",
    "                # 累積を防ぐため\n",
    "                paper_dict = {}\n",
    "                iter_counter = 0\n",
    "                continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### テストコード "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ディレクトリからのパース"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-08T14:09:42.207229Z",
     "start_time": "2020-05-08T14:09:42.153376Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dir_path = Path(\"E:\\pdf_python\\PDFs\")\n",
    "start_patterns = {\"序論\":re.compile(\"[1-9]*( |　)*(背景|はじめに|Abstract|序論|概要|Introduction)\")}  # これが当てはまらないものも多い\n",
    "end_patterns = {\"序論\":re.compile(\"[2-9]+( |　)*(関連研究|提案手法|従来手法|従来研究)\")}  # これが当てはまらないものも多い\n",
    "conference_name = \"SSII2019\"\n",
    "title_position_number = 2\n",
    "parse_page_numbers = [0]  # 正直これが一番重要(1枚目まで確認)\n",
    "date = datetime.datetime(2019, 6, 10, 0, 0, 0)\n",
    "\n",
    "pdf_parser = PdfParser(conference_name=conference_name,\n",
    "                       start_patterns=start_patterns,\n",
    "                       end_patterns=end_patterns,\n",
    "                       title_position_number=title_position_number,\n",
    "                       parse_page_numbers=parse_page_numbers,\n",
    "                       date=date\n",
    "                       )\n",
    "max_iter = 5\n",
    "\n",
    "dir_pdf_parser = DirectoryPdfParser(dir_path=dir_path,\n",
    "                                    pdf_parser=pdf_parser,\n",
    "                                    max_iter=max_iter\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ディクショナリのリストで取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-08T14:08:59.646968Z",
     "start_time": "2020-05-08T14:07:19.667249Z"
    }
   },
   "outputs": [],
   "source": [
    "for paper_list in dir_pdf_parser.parse_dict_list():\n",
    "    pprint.pprint(paper_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ディクショナリとして取得 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-08T14:11:47.138233Z",
     "start_time": "2020-05-08T14:09:47.542602Z"
    }
   },
   "outputs": [],
   "source": [
    "all_paper_dict = {}\n",
    "for paper_dict in dir_pdf_parser.parse_dict():\n",
    "    all_paper_dict.update(paper_dict)\n",
    "    \n",
    "pprint.pprint(all_paper_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### jsonへの保存 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-08T14:51:25.497668Z",
     "start_time": "2020-05-08T14:51:24.779067Z"
    }
   },
   "outputs": [],
   "source": [
    "save_path = Path(\"./papers.json\")\n",
    "with open(save_path,\"w\",encoding=\"utf-8\") as f:\n",
    "    json.dump(all_paper_dict,f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### カウント"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-08T15:01:04.979313Z",
     "start_time": "2020-05-08T15:01:04.877503Z"
    }
   },
   "outputs": [],
   "source": [
    "dir_path = Path(\"E:\\pdf_python\\PDFs\")\n",
    "start_patterns = {\"序論\":re.compile(\"[1-9]*( |　)*(背景|はじめに|Abstract|序論|概要|Introduction)\")}  # これが当てはまらないものも多い\n",
    "end_patterns = {\"序論\":re.compile(\"[2-9]+( |　)*(関連研究|提案手法|従来手法|従来研究)\")}  # これが当てはまらないものも多い\n",
    "count_patterns = [re.compile(\"ディープラーニング|深層学習\"),\n",
    "                  re.compile(\"CNN|ニューラルネットワーク\"),\n",
    "                  re.compile(\"VAE|変分オートエンコーダ\"),\n",
    "                  re.compile(\"GAN\")\n",
    "                 ]\n",
    "\n",
    "conference_name = \"SSII2019\"\n",
    "title_position_number = 2\n",
    "parse_page_numbers = [0]  # 正直これが一番重要(1枚目まで確認)\n",
    "date = datetime.datetime(2019, 6, 10, 0, 0, 0)\n",
    "pdf_paper_parser = PdfParserCount(count_patterns=count_patterns,\n",
    "                                  conference_name=conference_name,\n",
    "                                  start_patterns=start_patterns,\n",
    "                                  end_patterns=end_patterns,\n",
    "                                  title_position_number=title_position_number,\n",
    "                                  parse_page_numbers=parse_page_numbers,\n",
    "                                  date=date\n",
    "                                  )\n",
    "max_iter = 5\n",
    "\n",
    "dir_pdf_parser = DirectoryPdfParser(dir_path=dir_path,\n",
    "                                    pdf_parser=pdf_paper_parser,\n",
    "                                    max_iter=max_iter\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T10:31:04.161961Z",
     "start_time": "2020-05-06T10:31:04.083482Z"
    }
   },
   "source": [
    "#### paper_listのソート "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-08T15:27:49.983264Z",
     "start_time": "2020-05-08T15:25:20.853116Z"
    }
   },
   "outputs": [],
   "source": [
    "all_paper_list = []\n",
    "for paper_list in dir_pdf_parser.parse_paper_list():\n",
    "    all_paper_list.extend(paper_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-08T15:27:50.082998Z",
     "start_time": "2020-05-08T15:27:50.013184Z"
    }
   },
   "outputs": [],
   "source": [
    "all_paper_list.sort(key=lambda paper_counter: tuple(paper_counter.counters.values()),reverse=True)  # OrderdDictなのでvalues順に並べればよい\n",
    "print(all_paper_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdf_py37",
   "language": "python",
   "name": "pdf_py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "202.542px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
