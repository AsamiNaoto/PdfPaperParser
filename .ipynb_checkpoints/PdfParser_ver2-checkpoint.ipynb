{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-08T16:37:54.208522Z",
     "start_time": "2020-05-08T16:37:50.990231Z"
    }
   },
   "outputs": [],
   "source": [
    "from pdfminer.converter import PDFPageAggregator\n",
    "from pdfminer.layout import LAParams, LTContainer, LTTextBox\n",
    "from pdfminer.pdfinterp import PDFPageInterpreter, PDFResourceManager\n",
    "from pdfminer.pdfpage import PDFPage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-08T16:37:54.728131Z",
     "start_time": "2020-05-08T16:37:54.220491Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "from collections import OrderedDict\n",
    "from tqdm.notebook import tqdm\n",
    "import pprint\n",
    "import json\n",
    "import abc\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LayoutオブジェクトからLTTextBoxのリストを取得する関数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "抜き出すのは，textデータを前提とするのでこの関数が必要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-08T16:37:54.769024Z",
     "start_time": "2020-05-08T16:37:54.741098Z"
    }
   },
   "outputs": [],
   "source": [
    "def find_textboxes_recursively(layout):\n",
    "    \"\"\"\n",
    "    再帰的にテキストボックス（LTTextBox）を探して、テキストボックスのリストを取得する。\n",
    "    \"\"\"\n",
    "    # LTTextBoxを継承するオブジェクトの場合は1要素のリストを返す。\n",
    "    if isinstance(layout, LTTextBox):\n",
    "        text_boxes = [layout]\n",
    "        return text_boxes  # 返すのはリスト\n",
    "\n",
    "    # LTContainerを継承するオブジェクトは子要素を含むので、再帰的に探す。\n",
    "    if isinstance(layout, LTContainer):\n",
    "        text_boxes = []\n",
    "        for child in layout:\n",
    "            text_boxes.extend(find_textboxes_recursively(child))  # 再帰的にリストをextend\n",
    "            \n",
    "        return text_boxes\n",
    "\n",
    "    return []  # 何も取得できなかった場合は空リストを返す"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ソート用の関数 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "textboxのソートは，1段組みと2段組みで異なる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 二段組用のソート "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-08T16:37:54.819888Z",
     "start_time": "2020-05-08T16:37:54.782986Z"
    }
   },
   "outputs": [],
   "source": [
    "class SortTextbox2Column():\n",
    "    \"\"\"\n",
    "    2段組み用，始めのソートは左側と右側\n",
    "    \"\"\"\n",
    "    def __init__(self, layout_x0, layout_x1):\n",
    "        self.half_x = (layout_x0 + layout_x1)/2\n",
    "    \n",
    "    def __call__(self, text_box):\n",
    "        if text_box.x0 < self.half_x:\n",
    "            left_or_right = -1  # it mean left\n",
    "            \n",
    "        else:\n",
    "            left_or_right = 1  # it mean right\n",
    "            \n",
    "        return (left_or_right, -text_box.y1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1段組み用のソート "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-08T16:37:54.853797Z",
     "start_time": "2020-05-08T16:37:54.832853Z"
    }
   },
   "outputs": [],
   "source": [
    "class SortTextbox():\n",
    "    \"\"\"\n",
    "    textboxの左下の座標でソート\n",
    "    \"\"\"\n",
    "    def __init__(self,*args):\n",
    "        \"\"\"\n",
    "        2段組み用のソートクラスとの対応のため\n",
    "        \"\"\"\n",
    "        pass\n",
    "    def __call__(self, text_box):\n",
    "        return (-text_boxt.y1, text_box.x0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 論文データのベースクラス "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pdfデータをパースして保存するときと，呼び出すときに利用する？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-08T16:37:55.031688Z",
     "start_time": "2020-05-08T16:37:54.869837Z"
    }
   },
   "outputs": [],
   "source": [
    "class PaperBase(metaclass=abc.ABCMeta):\n",
    "    \"\"\"\n",
    "    論文のデータクラスとPaser用のストラテジーを一つにしたもの.正直一つにする意味はない.\n",
    "    ただ変更するクラスをまとめただけ\n",
    "    \n",
    "    \"\"\"\n",
    "    @abc.abstractmethod\n",
    "    def toDict(self):\n",
    "        pass\n",
    "    \n",
    "    @classmethod\n",
    "    def parse_by_textboxes(cls, text_boxes, parse_info):\n",
    "        \"\"\"\n",
    "        text_boxesからパースする\n",
    "        \"\"\"\n",
    "        paper_title, parse_text_dict = cls.str_from_textboxes(text_boxes, parse_info)  # スタティクメソッド\n",
    "        paper = cls.parse_by_text_dict(paper_title=paper_title, \n",
    "                                       parse_text_dict=parse_text_dict, \n",
    "                                       parse_info=parse_info)  # クラスメソッド\n",
    "        \n",
    "        return paper\n",
    "    \n",
    "    @classmethod\n",
    "    def parse_by_text_dict(cls, paper_title, parse_text_dict, parse_info):\n",
    "        raise NotImplementedError(\"Implement parse_by_text_dict\")\n",
    "        \n",
    "        \n",
    "    @classmethod\n",
    "    def parse_by_dict(cls, content):\n",
    "        raise NotImplementedError(\"Implement parse_by_content\")\n",
    "        \n",
    "    @staticmethod\n",
    "    def str_from_textboxes(text_boxes, parse_info):\n",
    "        \"\"\"\n",
    "        共通するテキスト取得プログラム\n",
    "        \"\"\"\n",
    "        #parse_text_flag = False  # このフラッグがTrueである部分を保存する        \n",
    "         \n",
    "        patterns_keys = parse_info[\"start_patterns\"].keys()  # キーのリスト(のようなもの)\n",
    "        \n",
    "        #patterns_key_iter = iter(patterns_keys)  # 長さの違うfor文内で回すので，キーをイテレーター化\n",
    "        #pattern_key = next(patterns_key_iter)  # 最初のキーを取得\n",
    "        \n",
    "        parse_text_dict = {i:\"\" for i in patterns_keys}\n",
    "        parse_text_flag_dict = {i:False for i in patterns_keys}  # このフラッグがTrueであるときに保存する\n",
    "        parse_text_started = {i:False for i in patterns_keys}  # マッチングがスタートしたらTrueになる(何度もマッチングがスタートしないように)\n",
    "        \n",
    "        for i,box in enumerate(text_boxes):\n",
    "            text = box.get_text().strip()  # 末尾の文字を削除\n",
    "            if i == parse_info[\"title_position_number\"]:\n",
    "                paper_title = text\n",
    "            \n",
    "            for pattern_key in patterns_keys:                    \n",
    "                    \n",
    "                if parse_info[\"end_patterns\"][pattern_key] is not None: # Noneなら，最後までTrue\n",
    "                    if parse_info[\"end_patterns\"][pattern_key].search(text):\n",
    "                        parse_text_flag_dict[pattern_key] = False\n",
    "                        if set(parse_text_flag_dict.values()) == {False} and set(parse_text_started.values()) == {True}:  # parse_text_flag_dictが全てFalseに\n",
    "                            break  # すでにパターンが全てスタートし，全てエンドした場合\n",
    "                        \n",
    "                if parse_text_flag_dict[pattern_key]: \n",
    "                    parse_text_dict[pattern_key] += text  # flagがTrueのとき，保存\n",
    "                    \n",
    "                if parse_info[\"start_patterns\"][pattern_key].search(text) and not parse_text_started[pattern_key]:# マッチしたらフラッグをTrueに\n",
    "                    parse_text_flag_dict[pattern_key] = True\n",
    "                    parse_text_started[pattern_key] = True  # マッチングがスタートしたかどうか\n",
    "            else:\n",
    "                continue\n",
    "            break  # 多重ループから抜ける\n",
    "                    \n",
    "        return paper_title, parse_text_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### セーブデータ保存用の Paperクラス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-08T16:37:55.100654Z",
     "start_time": "2020-05-08T16:37:55.054666Z"
    }
   },
   "outputs": [],
   "source": [
    "class PaperForSave(PaperBase):\n",
    "    \"\"\"\n",
    "    論文をテキストデータとして，保存するための論文データクラス\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 conf_name=None, \n",
    "                 pdf_name=None, \n",
    "                 paper_title=None, \n",
    "                 pdf_content=None,\n",
    "                 date=None\n",
    "                 \n",
    "                ):\n",
    "        \"\"\"\n",
    "        一つのデータで\n",
    "        Parameters\n",
    "        ----------\n",
    "        conf_name: str\n",
    "            学会や論文集を表す文字列\n",
    "        pdf_name: str\n",
    "            対応するpdfファイルの名前を表す文字列\n",
    "        paper_title: str\n",
    "            論文のタイトル\n",
    "        pdf_content: dict\n",
    "            保存するテキストのdictionaly\n",
    "        \"\"\"\n",
    "        self.conf_name = conf_name\n",
    "        self.pdf_name = pdf_name\n",
    "        self.paper_title = paper_title\n",
    "        self.pdf_content = pdf_content\n",
    "        self.date = date\n",
    "        \n",
    "    def toDict(self):\n",
    "        out_dict = {\"pdf_name\": self.pdf_name,\n",
    "                    \"paper_title\": self.paper_title,\n",
    "                    \"content\":self.pdf_content,\n",
    "                    \"date\":str(self.date),\n",
    "                    \"conf_name\": self.conf_name\n",
    "                   }\n",
    "        return out_dict\n",
    "    \n",
    "    @classmethod\n",
    "    def parse_by_text_dict(cls, paper_title, parse_text_dict, parse_info):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        text_boxes: list of textbox\n",
    "            pdfをパースしたときに得られるtextboxのリスト\n",
    "        start_patterns\n",
    "        \"\"\"\n",
    "        #from IPython.core.debugger import Pdb; Pdb().set_trace()  # PaperForSave\n",
    "        paper_conf_name = parse_info[\"conf_name\"]\n",
    "        paper_pdf_name = parse_info[\"pdf_name\"]\n",
    "        paper_date = parse_info[\"date\"]\n",
    "        \n",
    "        # Paperへのデータの付与\n",
    "        paper = cls(conf_name=paper_conf_name,\n",
    "                    paper_title=paper_title,\n",
    "                    pdf_name=paper_pdf_name,\n",
    "                    pdf_content=parse_text_dict,\n",
    "                    date=paper_date\n",
    "                   )\n",
    "\n",
    "        return paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### カウント用のPaperクラス "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paperクラスの拡張は以下のように行う，初期化メソッドはデータをアトリビュートとして保持するように実装．`toDict`と`parse_by_textboxes`,`parse_by_contents`は適宜実装する．その際，Parserクラスの`parse_info`と対応するように実装する．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-08T16:37:55.225045Z",
     "start_time": "2020-05-08T16:37:55.116641Z"
    }
   },
   "outputs": [],
   "source": [
    "class PaperForCount(PaperBase):\n",
    "    def __init__(self, conf_name=None, pdf_name=None, count_patterns=[], paper_title=None, date=None):\n",
    "        \"\"\"\n",
    "        countersは保存する文字列あるいはパターンのリスト\n",
    "        \"\"\"\n",
    "        self.conf_name = conf_name\n",
    "        self.pdf_name = pdf_name\n",
    "        self.paper_title = paper_title\n",
    "        self.date = date\n",
    "        self.counters = OrderedDict()\n",
    "        for i in count_patterns:\n",
    "            self.counters[i] = 0  # パターンオブジェクトはhashableでキーにできる．まず，0に初期化\n",
    "    \n",
    "    def toDict(self):\n",
    "        counters = {i.pattern:self.counters[i] for i in self.counters.keys()}  # キーを文字列へ\n",
    "        \n",
    "        out_dict = {\n",
    "                    \"conf_name\":self.conf_name,\n",
    "                    \"pdf_name\":self.pdf_name,\n",
    "                    \"paper_title\":self.paper_title,\n",
    "                    \"counters\":counters,\n",
    "                    \"date\":str(self.date)\n",
    "                   }\n",
    "        return out_dict\n",
    "    \n",
    "    @classmethod\n",
    "    def parse_by_text_dict(cls, paper_title, parse_text_dict, parse_info):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        text_boxes: list of textbox\n",
    "            pdfをパースしたときに得られるtextboxのリスト\n",
    "        parse_info: dict \n",
    "            パースの時に必要な情報\n",
    "        \"\"\"\n",
    "        #from IPython.core.debugger import Pdb; Pdb().set_trace()  # PaperForCount\n",
    "        \n",
    "        paper_conf_name = parse_info[\"conf_name\"]\n",
    "        paper_pdf_name = parse_info[\"pdf_name\"]\n",
    "        paper_date = parse_info[\"date\"]\n",
    "                \n",
    "        # 以下Paperへのデータの付与\n",
    "        count_patterns = parse_info[\"count_patterns\"]\n",
    "        \n",
    "        paper = cls(\n",
    "                    conf_name=paper_conf_name,\n",
    "                    pdf_name=paper_pdf_name,\n",
    "                    paper_title=paper_title,\n",
    "                    count_patterns=count_patterns,\n",
    "                    date=paper_date\n",
    "                   )\n",
    "        \n",
    "        for pattern in count_patterns:\n",
    "            for text in parse_text_dict.values():\n",
    "                m = pattern.findall(text)\n",
    "                paper.counters[pattern] += len(m)\n",
    "                \n",
    "        return paper\n",
    "    \n",
    "    @classmethod\n",
    "    def parse_by_dict(cls, paper_dict, parse_info):\n",
    "        #from IPython.core.debugger import Pdb; Pdb().set_trace()  # PaperForCount\n",
    "        paper_conf_name = paper_dict[\"conf_name\"]\n",
    "        paper_title = paper_dict[\"paper_title\"]\n",
    "        paper_pdf_name = paper_dict[\"pdf_name\"]\n",
    "        paper_date = paper_dict[\"date\"]\n",
    "        parse_text_dict = paper_dict[\"contents\"]\n",
    "        \n",
    "        count_patterns = parse_infonfo[\"count_patterns\"]\n",
    "        \n",
    "        paper = cls(\n",
    "                    conf_name=paper_conf_name,\n",
    "                    pdf_name=paper_pdf_name,\n",
    "                    paper_title=paper_title,\n",
    "                    count_patterns=count_patterns,\n",
    "                    date=paper_date\n",
    "                   )\n",
    "        \n",
    "        for pattern in count_patterns:\n",
    "            for text in parse_text_dict.values():\n",
    "                m = pattern.findall(text)\n",
    "                paper.counters[pattern] += len(m)\n",
    "                \n",
    "        return paper\n",
    "    \n",
    "    def is_counted(self):\n",
    "        # 一つも含まれていないとき\n",
    "        if set(self.counters.values()) == {0}:\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "        \n",
    "    def __repr__(self):\n",
    "        str_conf_name = str(self.conf_name)\n",
    "        str_pdf_name = str(self.pdf_name)\n",
    "        str_paper_title = str(self.paper_title)\n",
    "        str_counters = str(self.counters)\n",
    "        str_date = str(self.date)\n",
    "        return str_pdf_name+\"\\n\"+str_paper_title+\"\\n\"+str_counters+\"\\n\"+str_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## あるpdfファイルをパースし，パースした内容をPaperオブジェクトで返すオブジェクト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-08T16:37:55.354818Z",
     "start_time": "2020-05-08T16:37:55.244067Z"
    }
   },
   "outputs": [],
   "source": [
    "class PdfParser():\n",
    "    def __init__(self, \n",
    "                 conference_name,\n",
    "                 start_patterns={\"all\":re.compile(\".*\")},\n",
    "                 end_patterns={\"all\":None},\n",
    "                 title_position_number=2,\n",
    "                 parse_page_numbers=[0],\n",
    "                 column_number=2,\n",
    "                 date=datetime.datetime(2000, 1, 1, 00, 00, 00),\n",
    "                 paper_data_class=PaperForSave()\n",
    "                ):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        conference_name: str\n",
    "            学会や論文集の名前\n",
    "        start_patterns: dict of patterns\n",
    "            Paperオブジェクトに保持するテキストの開始位置の辞書\n",
    "        end_patterns: dict of pattrens\n",
    "            Paperオブジェクトに保持するテキストの終了位置の辞書，Noneは最後まで\n",
    "        title_position_number: int\n",
    "            titleが与えられるtextboxのインデックス(ソート後)\n",
    "        parse_page_numbers: list of int\n",
    "            パースするページのリスト，Noneは最後まで\n",
    "        paper_data_class: Paper class\n",
    "            ペーパークラスのオブジェクトをストラテジーとして直接与える．\n",
    "        \"\"\"\n",
    "        \n",
    "        self.conference_name = conference_name\n",
    "        \n",
    "        if set(start_patterns.keys()) != set(end_patterns.keys()):\n",
    "            raise ValueError(\"start patterns and eend patterns are not correspondding\")\n",
    "        \n",
    "        self.title_position_number = title_position_number\n",
    "        self.parse_page_numbers = parse_page_numbers  \n",
    "        self.column_number = column_number\n",
    "        self.date = date\n",
    "        \n",
    "        self.paper_data_class = paper_data_class\n",
    "        \n",
    "        self.start_patterns = start_patterns\n",
    "        self.end_patterns = end_patterns\n",
    "        \n",
    "        # パースに必要なクラスの作成\n",
    "        # Layout Analysisのパラメーターを設定。縦書きの検出を有効にする。\n",
    "        laparams = LAParams(detect_vertical=True)\n",
    "\n",
    "        # 共有のリソースを管理するリソースマネージャーを作成。\n",
    "        resource_manager = PDFResourceManager(caching=False)\n",
    "\n",
    "        # ページを集めるPageAggregatorオブジェクトを作成。\n",
    "        self.device = PDFPageAggregator(resource_manager, laparams=laparams)\n",
    "\n",
    "        # Interpreterオブジェクトを作成。\n",
    "        self.interpreter = PDFPageInterpreter(resource_manager, self.device)\n",
    "        \n",
    "        if column_number==1:\n",
    "            self.SortFuncClass = SortTextbox  # クラスを変数として保持\n",
    "        elif column_number==2:\n",
    "            self.SortFuncClass = SortTextbox2Column\n",
    "        else:\n",
    "            raise ValueError(\"The column rather than two is not defined\")\n",
    "        \n",
    "    def parse(self, pdf_file_path):\n",
    "        \"\"\"\n",
    "        オーバーライドは原則禁止\n",
    "        \"\"\"\n",
    "        self.pdf_file_name = str(pdf_file_path.stem)  # 内部メソッドからの参照用\n",
    "        \n",
    "        with open(pdf_file_path, \"rb\") as f:\n",
    "\n",
    "            parse_text = \"\"\n",
    "            parse_text_flag = False  # このフラッグがTrueである部分を序論とする\n",
    "            \n",
    "            if self.parse_page_numbers is None:\n",
    "                pages = PDFPage.get_pages(f)  # ページ指定をしない\n",
    "            else:\n",
    "                pages = PDFPage.get_pages(f, pagenos=self.parse_page_numbers)  # ページ指定\n",
    "            \n",
    "            all_page_text_boxes = []\n",
    "            \n",
    "            for page in pages:\n",
    "                self.interpreter.process_page(page)  # ページを処理する。\n",
    "                layout = self.device.get_result()  # LTPageオブジェクトを取得。\n",
    "                text_boxes = find_textboxes_recursively(layout)      \n",
    "\n",
    "                # text_boxの座標値毎にソート，複数キーのソート\n",
    "                # 少なくともこのページは全て読み込む必要があるため，非効率\n",
    "                sort_func= self.SortFuncClass(layout_x0=layout.x0, layout_x1=layout.x1)\n",
    "                text_boxes.sort(key=sort_func)\n",
    "                all_page_text_boxes.extend(text_boxes)\n",
    "                \n",
    "            info_dict = self.parse_info()\n",
    "            paper = self.paper_data_class.parse_by_textboxes(all_page_text_boxes, info_dict)\n",
    "\n",
    "        return paper\n",
    "    \n",
    "    def parse_info(self):\n",
    "        \"\"\"\n",
    "        Paperオブジェクトによって要オーバーライド\n",
    "        \"\"\"\n",
    "        info_dict = {}\n",
    "        info_dict[\"conf_name\"] = self.conference_name\n",
    "        info_dict[\"pdf_name\"] = self.pdf_file_name\n",
    "        info_dict[\"start_patterns\"] = self.start_patterns\n",
    "        info_dict[\"end_patterns\"] = self.end_patterns\n",
    "        info_dict[\"title_position_number\"] = self.title_position_number\n",
    "        info_dict[\"date\"] = self.date\n",
    "        return info_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### テストコード "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-08T16:38:02.202644Z",
     "start_time": "2020-05-08T16:37:55.364791Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'序論': '機械学習技術や IoT  (Internet  of  Things)，M2M \\n'\n",
      "       '(Machine  to  Machine)  によるセンサネットワークの広\\n'\n",
      "       'がりとともに，例えば日常生活での見守りサービスや，生産現場での生産性改善など，センサデータを用い\\n'\n",
      "       'た行動分析アプリケーションが提案されている．ところで，従来の行動分析技術は，その多くが教師あり学習に基づいて検討されている．教師あり学習は，事前に人手による教師データの作成等が必要であり，これにかかる手間と時間とが実用化の際には大\\n'\n",
      "       'きな課題となる．本稿では上記の課題を解決した行動分析アプリケーションの実現を目的として，教師なし学習に基づく\\n'\n",
      "       '行動分析アルゴリズムを提案する．提案手法が対象とするのは，とくに日常生活や生産現場等で見られる，同じ動作が繰り返される行動である．複数回繰り返された動作のセンサデータ同士を，動作要素ごとに分節化して比較することで，教師データを与えることなく，標準的な動作パターンを\\n'\n",
      "       '決定するとともに非標準動作を検出する．',\n",
      " '序論以外': '提案手法の入力となるセンサデータは，複数回の動作を繰り返す人に対して，身体の複数箇所の時間変位を計測することで得られる．アルゴリズムは，以\\n'\n",
      "         '下の 4 つのステップからなる， \\n'\n",
      "         '2.1  センサデータの分節化確率的生成モデル[1]により，センサデータを動作\\n'\n",
      "         '要素ごとに分節化した分節データを得る．分節は，\\n'\n",
      "         '動作要素のクラスと，その継続時間として表される． \\n'\n",
      "         '2.2  '\n",
      "         '分節データの整列複数回繰り返された動作の中には，標準的には行われない動作要素が含まれる可能性があり，各回の動作で得られる分節の数は必ずしも一定とならない．\\n'\n",
      "         'このため多重整列[2]を用いて，分節データから複数Copyright © SSII 2019. All Rights '\n",
      "         'Reserved.- IS1-05 -回の動作間で対応する分節を同じ列に整列した整\\n'\n",
      "         '列データを得る． \\n'\n",
      "         '2.3  '\n",
      "         '標準動作パターンの決定整列データから複数回の動作間で同じ列に整列された分節同士を比較することで，各列での標準的なクラスと分節の継続時間とを算出し，標準動作パター\\n'\n",
      "         'ンを決定する． \\n'\n",
      "         '2.4  '\n",
      "         '非標準動作の検出整列データと標準動作パターンの分節を比較し，各列において標準と異なるクラス，あるいは標準と大きく異なる継続時間を持つ分節を非標準動作として\\n'\n",
      "         '検出する．3実験3.1  '\n",
      "         '実験条件提案手法の評価のため，生産現場での作業を模擬した繰り返し行動を対象とした実験を行った．被験者は両手首に色付きのリストバンドを装着し，\\n'\n",
      "         'センサとして RGB-D カメラ（RealSense D435，Intel 社）\\n'\n",
      "         'を利用することで，両手の 3 次元位置（6 次元）を計\\n'\n",
      "         '測した（図 1）．また，動作の繰り返し回数は 9 回とし\\n'\n",
      "         'た．なお，提案手法の評価としては下記を用いた． \\n'\n",
      "         '\\uf06c  人 手 に よ り 与 え た 動 作 の ク ラ ス と ， 提 案 手 法\\n'\n",
      "         '（2.1 節）により得られた各時刻における動作のクラス\\n'\n",
      "         'との一致率． \\n'\n",
      "         '\\uf06c  人手により見つかった非標準動作の、提案手法\\n'\n",
      "         '（2.4 節）による検出率． \\n'\n",
      "         '3.2  実験結果提案手法による分析結果を図 2 に示す．図 2(a)は\\n'\n",
      "         '取得されたセンサデータ，図 2(b)は分節化により得ら\\n'\n",
      "         'れた分節データである．色はそれぞれの分節が分類\\n'\n",
      "         'されたクラスを示す．図 2(c)は，図 2(b)の分節データ\\n'\n",
      "         'を離散的に表現した図である．矩形はそれぞれの分\\n'\n",
      "         '節であり，数字は継続時間 [s]である。図 2(d)は，整列により得られた整列データであり，\\n'\n",
      "         '図 2(e)は整列データから決定された標準動作パター'}\n"
     ]
    }
   ],
   "source": [
    "start_patterns = {\"序論\":re.compile(\"[1-9]*( |　)*(背景|はじめに|Abstract|序論|概要|Introduction)\"), \n",
    "                  \"序論以外\":re.compile(\"[2-9]+( |　)*(関連研究|提案手法|従来手法|従来研究)\")}  # これが当てはまらないものも多い\n",
    "end_patterns = {\"序論\":re.compile(\"[2-9]+( |　)*(関連研究|提案手法|従来手法|従来研究)\"),\n",
    "                \"序論以外\":None}  # これが当てはまらないものも多い\n",
    "#end_patterns = {\"序論\":None}\n",
    "conference_name = \"SSII2019\"\n",
    "title_position_number = 2\n",
    "parse_page_numbers = [0]  # 正直これが一番重要(1枚目まで確認)\n",
    "date = datetime.datetime(2019, 6, 10, 0, 0, 0)\n",
    "\n",
    "#parse_page_numbers = None\n",
    "pdf_paper_parser = PdfParser(\n",
    "                             conference_name=conference_name,\n",
    "                             start_patterns=start_patterns,\n",
    "                             end_patterns=end_patterns,\n",
    "                             title_position_number=title_position_number,\n",
    "                             parse_page_numbers=parse_page_numbers,\n",
    "                             paper_data_class=PaperForSave(),\n",
    "                             date=date\n",
    "                            )\n",
    "\n",
    "paper = pdf_paper_parser.parse(Path(\"../sample_pdf/IS1-05.pdf\"))\n",
    "pprint.pprint(paper.pdf_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## カウント用のパーサ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PdfParserの拡張はPdfParserを継承することによって行う．PdfParserクラスはPaperクラスと対のようになっており，対応するようにparse_infoに追加する．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-08T16:38:02.294612Z",
     "start_time": "2020-05-08T16:38:02.218593Z"
    }
   },
   "outputs": [],
   "source": [
    "class PdfParserCount(PdfParser):\n",
    "    def __init__(self, count_patterns,**kwargs):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        count_patterns: list of pattern\n",
    "            検索したいパターンのリスト\n",
    "        conference_name: str\n",
    "            学会や論文集の名前\n",
    "        start_patterns: dict of patterns\n",
    "            Paperオブジェクトに保持するテキストの開始位置の辞書\n",
    "        end_patterns: dict of pattrens\n",
    "            Paperオブジェクトに保持するテキストの終了位置の辞書，Noneは最後まで\n",
    "        title_position_number: int\n",
    "            titleが与えられるtextboxのインデックス(ソート後)\n",
    "        parse_page_numbers: list of int\n",
    "            パースするページのリスト，Noneは最後まで\n",
    "        paper_data_class: Paper class\n",
    "            ペーパークラスのオブジェクトをストラテジーとして直接与える．\n",
    "        \"\"\"\n",
    "        kwargs[\"paper_data_class\"] = PaperForCount()  # カウント用のPaperクラス\n",
    "        super(PdfParserCount, self).__init__(**kwargs)  # 引数展開\n",
    "        self.count_patterns = count_patterns\n",
    "        \n",
    "    def parse_info(self):\n",
    "        info_dict = super(PdfParserCount, self).parse_info()\n",
    "        info_dict[\"count_patterns\"] = self.count_patterns\n",
    "        \n",
    "        return info_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### テストコード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-08T16:38:09.508192Z",
     "start_time": "2020-05-08T16:38:02.306577Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'conf_name': 'SSII2019',\n",
      " 'counters': {'CNN|ニューラルネットワーク': 0,\n",
      "              'GAN': 0,\n",
      "              'VAE|変分オートエンコーダ': 0,\n",
      "              'ディープラーニング|深層学習': 0},\n",
      " 'date': '2019-06-10 00:00:00',\n",
      " 'paper_title': '',\n",
      " 'pdf_name': 'IS1-05'}\n"
     ]
    }
   ],
   "source": [
    "start_patterns = {\"序論\":re.compile(\"[1-9]*( |　)*(背景|はじめに|Abstract|序論|概要|Introduction)\")}  # これが当てはまらないものも多い\n",
    "end_patterns = {\"序論\":re.compile(\"[2-9]+( |　)*(関連研究|提案手法|従来手法|従来研究)\")}  # これが当てはまらないものも多い\n",
    "count_patterns = [re.compile(\"ディープラーニング|深層学習\"),\n",
    "                  re.compile(\"CNN|ニューラルネットワーク\"),\n",
    "                  re.compile(\"VAE|変分オートエンコーダ\"),\n",
    "                  re.compile(\"GAN\")\n",
    "                 ]\n",
    "\n",
    "conference_name = \"SSII2019\"\n",
    "title_position_number = 2\n",
    "parse_page_numbers = [0]  # 正直これが一番重要(1枚目まで確認)\n",
    "date = datetime.datetime(2019, 6, 10, 0, 0, 0)\n",
    "\n",
    "pdf_paper_parser = PdfParserCount(count_patterns=count_patterns,\n",
    "                                  conference_name=conference_name,\n",
    "                                  start_patterns=start_patterns,\n",
    "                                  end_patterns=end_patterns,\n",
    "                                  title_position_number=title_position_number,\n",
    "                                  parse_page_numbers=parse_page_numbers,\n",
    "                                  date = date\n",
    "                                  )\n",
    "\n",
    "paper = pdf_paper_parser.parse(Path(\"../sample_pdf/IS1-05.pdf\"))\n",
    "pprint.pprint(paper.toDict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## あるディレクトリ内のpdfをパース"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-08T14:59:52.385255Z",
     "start_time": "2020-05-08T14:59:52.252641Z"
    }
   },
   "outputs": [],
   "source": [
    "class DirectoryPdfParser:\n",
    "    def __init__(self, \n",
    "                 dir_path,\n",
    "                 pdf_parser,\n",
    "                 max_iter=5\n",
    "                ):\n",
    "        \n",
    "        self.dir_path = Path(dir_path)\n",
    "        self.pdf_list = list(self.dir_path.glob(\"./*.pdf\"))  # 複数回パースする必要があるため、リスト化\n",
    "        self.max_iter = max_iter\n",
    "        \n",
    "        self.pdf_parser = pdf_parser\n",
    "    \n",
    "    def parse_paper_list(self):\n",
    "        \"\"\"\n",
    "        Paperオブジェクトのリストを返すジェネレーター\n",
    "        \"\"\"\n",
    "        paper_list = []\n",
    "        iter_counter = 0\n",
    "        for pdf_path in tqdm(self.pdf_list):\n",
    "            paper = self.pdf_parser.parse(pdf_path)\n",
    "            paper_list.append(paper)\n",
    "            iter_counter += 1 # カウンターに加える\n",
    "            if iter_counter >= self.max_iter:\n",
    "                yield paper_list\n",
    "                paper_list = []\n",
    "                iter_counter = 0\n",
    "                \n",
    "    def parse_dict_list(self):\n",
    "        \"\"\"\n",
    "        Paperオブジェクトのリストを返すジェネレータ―\n",
    "        \"\"\"\n",
    "        paper_list = []\n",
    "        iter_counter = 0\n",
    "        for pdf_path in tqdm(self.pdf_list):\n",
    "            paper = self.pdf_parser.parse(pdf_path)\n",
    "            paper_list.append(paper.toDict())\n",
    "            iter_counter += 1 # カウンターに加える\n",
    "            if iter_counter >= self.max_iter:\n",
    "                yield paper_list\n",
    "                paper_list = []\n",
    "                iter_counter = 0\n",
    "                \n",
    "    def parse_dict(self):\n",
    "        \"\"\"\n",
    "        Paperオブジェクトのリストを返すジェネレータ―\n",
    "        \"\"\"\n",
    "        paper_dict = {}\n",
    "        iter_counter = 0\n",
    "        for pdf_path in tqdm(self.pdf_list):\n",
    "            paper = self.pdf_parser.parse(pdf_path)\n",
    "            paper_dict[paper.pdf_name] = paper.toDict()\n",
    "            iter_counter += 1 # カウンターに加える\n",
    "            if iter_counter >= self.max_iter:\n",
    "                yield paper_dict\n",
    "                paper_list = {}\n",
    "                iter_counter = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### テストコード "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ディレクトリからのパース"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-08T14:09:42.207229Z",
     "start_time": "2020-05-08T14:09:42.153376Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dir_path = Path(\"E:\\pdf_python\\PDFs\")\n",
    "start_patterns = {\"序論\":re.compile(\"[1-9]*( |　)*(背景|はじめに|Abstract|序論|概要|Introduction)\")}  # これが当てはまらないものも多い\n",
    "end_patterns = {\"序論\":re.compile(\"[2-9]+( |　)*(関連研究|提案手法|従来手法|従来研究)\")}  # これが当てはまらないものも多い\n",
    "conference_name = \"SSII2019\"\n",
    "title_position_number = 2\n",
    "parse_page_numbers = [0]  # 正直これが一番重要(1枚目まで確認)\n",
    "date = datetime.datetime(2019, 6, 10, 0, 0, 0)\n",
    "\n",
    "pdf_parser = PdfParser(conference_name=conference_name,\n",
    "                       start_patterns=start_patterns,\n",
    "                       end_patterns=end_patterns,\n",
    "                       title_position_number=title_position_number,\n",
    "                       parse_page_numbers=parse_page_numbers,\n",
    "                       date=date\n",
    "                       )\n",
    "max_iter = 5\n",
    "\n",
    "dir_pdf_parser = DirectoryPdfParser(dir_path=dir_path,\n",
    "                                    pdf_parser=pdf_parser,\n",
    "                                    max_iter=max_iter\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ディクショナリのリストで取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-08T14:08:59.646968Z",
     "start_time": "2020-05-08T14:07:19.667249Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5c582c03281421f8bfd6166d39a8b9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=19.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'conf_name': 'SSII2019',\n",
      "  'content': {'序論': '製造・物流分野での労働力安定供給に向け，人の物理的な非定型作業を代替できるロボットの開発が求められている．さまざまな作業環境での代替実現には，作業環境の照明状況によらずに種々の物体を\\n'\n",
      "                    '認識できる必要がある．そこで，本研究では，画像\\n'\n",
      "                    'の局所的な鮮明度が照明条件によって変わること\\n'\n",
      "                    'に着目し，局所鮮明度に応じて対象物の類似度\\n'\n",
      "                    '評価方法を適切に自動選択する認識アーキテク\\n'\n",
      "                    'チャを開発した．倉庫作業を模擬した実験系を組\\n'\n",
      "                    'み，撮像画像内の複数対象物の照明条件がそれ\\n'\n",
      "                    'ぞれ異なる状況下において，従来手法は認識率\\n'\n",
      "                    'が 90%未満であるのに対し，提案手法では 98%\\n'\n",
      "                    '以上の認識率を達成できることを確認した．1  '\n",
      "                    '背景・目的近年，先進国を中心として，消費者ニーズの多様化に伴い，多種多様な製品・商品を扱う工場・倉庫と，そこでの従業員の物理的作業が急増してきている．今後，この人手不足の傾向に拍車が掛かることが予想される中，工場・倉庫内作業の自動化技術に対する期待が高まっている．与えられた状況を理解し，その状況に対応するための多様な非定型作業をこなすことができる自律作業ロボットが求められている．本研究では，このような自律作業ロボットの認識技術の向上を目的とする．視覚センサを用いて対象となる物品を認識することで，物品に対する高度な作業を可能と\\n'\n",
      "                    'することをめざす．対象物品の位置姿勢を認識するための有用な手法の一つとして，局所的な模様の類似度を評価する\\n'\n",
      "                    '手法が挙げられる[1]．この方法では，あらかじめ作\\n'\n",
      "                    '成したマスタデータと撮像して得た対象物の間で局所的な模様情報の類似度を計算することで多種多様\\n'\n",
      "                    'な物体の位置姿勢推定を可能とする．一方，模様の比較による物体認識の大きな技術課Copyright © SSII '\n",
      "                    '2019. All Rights Reserved.- IS1-20 '\n",
      "                    '-題の一つとして，照明や影の映りこみによって対象物の認識精度が低下することが挙げられる．照明や影の映り込みによって物体の模様が不鮮明になると模様特徴が変化してしまい，結果として位置姿勢推定に失敗することがしばしば生じる．特に，認識結果に基づいて，ロボットが対象物品の把持動作を実施する場合には，位置姿勢推定の誤りによって，対象物品あるいはロボットの破損につながる恐れがある．この問題を解決する方法として，照明映り込み部分の模様を鮮明にするための画像修正技術も提案されているが，模様にグラデーションがある物体には適用で\\n'\n",
      "                    'きないなど，その利用範囲は限定的である[2]．そこで，本研究では，照明変動によらずに対象物品の位置姿勢を正しく推定することを目的とし，画像の局所領域ごとに模様の鮮明度合いを計算し，その鮮明度に応じて適切な類似度評価方法を選択・実行\\n'\n",
      "                    'する認識アーキテクチャを提案する．'},\n",
      "  'date': '2019-06-10 00:00:00',\n",
      "  'paper_title': '',\n",
      "  'pdf_name': 'IS1-20'},\n",
      " {'conf_name': 'SSII2019',\n",
      "  'content': {'序論': '近年，画像を活用した異常検出手法は数多く提案され\\n'\n",
      "                    'ており，不良品検出や，監視カメラからの危険人物の検\\n'\n",
      "                    '出，医療の発病検知などの領域に応用されている [1{4]．\\n'\n",
      "                    'その中でも，生成モデルで通常クラスの画像を十分\\n'\n",
      "                    '学習させた後，生成モデルに画像を入力し生成された\\n'\n",
      "                    '再構成画像と，入力画像との誤差画像を基に異常を検\\n'\n",
      "                    '出する手法が代表的である．生成モデルとして Auto-\\n'\n",
      "                    'Encoder (AE) を応用した異常検出手法 [5] や，Vari-\\n'\n",
      "                    'ational Auto-Encoder (VAE) [6] を応用した手法 [7]，\\n'\n",
      "                    'Generative Adversarial Networks (GAN) [8] を活用し\\n'\n",
      "                    'た手法 [9] が既に提案されている．その中でも，GAN\\n'\n",
      "                    'を活用した手法 [9] は，精度が良いものの，識別時に再\\n'\n",
      "                    '構成画像と入力画像との誤差の最小化計算のコストが\\n'\n",
      "                    'かかる問題 [10] や，最小化中に初期値によっては局所\\n'\n",
      "                    '解に陥ってしまう問題がある．そこで，VAE を用いて\\n'\n",
      "                    'GAN の初期値を決めることで，常に入力画像に近い生\\n'\n",
      "                    '成画像を出力する VAEGAN [11] の活用が必要である\\n'\n",
      "                    'と考える．一方で，実世界での利用を想定した場合，入力画像\\n'\n",
      "                    'にはノイズが多く含まれる．生成モデルでは平均的な\\n'\n",
      "                    '画像を出力するため，入力画像にノイズが混入してい\\n'\n",
      "                    'る場合，モデルはノイズの少ない画像を生成する．そ\\n'\n",
      "                    'のため，ノイズ部には再構成誤差が生じる．前述した\\n'\n",
      "                    '手法では，画像全体の再構成誤差の大きさにより判定\\n'\n",
      "                    'を行っているため，異常に起因する誤差と，ノイズに\\n'\n",
      "                    '起因する誤差を分ける必要がある．しかし，これらの\\n'\n",
      "                    '手法では，その機構がない．すなわち，ノイズ部の誤\\n'\n",
      "                    '差と本来の異常領域の誤差の区別ができなく，ノイズ\\n'\n",
      "                    'への頑健性が懸念される．そこで我々は以前，異常ク\\n'\n",
      "                    'ラスの一部を教示し，識別に必要となる領域に焦点を\\n'\n",
      "                    '当てることで，ノイズに頑健な手法を提案した [12,13]．\\n'\n",
      "                    'ところが，異常画像の一部を事前に知り得る必要があ\\n'\n",
      "                    'り，それらが未知の場合は根本的な問題となる．そこで本稿では，まず，先の局所解の問題を解決する\\n'\n",
      "                    'ために，VAEGAN を用いた異常値判検出手法を提案す\\n'\n",
      "                    'る．次に，ノイズへの頑健性を向上させるために，VAE-\\n'\n",
      "                    'GAN の Discriminator から Region-of-interest (ROI)\\n'\n",
      "                    'を算出し，それを再構成誤差の重み付けに活用する手Copyright © SSII 2019. All Rights '\n",
      "                    'Reserved.- IS1-02 -図 1: 提案手法の概要図．‘0’ が正常クラスであり，‘4’\\n'\n",
      "                    'の画像が入力された時の手法による異常度合いの違い．\\n'\n",
      "                    'Na(cid:127)(cid:16)ve に VAEGAN を用いた手法では，ピンクの領域が\\n'\n",
      "                    'ノイズの有無に起因しているため，判別に悪影響を及\\n'\n",
      "                    'ぼしてしまう．法を提案する．そして，VAE，GAN を活用した従来手\\n'\n",
      "                    '法と比較実験を実施し，評価する．提案手法の概略図\\n'\n",
      "                    'を図 1 に示す．'},\n",
      "  'date': '2019-06-10 00:00:00',\n",
      "  'paper_title': 'VAEGAN の再構成誤差と Discriminator の ROI を活用した異常検出',\n",
      "  'pdf_name': 'IS1-02'},\n",
      " {'conf_name': 'SSII2019',\n",
      "  'content': {'序論': '橋梁や道路，トンネルなどの社会インフラは年々増加している．これらの設備は建設後，使用とともに徐々に老朽化するため，定期的な検査が必要である．一般的に，構造物の検査には非破壊検査が用いられており，特に内部欠陥や厚さの測定には超音波厚さ測定が用いられる．超音波厚さ測定はソーナーの原理と同じで，超音波が往復する時間差によって所定の位置の厚さ（長さ）を求める検査方法である．測定器具の取扱いや計測データの解釈には専門的知識及び時間を必要とするため，大規模な測定は困難\\n'\n",
      "                    'である．このような課題に対し，本研究ではCNN によ\\n'\n",
      "                    'り測定データから超音波エコーを検出し，厚さを求める手法を提案する．実験の結果，専門的知識を必要\\n'\n",
      "                    'としなくても 95%のデータの厚みを測定でき，本手法\\n'\n",
      "                    'の有効性が確認できた．1  '\n",
      "                    'はじめに金属やコンクリートなどの厚さを測定する場合，ノギスやマイクロメータ等の物体を挟み込んで測定する厚さ測定器が使用される．測定対象物がタンクや配管など，物理的にこれらの測定器を使用できない場合は，非破壊検査手法のひとつである，超音波厚さ\\n'\n",
      "                    '測定（UTM：Ultrasonic Thickness Measurement）が用\\n'\n",
      "                    'いられることが多い．超音波厚さ測定とは，超音波探触子で発生した超音波を測定対象物に入射し，その反射波を計測することによって対象物の厚さを測定する検査方法である．超音波が測定対象物に垂直もしくは設定した任意の角度で入射し，所定の位置で反射することを前提とするため，測定器具の取扱いや計測データの読み取りに専門的技量を必要とする．そのため，超音波厚さ測定は他の非破壊試験と同様\\n'\n",
      "                    'に，日本工業規格（JIS）で測定方法が規定されてい\\n'\n",
      "                    'る[1]．また，各種法定検査では認定技術者による検\\n'\n",
      "                    '査が求められている．一方，国土交通省の予測によCopyright © SSII 2019. All Rights '\n",
      "                    'Reserved.- IS1-03 '\n",
      "                    '-ると，高度経済成長以降に整備されたインフラ設備が今後一斉に老朽化するとされており，効率的な維\\n'\n",
      "                    '持管理が喫緊の課題となっている．超音波厚さ測定や類似検査である超音波探傷試験では，探触子を自動で移動走査することによる自\\n'\n",
      "                    '動計測システム[2]は開発されているものの，計測デ\\n'\n",
      "                    'ータから測定値を算出する部分には言及されていない．一般に，超音波厚さ測定では計測データ中の超音波エコーから測定対象物の厚さを求めているが，超音波エコーの妥当性は目視で確認している．その確認に多大な時間を要するため省力化が課題となっている．本研究では，超音波厚さ測定における計測\\n'\n",
      "                    'データから Convolutional  Neural  Network  (CNN)を\\n'\n",
      "                    '用いて超音波エコーを検出し，厚さを算出する手法\\n'\n",
      "                    'を提案する．2  '\n",
      "                    '超音波厚さ測定（UTM）超音波厚さ測定は，超音波探触子から発生した超音波パルスを測定対象物に入射し，その伝搬時間をもとに対象物の厚さを求める方法である．探触子で発生した超音波を効率よく測定対象物に入射させるために，対象物を水などの媒質内に沈めて測定されることが多い．ここでは，超音波パルスが対象物中を図 '\n",
      "                    '1 に示すように，厚さ(cid:1830)の測定対象物中に超音往復する時間を計測することで厚さを求める，パルス\\n'\n",
      "                    '反射法について説明する．波探触子から超音波パルス T を送信したとき，T の一\\n'\n",
      "                    '部は対象物の表面で反射し，探触子で受信される．図 1.  超音波厚さ測定の概略図'},\n",
      "  'date': '2019-06-10 00:00:00',\n",
      "  'paper_title': '超音波厚さ測定の効率化のためのエコー検出手法',\n",
      "  'pdf_name': 'IS1-03'},\n",
      " {'conf_name': 'SSII2019',\n",
      "  'content': {'序論': '近年，自動車産業において交通事故減少や利便性向\\n'\n",
      "                    '上のために自動運転のシステムが開発されている．自動\\n'\n",
      "                    '運転の確立には，高度な周辺環境認識が重要となり，特\\n'\n",
      "                    'に交通弱者である歩行者を認識することが極めて重要\\n'\n",
      "                    'となる．本研究では，逆光や夜間などの，照明変化に頑\\n'\n",
      "                    '健な LIDAR を用いた歩行者検出に着目する．LIDAR\\n'\n",
      "                    'を用いた歩行者検出では，2 人以上の歩行者群を検出す\\n'\n",
      "                    'る方法は確立されてない．本研究では，2 人以上の歩行\\n'\n",
      "                    '者群を適切に分割して単独歩行者として検出するため\\n'\n",
      "                    'に，k-means++法 [1] による歩行者群分割を提案する．\\n'\n",
      "                    'さらに，k-means++法の分割数を手動決定しなければ\\n'\n",
      "                    'ならない問題点を解決するため，シルエット値 [2] を用\\n'\n",
      "                    'いる手法を提案した．2 LIDAR を用いた歩行者検出従来の LIDAR による歩行者検出の 1 '\n",
      "                    'つである，Ki-\\n'\n",
      "                    'dono らによる歩行者検出 [3] について述べる．歩行者\\n'\n",
      "                    '検出の流れを図 1 に示す．歩行者検出の大きな流れとし\\n'\n",
      "                    'て，歩行者データと非歩行者データを用いた検出器の\\n'\n",
      "                    '構築と，検出器による歩行者検出の 2 つに分けられる．図 1 歩行者検出の流れCopyright © SSII '\n",
      "                    '2019. All Rights Reserved.- IS1-04 -第25回画像センシングシンポジウム2.1 '\n",
      "                    'LIDAR による三次元点群データの取得歩行者検出を行うために，まず，LIDAR を用いて三\\n'\n",
      "                    '次元点群データを取得する．車載カメラ映像と取得した\\n'\n",
      "                    'データを可視化したものを図 2，図 3 に示す．可視化に\\n'\n",
      "                    'は三次元点群情報を取り扱うことのできる Point Cloud\\n'\n",
      "                    'Library(PCL) を利用している．図 2 車載カメラ映像図 3LIDAR による三次元点群データ2.2 '\n",
      "                    '路面平面の決定その後，取得した三次元点群データから路面平面を\\n'\n",
      "                    '決定するために，PCL の平面検出を行い，以下の平面\\n'\n",
      "                    'の方程式を得る．ax + by + cz = d(1)2.3 '\n",
      "                    'グリッドマップを用いた立体物検出路面平面を決定した後，グリッドマップを用いて立\\n'\n",
      "                    '体物検出を行う．立体物の検出はまず，図 4 のような\\n'\n",
      "                    '路面平面に平行なグリッドマップを作成する．その後，'},\n",
      "  'date': '2019-06-10 00:00:00',\n",
      "  'paper_title': '歩行者群分割',\n",
      "  'pdf_name': 'IS1-04'},\n",
      " {'conf_name': 'SSII2019',\n",
      "  'content': {'序論': '機械学習技術や IoT  (Internet  of  Things)，M2M \\n'\n",
      "                    '(Machine  to  Machine)  によるセンサネットワークの広\\n'\n",
      "                    'がりとともに，例えば日常生活での見守りサービスや，生産現場での生産性改善など，センサデータを用い\\n'\n",
      "                    'た行動分析アプリケーションが提案されている．ところで，従来の行動分析技術は，その多くが教師あり学習に基づいて検討されている．教師あり学習は，事前に人手による教師データの作成等が必要であり，これにかかる手間と時間とが実用化の際には大\\n'\n",
      "                    'きな課題となる．本稿では上記の課題を解決した行動分析アプリケーションの実現を目的として，教師なし学習に基づく\\n'\n",
      "                    '行動分析アルゴリズムを提案する．提案手法が対象とするのは，とくに日常生活や生産現場等で見られる，同じ動作が繰り返される行動である．複数回繰り返された動作のセンサデータ同士を，動作要素ごとに分節化して比較することで，教師データを与えることなく，標準的な動作パターンを\\n'\n",
      "                    '決定するとともに非標準動作を検出する．'},\n",
      "  'date': '2019-06-10 00:00:00',\n",
      "  'paper_title': '',\n",
      "  'pdf_name': 'IS1-05'}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'conf_name': 'SSII2019',\n",
      "  'content': {'序論': '放牧における牛の監視作業は，労働の負担が大きい\\n'\n",
      "                    '一方で，個体の状態を管理し病気や怪我の牛を早期発見\\n'\n",
      "                    'するために重要である．本稿ではドローンを用いて撮影\\n'\n",
      "                    'した空撮画像から乳牛の模様によって個体識別を行い，\\n'\n",
      "                    'それによる個体ごとの監視を目指す．空撮画像では牛\\n'\n",
      "                    'の向きは不揃いであるが，牛の識別を行う際には，体の\\n'\n",
      "                    '向きが揃っていた方が識別精度がよいと予測される．こ\\n'\n",
      "                    'のため，畳込みニューラルネットワーク (CNN) である\\n'\n",
      "                    'YOLOv3 を用いてまず牛の体と頭部を検出し，画像に\\n'\n",
      "                    'おける牛の体軸整合を行う．その後 Siamese Network\\n'\n",
      "                    'を用いて乳牛の模様の類似度による個体識別を行う．従\\n'\n",
      "                    '来手法であるテンプレートマッチングと比較し，提案\\n'\n",
      "                    '手法の有効性を確認した．1 はじめに畜産農家の作業時間の中で，大きな割合を占めるの\\n'\n",
      "                    'は監視作業である．その中でも病気や怪我をした牛の\\n'\n",
      "                    '早期発見が重要である．近年，一戸あたりの牛飼養頭\\n'\n",
      "                    '数は増加する一方，労働人口は高齢化しており，農家\\n'\n",
      "                    'の管理負担が増している．放牧の監視作業の負担を軽\\n'\n",
      "                    '減するため，長期的なコストが少ない，保守運用が楽\\n'\n",
      "                    'などのメリットを持つコンピュータビジョンを用いた\\n'\n",
      "                    '監視が注目されている．特に，広い範囲にわたる放牧\\n'\n",
      "                    '地をカバーできるドローンによる空撮画像の使用が有\\n'\n",
      "                    '望である．本稿は，ドローンによる空撮画像から乳牛の個体識\\n'\n",
      "                    '別を目指す．これにより，遠隔地から牛を個体ごとに観\\n'\n",
      "                    '察することが可能となり，農家の支援につながる．空\\n'\n",
      "                    '撮画像では対象物が様々な向きで写されるが，個体識\\n'\n",
      "                    '別のためには，体の向きが揃っている方が精度が良い\\n'\n",
      "                    'ことが期待される．そこで，YOLOv3 [1] を用いた牛の\\n'\n",
      "                    '体と頭部の検出を行い，これに基づいて個体の向きを\\n'\n",
      "                    '揃える体軸整合を行う．また，模様による個体識別に\\n'\n",
      "                    'ついては類似度学習を行う Siamese Network [2] を用い\\n'\n",
      "                    'る．実験では，Siamese Network を用いる場合とテン\\n'\n",
      "                    'プレートマッチングを用いる場合の比較を行い，また\\n'\n",
      "                    'それぞれでは体軸整合の処理の有無による比較も行う．Copyright © SSII 2019. All '\n",
      "                    'Rights Reserved.- IS1-06 -図 1: 手法の概要'},\n",
      "  'date': '2019-06-10 00:00:00',\n",
      "  'paper_title': 'ドローンによる牧場空撮画像における乳牛の個体識別',\n",
      "  'pdf_name': 'IS1-06'},\n",
      " {'conf_name': 'SSII2019',\n",
      "  'content': {'序論': '医療，建築の分野において，3 '\n",
      "                    '次元物体の形状を非接触で計測することは，利便性の面で重要である．現在の主な手法は、ステレオ画像法，光レーダー法，光切断法，照度差ステレオ法，焦点調節法，等高線\\n'\n",
      "                    '計測法が存在する[1]．これらの手法の中で，等高線\\n'\n",
      "                    '計測法に分類されるモアレトポグラフィがある．この手法は，身近な利用例を挙げると医療分野において，人体の骨格の形状を診断する際に用いられてきた．また，近年では格子や干渉縞の位相解析を行うことで，高精度になってきている．そして、モアレトポグラフィを基礎とし，デジタルカメラの走査線を利用した\\n'\n",
      "                    'サンプリングモアレ法が考案されている[2]．本研究の目的は，上記のような非接触 3 次元形状\\n'\n",
      "                    '計測によって患者の腹部や胸部の動態を認識し，緊\\n'\n",
      "                    '急搬送中のトリアージ判定や ICU での継続的な容態\\n'\n",
      "                    'モニタリングを実現することである．そのために，上記手法を動的な計測システムへと拡張する必要がある．\\n'\n",
      "                    '本論文では，2 章でサンプリングモアレ法の原理を説\\n'\n",
      "                    '明し，3 章でこれにアクティブステレオ法を組み込ん\\n'\n",
      "                    'だ動的 3 時限形状計測手法を提案し，人の腹部に適\\n'\n",
      "                    '用した実験結果を述べ，4 章で結論をまとめる．2  モアレトポグラフィ2.1  '\n",
      "                    'モアレ法すだれを二枚重ねると，元のすだれにない新しい縞模様が現れる場合がある．これをモアレ縞と言い，細かな縞どうしの干渉によって，より周波数の低い縞模様が見える現象である．そして，この干渉縞を使っ\\n'\n",
      "                    'て計測を行う手法がモアレ法である．図 1(a)の等間隔の基準格子に，その格子が少し\\n'\n",
      "                    '変形した図 1(b)の試料格子を重ねると，図 1(c)のよう\\n'\n",
      "                    'に元の格子にない，より周波数の低い新たなモアレ\\n'\n",
      "                    '縞が発生する．Copyright © SSII 2019. All Rights Reserved.- '\n",
      "                    'IS1-07 '\n",
      "                    '-基準格子の黒い線と試料格子の黒い線が重なった部分，基準格子の白い線と試料格子の白い線が重なった部分に，白い線ができている。また，基準格子の黒い線と試料格子の白い線が重なった部分，基準格子の黒い線と試料格子の白い線が重なった部分に，黒い線ができている．これがモアレ縞である．\\n'\n",
      "                    'なお，図 1(b)の変形した試料格子をデジタルカメラな\\n'\n",
      "                    'どで撮影しても，図 1(d)に示すようなモアレ縞が発生\\n'\n",
      "                    'する場合がある．これは，後述するサンプリングモア\\n'\n",
      "                    'レ法で利用される．一つの連なるモアレ縞は変形量の等しい等変位線となっているので，このモアレ縞を解析することにより，試料格子の変位やひずみを解析できる．これをモアレ法と言う．また，プロジェクター等を用い，基準格子を三次元物体に投影し，その物体を基準格子と重ねると，モアレ縞が発生する．この干渉縞を解析することで，本研究の目的である三次元形状を計測する\\n'\n",
      "                    'ことができる．これをモアレトポクラフィと呼ぶ[3]．図 1  等変位線を示すモアレ縞の説明:  (a)  基準\\n'\n",
      "                    '格子，(b)  試料格子，(c)  図(a)と(b)の重ねあわせに\\n'\n",
      "                    'よって生じるモアレ縞，(d)  デジタルカメラで撮影され\\n'\n",
      "                    'た画像によって得られるモアレ縞，[2]より転載'},\n",
      "  'date': '2019-06-10 00:00:00',\n",
      "  'paper_title': '',\n",
      "  'pdf_name': 'IS1-07'},\n",
      " {'conf_name': 'SSII2019',\n",
      "  'content': {'序論': '油圧ショベルに搭載した３台の単眼カメラの画像をリアルタイムに画像認識し、人らしい像があればモニタ表示と音で知らせる機能を開発した。動作イメージを図１に示す。油圧ショベルは人と比べて大型で、重量が大きく動きも速いうえ、走行だけでなく旋回動作もある。周辺に作業者や障害物が混在する現場では、安全確保のため、確実かつ広範囲の周辺確認が求められる。しかしながら、車体の左前方にある運転室からは、エンジンフードやカウンターウェイトが視界を遮るため、特に車体後方と右側方にオペレータから直接目視できない死角が多い。そこでミラーやカメラ\\n'\n",
      "                    'で周辺確認を可能にする必要がある。従来機能の画像合成処理[1]  '\n",
      "                    '[2]は、油圧ショベルの後方、右側方、左側方に、広角、高感度でダイナミックレンジが広い単眼カメラを３台搭載し、それらの画像をリアルタイムに合成して運転室内のモニタに表示する事で、油圧ショベルの後方２７０度をひと目で確認可能にした。カメラ配置と合成画像の例を図２に示す。ＦＰＧＡによるパイプライン処理で、フレームレート低下なく画像を合成表示する。車体のごく近傍から地平線の上空までカバーする事で大型の物体も全体を映し出せる視野の広さ、旋回動作を伴う油圧ショベルに好適な円形画像、直感的な分かりやすさが特徴である。２０１１年に油圧ショベルのオプションとして\\n'\n",
      "                    '販売を開始、その後標準装備とした。しかしながら、モニタ確認のタイミングはオペレータによって異なるため、例えば作業に集中してモニタから目を離しているすきに、周辺の作業者が油圧ショベルに接近してしまう状況が想定される。そこで、カメラ画像を認識して、人らしい像があればモニタ表示と音で知らせることで、オペレータに周辺確認のきっかけを与える機能を開発した。既設の単眼カメラの画像認識のみで、ローコストで簡便なシステム構成としながら、合成映像がカバーする範囲全体を画像認識する事が目的である。本稿ではこれらを実現するにあたCopyright '\n",
      "                    '© SSII 2019. All Rights Reserved.- IS1-08 '\n",
      "                    '-っての技術課題と解決方策、および実際の動作事例\\n'\n",
      "                    'を紹介する。2  目標・課題開発目標は以下とした。本章では、目標達成のための技術課題を説明する。目標１.  '\n",
      "                    '画像認識のみによる人らしさ評価 \\n'\n",
      "                    '目標２.  ３方向のカメラ画像を毎秒１０回以上認識 \\n'\n",
      "                    '目標３.  小型で安価な車載装置2.1  画像上での人の見かけ変化 \\n'\n",
      "                    '背景と服装の色のコントラスト、上半身と下半身で色が異なる服装、携行品、カメラに対する位置や向き、ポーズなど、画像上の人の見かけは多様に変化する。また、人の身長よりも高い油圧ショベルの車体上面にカメラを設置するため、人がカメラに接近した場合と離れた場合では、像の大きさだけでなく、頭と体の像の比率など見かけが変化する。画像の例を図３に示す。本開発では想定する人を歩行者に限定したが、それでもあらゆる見かけ変化を想定して人らしさを数\\n'\n",
      "                    '値化するアルゴリズムの手動設計は困難である。2.2  広角カメラ画像の歪み \\n'\n",
      "                    '後方カメラと側方カメラの境界部も隙間無く撮影するために広角カメラを採用し、車体のごく近傍から遠方までをカバーするために斜め下向きに設置する。これにより視野の左右端では物体の像が傾いて映り、視野の下端には車体の像が映りこむ場合がある。画像の例を図４に示す。人らしさを評価するために像を囲む注目領域を設定すると、一部が画像範囲外や\\n'\n",
      "                    '車体の像に及び、画像情報が欠損する。2.3  画像認識処理サイクルの高速化と安定化 \\n'\n",
      "                    '計算回数が多い画像認識処理を安定した時間サイクルで実行し続ける必要がある。ＦＰＧＡでハード化して処理時間のばらつきを低減するが、ローコストな'},\n",
      "  'date': '2019-06-10 00:00:00',\n",
      "  'paper_title': '',\n",
      "  'pdf_name': 'IS1-08'},\n",
      " {'conf_name': 'SSII2019',\n",
      "  'content': {'序論': '畳み込みニューラルネットワーク  (CNN)  を用いた\\n'\n",
      "                    'セマンティックセグメンテーションはコンピュータビジョンにおける基本的な問題の一つである．本稿では，\\n'\n",
      "                    'Encoder-Decoder 構 造 の ネ ッ ト ワ ー ク に 導 入 す る\\n'\n",
      "                    'Class の観点からの Attention 機構を提案する．  Class\\n'\n",
      "                    'の観点からの Attention 機構では，クラス領域を学習\\n'\n",
      "                    'しながら復元された特徴情報に注目する．これにより各クラスのセグメンテーションに重要な特徴情報に焦点を当てるようになるため，より正確に結果を生成す\\n'\n",
      "                    'ることが可能となる．本稿では CamVid データセットを\\n'\n",
      "                    '用いて評価し，従来手法よりも高い精度が得られた．1  はじめに画像内の各画素に対してクラス推定を行うセマン\\n'\n",
      "                    'ティックセグメンテーション[2,  3,  5]は，コンピュータビ\\n'\n",
      "                    'ジョンにおける基本的な問題の一つであり，自動運転や医学など様々な分野に応用され始めている．近年，画像認識問題において非常に高い認識精度を\\n'\n",
      "                    '実現した畳み込みニューラルネットワーク(CNN)[1]に\\n'\n",
      "                    '基づいた Encoder-Decoder 構造を採用した手法が数\\n'\n",
      "                    '多く提案されている．従来のセマンティックセグメンテーション手法では，あるクラスに属する物体の一部を異なるクラスであると誤って識別してしまうことがある．これは画像内に存在する各物体を画素単位で学習していたため，クラス間の区別が上手く出来ていないことが原因であると考えられる．この問題を対処する\\n'\n",
      "                    'ため，Encoder-Decoder 構造のネットワークに導入す\\n'\n",
      "                    'る Class の観点からの Attention 機構を提案する．Class の観点からの Attention '\n",
      "                    '機構は，セグメンテー\\n'\n",
      "                    'ションのために各クラス領域を学習しながら，それらを用いて特徴情報に注目する工程である．これにより重要な特徴情報のみ逐次焦点を当てるようになるた\\n'\n",
      "                    'め，より正確に結果を生成することが可能となる．実験では，車載カメラにより撮影された画像を 11 '\n",
      "                    'クCopyright © SSII 2019. All Rights Reserved.- IS1-09 -堀田  '\n",
      "                    '一弘ラスでラベル付けされた CamVid データセット[4]を使\\n'\n",
      "                    '用し，評価指標には IoU(Intersection over Union) [5]\\n'\n",
      "                    'を用いた．その結果，提案手法は従来のセグメンテ\\n'\n",
      "                    'ーション手法よりも高い精度を得ることができた．本論文は以下のように構成される．2 節では関連\\n'\n",
      "                    '研究，3 節では提案手法について述べる．また，4 節\\n'\n",
      "                    'で評価実験の結果を示し，5 節にまとめを述べる．'},\n",
      "  'date': '2019-06-10 00:00:00',\n",
      "  'paper_title': '',\n",
      "  'pdf_name': 'IS1-09'},\n",
      " {'conf_name': 'SSII2019',\n",
      "  'content': {'序論': '自転車競技を始めとした広域で高速に動くスポーツ\\n'\n",
      "                    'において, ユーザへの情報提示並びに誤差蓄積のない光\\n'\n",
      "                    '学的な姿勢推定を一つのシステムで同時に行うことは\\n'\n",
      "                    '一般に困難である. 本稿では, ベクタ型レーザ投影によっ\\n'\n",
      "                    'て人への情報提示と高速カメラの姿勢推定のためのマー\\n'\n",
      "                    'カー提示を両立させる手法を検討する. これは, 人への\\n'\n",
      "                    '提示曲線を時空間的に分割することで高速カメラから\\n'\n",
      "                    'はマーカとして利用できるが, 人間にはマーカであるこ\\n'\n",
      "                    'とを知覚されにくい描画を実現するものである. 実験で\\n'\n",
      "                    'はスクリーンへ提案手法で描画される円を投影し, 静止\\n'\n",
      "                    '状態の高速カメラから撮像した動画を用いてカメラの\\n'\n",
      "                    '姿勢推定を行い, 姿勢推定精度を評価した.1 はじめにスポーツにおける身体・使用機材のセンシングとフィー\\n'\n",
      "                    'ドバック技術が, 競技力向上を目的として重要性を増し\\n'\n",
      "                    'ている. 自転車競技タイムトライアル種目においては,\\n'\n",
      "                    '選手と機材の物理的・生理学的なモデルからペース配\\n'\n",
      "                    '分を最適化できることが知られている [1]. 中でもトラッ\\n'\n",
      "                    'ク種目においては, 路面抵抗を一定とみなすことができ,\\n'\n",
      "                    '路面のトポロジも事前に調べられることから, 物理モデ\\n'\n",
      "                    'ルによって非常に正確な予測ができる可能性がある [2].\\n'\n",
      "                    '一方で高速に周回しているという性格上, 自転車はほと\\n'\n",
      "                    'んど傾いているため, 地面に対する自転車の姿勢推定が\\n'\n",
      "                    'モデルの入力として重要となる.これらの最適化は従来オフラインで行われ, 選手は事\\n'\n",
      "                    '前に算出された数値を競技前に記憶することによって活\\n'\n",
      "                    '用してきた. 一方で, 競技者に音声 [3] や触覚振動 [4] に\\n'\n",
      "                    'よって即時フィードバック [5][6] を与えれば, より効率\\n'\n",
      "                    '的な競技結果の向上が期待される. 本研究ではこれらを\\n'\n",
      "                    'トラックで実現するために, 高速 (~20m=s) かつ広範囲\\n'\n",
      "                    '(~100m 四方) で移動する自転車の姿勢推定と, 乗車して\\n'\n",
      "                    'いる人間への情報提示を同時に実現するためのマーカ\\n'\n",
      "                    'を提案する.このマーカを利用する系は, 将来的に図 1 に示す構\\n'\n",
      "                    '成を想定している. 環境側に設置するレーザプロジェクCopyright © SSII 2019. All '\n",
      "                    'Rights Reserved.- IS1-10 -図 1 将来的な全体像図 2 '\n",
      "                    'ベクタ型レーザプロジェクションの例タ, 投影された提示画像, ユーザを含む移動体（自転車）\\n'\n",
      "                    'に取り付ける高速カメラからなる. ベクタ型レーザプロ\\n'\n",
      "                    'ジェクションとは, ガルバノミラーに代表される機構に\\n'\n",
      "                    'よってレーザの光軸を高速に制御して描くことのでき\\n'\n",
      "                    'る線分を用いた画像投影手法を指し, 図 2 に例を示す.\\n'\n",
      "                    '姿勢推定を行うためのマーカは, 情報提示のための画像\\n'\n",
      "                    '中に埋め込まれ, ユーザに意識されることなく, 移動体\\n'\n",
      "                    'にとりつけた小型の高速カメラからはデコードするこ\\n'\n",
      "                    'とができる. 本論文では, このマーカの埋め込み手法と,\\n'\n",
      "                    '静止状態における姿勢推定の安定性の評価を行う.'},\n",
      "  'date': '2019-06-10 00:00:00',\n",
      "  'paper_title': 'ベクタ型レーザ投影における自己位置推定のためのマーカ埋め込み手法の検討',\n",
      "  'pdf_name': 'IS1-10'}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'conf_name': 'SSII2019',\n",
      "  'content': {'序論': '固有画像分解は，入力画像を照明成分と反射率成分\\n'\n",
      "                    'に分解する手法である．反射率成分を正確に推定する\\n'\n",
      "                    'ことは，環境光による外乱を最小限に抑えることに相当\\n'\n",
      "                    'する．画像を照明成分と反射率成分の積として表現する\\n'\n",
      "                    'Retinex 理論を基礎として，近年では畳み込みニューラ\\n'\n",
      "                    'ルネットワーク (CNN) を用いた手法が提案されている．\\n'\n",
      "                    '正解画像を大量に用意することが著しく困難なこの問題\\n'\n",
      "                    '設定において，人工的に合成した画像を用いる従来手法\\n'\n",
      "                    'では，その結果に色ムラやにじみなどの不自然さが見ら\\n'\n",
      "                    'れた．本研究では，Encoder-Decoder 構造の CNN と，\\n'\n",
      "                    'その入力に Generative Adversarial Networks(GAN) に\\n'\n",
      "                    'よって生成した画像群を用いる枠組みを提案する．CNN\\n'\n",
      "                    '構造の最適化に加え，実世界における環境光のデータ\\n'\n",
      "                    '分布に基づき生成した画像群を入力とすることで，低\\n'\n",
      "                    '光量のテスト画像に対して，従来手法と比較してより自\\n'\n",
      "                    '然で視認性の高い反射率画像を得た．セマンティック・\\n'\n",
      "                    'セグメンテーションによる評価実験では，本手法で得\\n'\n",
      "                    'た反射率画像を用いて学習およびテストを行うことで，\\n'\n",
      "                    '環境光が画素値に与える悪影響が緩和され，識別精度\\n'\n",
      "                    'が向上することを確認した．2 はじめに一般物体認識やセマンティック・セグメンテーション\\n'\n",
      "                    'をはじめとするコンピュータビジョンのタスク全般に\\n'\n",
      "                    'おいて，その精度に悪影響をもたらす外乱として，シー\\n'\n",
      "                    'ンの照明状況が挙げられる．画像を通して観測される\\n'\n",
      "                    '物体の色情報は照明状況に強く依存し，環境変化が激\\n'\n",
      "                    'しい実空間において問題となる．特に，環境光の乏し\\n'\n",
      "                    'い暗部あるいは逆光条件下において物体の色情報は大\\n'\n",
      "                    'きく失われ，有効な画像特徴を抽出するにあたって障\\n'\n",
      "                    '害となる．そのため，画像の視認性を改善させる画像\\n'\n",
      "                    '処理技術への需要は高く，古くから活発に研究されて\\n'\n",
      "                    'いる分野である．\\n'\n",
      "                    '\\u3000一方，人間の視覚にはこのような外乱に適応する能\\n'\n",
      "                    '力が備わっており，異なる照明状況下においても同様に\\n'\n",
      "                    '物体を知覚できることが知られている．例えば，赤い\\n'\n",
      "                    'リンゴを明るい部屋と暗い部屋で撮影した場合を考えCopyright © SSII 2019. All Rights '\n",
      "                    'Reserved.- IS1-11 -(a) 入力画像 S(b) 反射率画像 R(c) 照明画像 I図 1: '\n",
      "                    '固有画像分解ると，リンゴの領域の RGB 画素値は部屋の明暗によっ\\n'\n",
      "                    'て大きく異なるはずだが，人間はどちらの環境におい\\n'\n",
      "                    'てもリンゴは同じく赤いものであるとして知覚できる．\\n'\n",
      "                    'この視覚特性は色恒常性と呼ばれ，物体の色や明るさ\\n'\n",
      "                    'をその周辺との分光反射率の比のみで知覚することで，\\n'\n",
      "                    '変化する照明状況に対して見え方が自動的に補正され\\n'\n",
      "                    'るという性質をあらわしている．\\n'\n",
      "                    '\\u3000この人間が持つ色恒常性をコンピュータビジョンに\\n'\n",
      "                    '応用する手法として，固有画像分解 (図 1) が挙げられ\\n'\n",
      "                    'る．シーンで撮影された入力画像 (a) を，物体の反射\\n'\n",
      "                    '率を RGB 値に変換した反射率画像 (b) と，物体の色成\\n'\n",
      "                    '分を一切持たず環境光のみに依存する照明画像 (c) に分\\n'\n",
      "                    '解する．反射率画像を正確に推定することは，環境光\\n'\n",
      "                    'による外乱の影響を最小限に抑えることと同義であり，\\n'\n",
      "                    'コンピュータビジョンにおいては，固有画像分解によっ\\n'\n",
      "                    'て人間の色恒常性のようなロバスト性を実現できると\\n'\n",
      "                    '考えられる．\\n'\n",
      "                    '\\u3000多くの有用な固有画像分解手法は Retinex 理論 [1] [2]\\n'\n",
      "                    'を基礎にしている．Retinex は Retina (網膜) と Cor-\\n'\n",
      "                    'tex(大脳皮質) を合わせた造語で，人間の脳による光や\\n'\n",
      "                    '色の知覚をモデル化する．Retinex 理論では，入力画像\\n'\n",
      "                    'S と反射率画像 R，照明画像 I の関係を次の式であら\\n'\n",
      "                    'わす．S = R・I(1)式 (1) は 2 つの未知変数を持つ不良設定問題であるた\\n'\n",
      "                    'め，1 枚の入力画像から Retinex 理論による固有画像分\\n'\n",
      "                    '解を行うためには，何らかの仮定を設ける必要がある．\\n'\n",
      "                    '実用上は，照明成分の勾配に滑らかさを仮定して，入\\n'\n",
      "                    '力画像に平滑化フィルタを畳み込んだ結果を照明画像'},\n",
      "  'date': '2019-06-10 00:00:00',\n",
      "  'paper_title': 'CNN を用いた固有画像分解による低光量画像の視認性改善',\n",
      "  'pdf_name': 'IS1-11'},\n",
      " {'conf_name': 'SSII2019',\n",
      "  'content': {'序論': 'デジタル画像処理技術は幅広い分野において様々な\\n'\n",
      "                    '用途で活用されるようになり，様々なアプリケーショ\\n'\n",
      "                    'ンが登場している．多くのアプリケーションにおいて，\\n'\n",
      "                    '高品質な画像の撮像は高性能化に不可欠である．しか\\n'\n",
      "                    'し，カメラの CCD の微細化や画像の高画素化が進んで\\n'\n",
      "                    'おり，回折現象によるボケの発生，そして画素あたりの\\n'\n",
      "                    'ノイズレベルの増加による画像の品質低下に繋がって\\n'\n",
      "                    'いる．そこで，多くのアプリケーションの高性能化に\\n'\n",
      "                    'おいては画像のノイズ除去やボケ除去アルゴリズムの\\n'\n",
      "                    '高精度化が重要となる．また，ノイズ除去やボケ除去\\n'\n",
      "                    'の結果はアプリケーション全体の基盤となるため，全体\\n'\n",
      "                    'の処理のボトルネックとなることが多い．しかし，ノ\\n'\n",
      "                    'イズ除去やボケ除去には処理精度と計算コストの間に\\n'\n",
      "                    'トレードオフがあり，数多く存在する高精度な処理手\\n'\n",
      "                    '法は計算コストが高いという問題点を持つ．そのため，\\n'\n",
      "                    'リアルタイムな動画像処理を行うことが多くなった現\\n'\n",
      "                    '代においては，処理精度と計算コストのバランスが良\\n'\n",
      "                    'い手法の検討が不可欠である．ノイズ除去手法においては BM3D [1] が state-of-the-\\n'\n",
      "                    'arts の性能を持つ手法として知られている．そして，こ\\n'\n",
      "                    'の BM3D の簡易版である離散コサイン変換 (Discrete\\n'\n",
      "                    'Cosine Transform: DCT) を利用した，DCT デノイジ\\n'\n",
      "                    'ング [2] はノイズ除去精度と計算コストのバランスに優\\n'\n",
      "                    'れた手法である．そこで，本研究ではノイズ除去精度が高く実用的な\\n'\n",
      "                    'ノイズ除去手法の実現を目指し，DCT デノイジングの\\n'\n",
      "                    '高速化を行った．本概要ではまず，高速 DCT アルゴリ\\n'\n",
      "                    'ズムである AAN [3] の適用，そして実装上の高速化手\\n'\n",
      "                    '法について提案 DCT デノイジングの高速化について説\\n'\n",
      "                    '明する．'},\n",
      "  'date': '2019-06-10 00:00:00',\n",
      "  'paper_title': '冗長 DCT による高効率な周波数フィルタリング',\n",
      "  'pdf_name': 'IS1-12'},\n",
      " {'conf_name': 'SSII2019',\n",
      "  'content': {'序論': 'カメラと 3D LiDAR のセンサフュージョンにより，セ\\n'\n",
      "                    'ンサ単体の歩行者認識より性能が高く，かつ車載マイコンによる実用的なシステムを可能とすべく，本開\\n'\n",
      "                    '発を行った[1]．一般的に，歩行者は奥行き方向，横向き方向それぞれ類似した動作であるが，我々はより複雑な動作\\n'\n",
      "                    '(荷物を運ぶ，しゃがみなど)の場合の人物も認識でき\\n'\n",
      "                    'るシステムの開発を目指している。このため，識別処理により性能が高いものが必要になり，かつ処理時間の課題が発生することが容易に想定できたため，識別処理にディープラーニングを選定し，さらにこれ\\n'\n",
      "                    'を  FPGA へ搭載することで，これらの課題を解決した．'},\n",
      "  'date': '2019-06-10 00:00:00',\n",
      "  'paper_title': '車載向け FPGA 搭載に向けたコンパクトな Residual Network による人物検知',\n",
      "  'pdf_name': 'IS1-13'},\n",
      " {'conf_name': 'SSII2019',\n",
      "  'content': {'序論': '現在，日本では土砂災害が多発している．土砂災害\\n'\n",
      "                    'の発生後にさらなる被害の拡大を阻止するためには迅\\n'\n",
      "                    '速な復旧工事が必要であり，迅速な復旧工事のために\\n'\n",
      "                    'は，建設機械を使用する必要がある．土砂災害の現場\\n'\n",
      "                    'で建設機械を活用するためには，最初に，現場での建\\n'\n",
      "                    '設機械の走破性を素早く調査する必要がある. 走破性\\n'\n",
      "                    'の調査については，走破性の指標の 1 つであるコーン\\n'\n",
      "                    '指数を測定して行うことが多い [1]．しかし，災害現場\\n'\n",
      "                    'では，二次災害の危険性が存在し，現場に人が立ち入\\n'\n",
      "                    'ることは難しいため，無人で走破性を調査することが\\n'\n",
      "                    '望ましい．無人で走破性を調査する先行研究には，無\\n'\n",
      "                    '人地上車両（UGV）にコーン指数を測定する機器を搭\\n'\n",
      "                    '載して遠隔操作した研究がある [2] [3]．しかし，この\\n'\n",
      "                    '手法では，走破性の調査に多くの時間が必要となるだ\\n'\n",
      "                    'けでなく，さらに，UGV が進入できない場所の調査は\\n'\n",
      "                    '不可能である．従って，この手法では適用可能な土砂\\n'\n",
      "                    '災害が限定されてしまう可能性が大きい．一方，画像\\n'\n",
      "                    'を使用して走破性を判定することが可能となれば，短\\n'\n",
      "                    '時間での判定が可能となるだけでなく，さらに UGV や\\n'\n",
      "                    '人の進入が困難な場所の走破性についても，その外側\\n'\n",
      "                    'から撮影した画像さえあれば判定が可能となる．画像\\n'\n",
      "                    'を使用して走破性を判定する先行研究には，可視近赤\\n'\n",
      "                    '外，短波長赤外，長波長赤外の波長を撮影出来るカメ\\n'\n",
      "                    'ラを使用した研究がある [4] [5]．しかし，これらの先行\\n'\n",
      "                    '研究では，含水比と走破性の関係にのみ注目しており，\\n'\n",
      "                    '走破性に影響すると考えられる土壌の種類には，注目\\n'\n",
      "                    'していない．そこで，本研究では，画像から土壌の種類の判別と含\\n'\n",
      "                    '水比の推定の双方を行うことによって，土壌の走破性\\n'\n",
      "                    'を判定することを目的とする．なお，一般的な RGB 画\\n'\n",
      "                    '像では土壌の種類の判別ならびに，含水比の推定を同\\n'\n",
      "                    '時に行うことが不可能であると考えられるので，ハイ\\n'\n",
      "                    'パースペクトル画像を使用することとした．ハイパー\\n'\n",
      "                    'スペクトル画像の分類には，最尤推定法や多変量解析Copyright © SSII 2019. All Rights '\n",
      "                    'Reserved.- IS1-14 -が使用されることが多い．しかし，ニューラルネット\\n'\n",
      "                    'ワークの方が，学習データやラベルの定義に左右され\\n'\n",
      "                    'にくく [6]，重要な特徴量を自動で探索できることが知\\n'\n",
      "                    'られている [7]．そこで，本研究では, ニューラルネッ\\n'\n",
      "                    'トワークを利用し，土壌のハイパースペクトル画像を\\n'\n",
      "                    '分類することとした．本稿では，土壌の走破性を判定\\n'\n",
      "                    'する手法を提案すると共に，複数の土壌を用いて実施\\n'\n",
      "                    'した走破性判定試験について述べる．'},\n",
      "  'date': '2019-06-10 00:00:00',\n",
      "  'paper_title': 'ハイパースペクトル画像を用いた土壌の走破性の判定',\n",
      "  'pdf_name': 'IS1-14'},\n",
      " {'conf_name': 'SSII2019',\n",
      "  'content': {'序論': '安心安全な社会の実現のために，防犯や捜索など様々\\n'\n",
      "                    'な応用を目的として複数カメラを用いた広域見守りシ\\n'\n",
      "                    'ステムが必要とされている．このシステムは高精度な\\n'\n",
      "                    '人物対応付けの手法によって実現される．人物対応付\\n'\n",
      "                    'けには人物画像から抽出された人物に固有の特徴量を\\n'\n",
      "                    '使用し，特徴量間の距離を総当たりで計算する．そのた\\n'\n",
      "                    'めカメラ台数や被写体人数の変化により，処理負荷が\\n'\n",
      "                    '大きく増減する．このシステムにスケーラビリティを\\n'\n",
      "                    '持たせるため，クラウド上の計算サーバを用いてサー\\n'\n",
      "                    'バ上で人物対応付けを行うことが考えられる．しかし，\\n'\n",
      "                    '人物対応付けに使用する特徴量は，人物を特定できる\\n'\n",
      "                    'ため個人情報に該当する．よってクラウド上の計算サー\\n'\n",
      "                    'バを用いる場合，個人情報である特徴量を暗号化し，第\\n'\n",
      "                    '三者からはアクセスできない形で取り扱うことが求め\\n'\n",
      "                    'られる．人物対応付けをクラウド上の計算サーバで安全に行\\n'\n",
      "                    'うことを目指し，特徴量を準同型暗号 [1] により保護す\\n'\n",
      "                    'ることを考える．準同型暗号を用いることで，暗号化さ\\n'\n",
      "                    'れた特徴量をサーバ上で復号化することなく，距離計\\n'\n",
      "                    '算を行うことができる．準同型暗号を用いたパターン\\n'\n",
      "                    '認識の手法として，主成分分析への適用例 [2] や，深層\\n'\n",
      "                    '学習への適用例 [3] が報告されている．本稿では，特徴\\n'\n",
      "                    '量間の距離計算に準同型暗号を適用するシステムにつ\\n'\n",
      "                    'いて議論する．暗号化された人物対応付けの流れを図 1\\n'\n",
      "                    'に示す．検出した人物画像から特徴量を抽出し，その\\n'\n",
      "                    '特徴量を準同型暗号により保護してからクラウドサー\\n'\n",
      "                    'バ上へ送り距離計算を行う．準同型暗号を施して計算\\n'\n",
      "                    'を行う場合，暗号化せずに計算を行った場合と比較し\\n'\n",
      "                    'て処理時間が増大してしまう．そのため距離計算の回\\n'\n",
      "                    '数を減らす工夫が必要となる．距離計算の回数は，人\\n'\n",
      "                    '物対応付けに使用する人物画像の枚数によって決まる．\\n'\n",
      "                    '人物画像の枚数は，一人の人物に対してカメラ視野内\\n'\n",
      "                    'に存在している間に増加していく．本稿では，人物対応付け精度を保ったままカメラ視野\\n'\n",
      "                    '内で多数獲得される同一人物の画像枚数を削減し，準Copyright © SSII 2019. All Rights '\n",
      "                    'Reserved.- IS1-15 -図 1 '\n",
      "                    '特徴量を保護した人物対応付け同型暗号を用いて特徴量を保護する人物対応付けシス\\n'\n",
      "                    'テムを開発する．そのために各地点で見え方が類似し\\n'\n",
      "                    'た人物画像を選択することを指針とし，人物画像選択\\n'\n",
      "                    'のための基準を作成し，検出した全ての人物画像から\\n'\n",
      "                    '基準に沿う画像のみを選択する．基準には，人物の姿\\n'\n",
      "                    '勢を用いる．基準姿勢を用いて人物画像を選択するこ\\n'\n",
      "                    'とで，人物対応付け精度を保ったままで人物画像枚数\\n'\n",
      "                    'の削減が可能であるか確認をするために実験を行った．\\n'\n",
      "                    '以下，2 章では画像選択の関連研究について述べる．次\\n'\n",
      "                    'に 3 章では提案システムで用いる人物画像選択の手法\\n'\n",
      "                    'について述べ，4 章で人物画像選択を用いた提案システ\\n'\n",
      "                    'ムについて述べる．そして 5 章で独自データセットを\\n'\n",
      "                    '用いた人物画像選択の評価実験について述べる．最後\\n'\n",
      "                    'に，6 章でまとめる．'},\n",
      "  'date': '2019-06-10 00:00:00',\n",
      "  'paper_title': '個人情報が保護された人物対応付けにおける',\n",
      "  'pdf_name': 'IS1-15'}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for paper_list in dir_pdf_parser.parse_dict_list():\n",
    "    pprint.pprint(paper_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ディクショナリとして取得 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-08T14:11:47.138233Z",
     "start_time": "2020-05-08T14:09:47.542602Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0936e4dd61b44527aa00c8a5df586fb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=19.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'IS1-02': {'conf_name': 'SSII2019',\n",
      "            'content': {'序論': '近年，画像を活用した異常検出手法は数多く提案され\\n'\n",
      "                              'ており，不良品検出や，監視カメラからの危険人物の検\\n'\n",
      "                              '出，医療の発病検知などの領域に応用されている [1{4]．\\n'\n",
      "                              'その中でも，生成モデルで通常クラスの画像を十分\\n'\n",
      "                              '学習させた後，生成モデルに画像を入力し生成された\\n'\n",
      "                              '再構成画像と，入力画像との誤差画像を基に異常を検\\n'\n",
      "                              '出する手法が代表的である．生成モデルとして Auto-\\n'\n",
      "                              'Encoder (AE) を応用した異常検出手法 [5] や，Vari-\\n'\n",
      "                              'ational Auto-Encoder (VAE) [6] を応用した手法 [7]，\\n'\n",
      "                              'Generative Adversarial Networks (GAN) [8] を活用し\\n'\n",
      "                              'た手法 [9] が既に提案されている．その中でも，GAN\\n'\n",
      "                              'を活用した手法 [9] は，精度が良いものの，識別時に再\\n'\n",
      "                              '構成画像と入力画像との誤差の最小化計算のコストが\\n'\n",
      "                              'かかる問題 [10] や，最小化中に初期値によっては局所\\n'\n",
      "                              '解に陥ってしまう問題がある．そこで，VAE を用いて\\n'\n",
      "                              'GAN の初期値を決めることで，常に入力画像に近い生\\n'\n",
      "                              '成画像を出力する VAEGAN [11] の活用が必要である\\n'\n",
      "                              'と考える．一方で，実世界での利用を想定した場合，入力画像\\n'\n",
      "                              'にはノイズが多く含まれる．生成モデルでは平均的な\\n'\n",
      "                              '画像を出力するため，入力画像にノイズが混入してい\\n'\n",
      "                              'る場合，モデルはノイズの少ない画像を生成する．そ\\n'\n",
      "                              'のため，ノイズ部には再構成誤差が生じる．前述した\\n'\n",
      "                              '手法では，画像全体の再構成誤差の大きさにより判定\\n'\n",
      "                              'を行っているため，異常に起因する誤差と，ノイズに\\n'\n",
      "                              '起因する誤差を分ける必要がある．しかし，これらの\\n'\n",
      "                              '手法では，その機構がない．すなわち，ノイズ部の誤\\n'\n",
      "                              '差と本来の異常領域の誤差の区別ができなく，ノイズ\\n'\n",
      "                              'への頑健性が懸念される．そこで我々は以前，異常ク\\n'\n",
      "                              'ラスの一部を教示し，識別に必要となる領域に焦点を\\n'\n",
      "                              '当てることで，ノイズに頑健な手法を提案した [12,13]．\\n'\n",
      "                              'ところが，異常画像の一部を事前に知り得る必要があ\\n'\n",
      "                              'り，それらが未知の場合は根本的な問題となる．そこで本稿では，まず，先の局所解の問題を解決する\\n'\n",
      "                              'ために，VAEGAN を用いた異常値判検出手法を提案す\\n'\n",
      "                              'る．次に，ノイズへの頑健性を向上させるために，VAE-\\n'\n",
      "                              'GAN の Discriminator から Region-of-interest '\n",
      "                              '(ROI)\\n'\n",
      "                              'を算出し，それを再構成誤差の重み付けに活用する手Copyright © SSII 2019. '\n",
      "                              'All Rights Reserved.- IS1-02 -図 1: 提案手法の概要図．‘0’ '\n",
      "                              'が正常クラスであり，‘4’\\n'\n",
      "                              'の画像が入力された時の手法による異常度合いの違い．\\n'\n",
      "                              'Na(cid:127)(cid:16)ve に VAEGAN '\n",
      "                              'を用いた手法では，ピンクの領域が\\n'\n",
      "                              'ノイズの有無に起因しているため，判別に悪影響を及\\n'\n",
      "                              'ぼしてしまう．法を提案する．そして，VAE，GAN を活用した従来手\\n'\n",
      "                              '法と比較実験を実施し，評価する．提案手法の概略図\\n'\n",
      "                              'を図 1 に示す．'},\n",
      "            'date': '2019-06-10 00:00:00',\n",
      "            'paper_title': 'VAEGAN の再構成誤差と Discriminator の ROI を活用した異常検出',\n",
      "            'pdf_name': 'IS1-02'},\n",
      " 'IS1-03': {'conf_name': 'SSII2019',\n",
      "            'content': {'序論': '橋梁や道路，トンネルなどの社会インフラは年々増加している．これらの設備は建設後，使用とともに徐々に老朽化するため，定期的な検査が必要である．一般的に，構造物の検査には非破壊検査が用いられており，特に内部欠陥や厚さの測定には超音波厚さ測定が用いられる．超音波厚さ測定はソーナーの原理と同じで，超音波が往復する時間差によって所定の位置の厚さ（長さ）を求める検査方法である．測定器具の取扱いや計測データの解釈には専門的知識及び時間を必要とするため，大規模な測定は困難\\n'\n",
      "                              'である．このような課題に対し，本研究ではCNN によ\\n'\n",
      "                              'り測定データから超音波エコーを検出し，厚さを求める手法を提案する．実験の結果，専門的知識を必要\\n'\n",
      "                              'としなくても 95%のデータの厚みを測定でき，本手法\\n'\n",
      "                              'の有効性が確認できた．1  '\n",
      "                              'はじめに金属やコンクリートなどの厚さを測定する場合，ノギスやマイクロメータ等の物体を挟み込んで測定する厚さ測定器が使用される．測定対象物がタンクや配管など，物理的にこれらの測定器を使用できない場合は，非破壊検査手法のひとつである，超音波厚さ\\n'\n",
      "                              '測定（UTM：Ultrasonic Thickness Measurement）が用\\n'\n",
      "                              'いられることが多い．超音波厚さ測定とは，超音波探触子で発生した超音波を測定対象物に入射し，その反射波を計測することによって対象物の厚さを測定する検査方法である．超音波が測定対象物に垂直もしくは設定した任意の角度で入射し，所定の位置で反射することを前提とするため，測定器具の取扱いや計測データの読み取りに専門的技量を必要とする．そのため，超音波厚さ測定は他の非破壊試験と同様\\n'\n",
      "                              'に，日本工業規格（JIS）で測定方法が規定されてい\\n'\n",
      "                              'る[1]．また，各種法定検査では認定技術者による検\\n'\n",
      "                              '査が求められている．一方，国土交通省の予測によCopyright © SSII 2019. '\n",
      "                              'All Rights Reserved.- IS1-03 '\n",
      "                              '-ると，高度経済成長以降に整備されたインフラ設備が今後一斉に老朽化するとされており，効率的な維\\n'\n",
      "                              '持管理が喫緊の課題となっている．超音波厚さ測定や類似検査である超音波探傷試験では，探触子を自動で移動走査することによる自\\n'\n",
      "                              '動計測システム[2]は開発されているものの，計測デ\\n'\n",
      "                              'ータから測定値を算出する部分には言及されていない．一般に，超音波厚さ測定では計測データ中の超音波エコーから測定対象物の厚さを求めているが，超音波エコーの妥当性は目視で確認している．その確認に多大な時間を要するため省力化が課題となっている．本研究では，超音波厚さ測定における計測\\n'\n",
      "                              'データから Convolutional  Neural  Network  (CNN)を\\n'\n",
      "                              '用いて超音波エコーを検出し，厚さを算出する手法\\n'\n",
      "                              'を提案する．2  '\n",
      "                              '超音波厚さ測定（UTM）超音波厚さ測定は，超音波探触子から発生した超音波パルスを測定対象物に入射し，その伝搬時間をもとに対象物の厚さを求める方法である．探触子で発生した超音波を効率よく測定対象物に入射させるために，対象物を水などの媒質内に沈めて測定されることが多い．ここでは，超音波パルスが対象物中を図 '\n",
      "                              '1 '\n",
      "                              'に示すように，厚さ(cid:1830)の測定対象物中に超音往復する時間を計測することで厚さを求める，パルス\\n'\n",
      "                              '反射法について説明する．波探触子から超音波パルス T を送信したとき，T の一\\n'\n",
      "                              '部は対象物の表面で反射し，探触子で受信される．図 1.  超音波厚さ測定の概略図'},\n",
      "            'date': '2019-06-10 00:00:00',\n",
      "            'paper_title': '超音波厚さ測定の効率化のためのエコー検出手法',\n",
      "            'pdf_name': 'IS1-03'},\n",
      " 'IS1-04': {'conf_name': 'SSII2019',\n",
      "            'content': {'序論': '近年，自動車産業において交通事故減少や利便性向\\n'\n",
      "                              '上のために自動運転のシステムが開発されている．自動\\n'\n",
      "                              '運転の確立には，高度な周辺環境認識が重要となり，特\\n'\n",
      "                              'に交通弱者である歩行者を認識することが極めて重要\\n'\n",
      "                              'となる．本研究では，逆光や夜間などの，照明変化に頑\\n'\n",
      "                              '健な LIDAR を用いた歩行者検出に着目する．LIDAR\\n'\n",
      "                              'を用いた歩行者検出では，2 人以上の歩行者群を検出す\\n'\n",
      "                              'る方法は確立されてない．本研究では，2 人以上の歩行\\n'\n",
      "                              '者群を適切に分割して単独歩行者として検出するため\\n'\n",
      "                              'に，k-means++法 [1] による歩行者群分割を提案する．\\n'\n",
      "                              'さらに，k-means++法の分割数を手動決定しなければ\\n'\n",
      "                              'ならない問題点を解決するため，シルエット値 [2] を用\\n'\n",
      "                              'いる手法を提案した．2 LIDAR を用いた歩行者検出従来の LIDAR による歩行者検出の '\n",
      "                              '1 つである，Ki-\\n'\n",
      "                              'dono らによる歩行者検出 [3] について述べる．歩行者\\n'\n",
      "                              '検出の流れを図 1 に示す．歩行者検出の大きな流れとし\\n'\n",
      "                              'て，歩行者データと非歩行者データを用いた検出器の\\n'\n",
      "                              '構築と，検出器による歩行者検出の 2 つに分けられる．図 1 '\n",
      "                              '歩行者検出の流れCopyright © SSII 2019. All Rights '\n",
      "                              'Reserved.- IS1-04 -第25回画像センシングシンポジウム2.1 LIDAR '\n",
      "                              'による三次元点群データの取得歩行者検出を行うために，まず，LIDAR を用いて三\\n'\n",
      "                              '次元点群データを取得する．車載カメラ映像と取得した\\n'\n",
      "                              'データを可視化したものを図 2，図 3 に示す．可視化に\\n'\n",
      "                              'は三次元点群情報を取り扱うことのできる Point Cloud\\n'\n",
      "                              'Library(PCL) を利用している．図 2 車載カメラ映像図 3LIDAR '\n",
      "                              'による三次元点群データ2.2 路面平面の決定その後，取得した三次元点群データから路面平面を\\n'\n",
      "                              '決定するために，PCL の平面検出を行い，以下の平面\\n'\n",
      "                              'の方程式を得る．ax + by + cz = d(1)2.3 '\n",
      "                              'グリッドマップを用いた立体物検出路面平面を決定した後，グリッドマップを用いて立\\n'\n",
      "                              '体物検出を行う．立体物の検出はまず，図 4 のような\\n'\n",
      "                              '路面平面に平行なグリッドマップを作成する．その後，'},\n",
      "            'date': '2019-06-10 00:00:00',\n",
      "            'paper_title': '歩行者群分割',\n",
      "            'pdf_name': 'IS1-04'},\n",
      " 'IS1-05': {'conf_name': 'SSII2019',\n",
      "            'content': {'序論': '機械学習技術や IoT  (Internet  of  Things)，M2M \\n'\n",
      "                              '(Machine  to  Machine)  によるセンサネットワークの広\\n'\n",
      "                              'がりとともに，例えば日常生活での見守りサービスや，生産現場での生産性改善など，センサデータを用い\\n'\n",
      "                              'た行動分析アプリケーションが提案されている．ところで，従来の行動分析技術は，その多くが教師あり学習に基づいて検討されている．教師あり学習は，事前に人手による教師データの作成等が必要であり，これにかかる手間と時間とが実用化の際には大\\n'\n",
      "                              'きな課題となる．本稿では上記の課題を解決した行動分析アプリケーションの実現を目的として，教師なし学習に基づく\\n'\n",
      "                              '行動分析アルゴリズムを提案する．提案手法が対象とするのは，とくに日常生活や生産現場等で見られる，同じ動作が繰り返される行動である．複数回繰り返された動作のセンサデータ同士を，動作要素ごとに分節化して比較することで，教師データを与えることなく，標準的な動作パターンを\\n'\n",
      "                              '決定するとともに非標準動作を検出する．'},\n",
      "            'date': '2019-06-10 00:00:00',\n",
      "            'paper_title': '',\n",
      "            'pdf_name': 'IS1-05'},\n",
      " 'IS1-06': {'conf_name': 'SSII2019',\n",
      "            'content': {'序論': '放牧における牛の監視作業は，労働の負担が大きい\\n'\n",
      "                              '一方で，個体の状態を管理し病気や怪我の牛を早期発見\\n'\n",
      "                              'するために重要である．本稿ではドローンを用いて撮影\\n'\n",
      "                              'した空撮画像から乳牛の模様によって個体識別を行い，\\n'\n",
      "                              'それによる個体ごとの監視を目指す．空撮画像では牛\\n'\n",
      "                              'の向きは不揃いであるが，牛の識別を行う際には，体の\\n'\n",
      "                              '向きが揃っていた方が識別精度がよいと予測される．こ\\n'\n",
      "                              'のため，畳込みニューラルネットワーク (CNN) である\\n'\n",
      "                              'YOLOv3 を用いてまず牛の体と頭部を検出し，画像に\\n'\n",
      "                              'おける牛の体軸整合を行う．その後 Siamese Network\\n'\n",
      "                              'を用いて乳牛の模様の類似度による個体識別を行う．従\\n'\n",
      "                              '来手法であるテンプレートマッチングと比較し，提案\\n'\n",
      "                              '手法の有効性を確認した．1 はじめに畜産農家の作業時間の中で，大きな割合を占めるの\\n'\n",
      "                              'は監視作業である．その中でも病気や怪我をした牛の\\n'\n",
      "                              '早期発見が重要である．近年，一戸あたりの牛飼養頭\\n'\n",
      "                              '数は増加する一方，労働人口は高齢化しており，農家\\n'\n",
      "                              'の管理負担が増している．放牧の監視作業の負担を軽\\n'\n",
      "                              '減するため，長期的なコストが少ない，保守運用が楽\\n'\n",
      "                              'などのメリットを持つコンピュータビジョンを用いた\\n'\n",
      "                              '監視が注目されている．特に，広い範囲にわたる放牧\\n'\n",
      "                              '地をカバーできるドローンによる空撮画像の使用が有\\n'\n",
      "                              '望である．本稿は，ドローンによる空撮画像から乳牛の個体識\\n'\n",
      "                              '別を目指す．これにより，遠隔地から牛を個体ごとに観\\n'\n",
      "                              '察することが可能となり，農家の支援につながる．空\\n'\n",
      "                              '撮画像では対象物が様々な向きで写されるが，個体識\\n'\n",
      "                              '別のためには，体の向きが揃っている方が精度が良い\\n'\n",
      "                              'ことが期待される．そこで，YOLOv3 [1] を用いた牛の\\n'\n",
      "                              '体と頭部の検出を行い，これに基づいて個体の向きを\\n'\n",
      "                              '揃える体軸整合を行う．また，模様による個体識別に\\n'\n",
      "                              'ついては類似度学習を行う Siamese Network [2] を用い\\n'\n",
      "                              'る．実験では，Siamese Network を用いる場合とテン\\n'\n",
      "                              'プレートマッチングを用いる場合の比較を行い，また\\n'\n",
      "                              'それぞれでは体軸整合の処理の有無による比較も行う．Copyright © SSII 2019. '\n",
      "                              'All Rights Reserved.- IS1-06 -図 1: 手法の概要'},\n",
      "            'date': '2019-06-10 00:00:00',\n",
      "            'paper_title': 'ドローンによる牧場空撮画像における乳牛の個体識別',\n",
      "            'pdf_name': 'IS1-06'},\n",
      " 'IS1-07': {'conf_name': 'SSII2019',\n",
      "            'content': {'序論': '医療，建築の分野において，3 '\n",
      "                              '次元物体の形状を非接触で計測することは，利便性の面で重要である．現在の主な手法は、ステレオ画像法，光レーダー法，光切断法，照度差ステレオ法，焦点調節法，等高線\\n'\n",
      "                              '計測法が存在する[1]．これらの手法の中で，等高線\\n'\n",
      "                              '計測法に分類されるモアレトポグラフィがある．この手法は，身近な利用例を挙げると医療分野において，人体の骨格の形状を診断する際に用いられてきた．また，近年では格子や干渉縞の位相解析を行うことで，高精度になってきている．そして、モアレトポグラフィを基礎とし，デジタルカメラの走査線を利用した\\n'\n",
      "                              'サンプリングモアレ法が考案されている[2]．本研究の目的は，上記のような非接触 3 次元形状\\n'\n",
      "                              '計測によって患者の腹部や胸部の動態を認識し，緊\\n'\n",
      "                              '急搬送中のトリアージ判定や ICU での継続的な容態\\n'\n",
      "                              'モニタリングを実現することである．そのために，上記手法を動的な計測システムへと拡張する必要がある．\\n'\n",
      "                              '本論文では，2 章でサンプリングモアレ法の原理を説\\n'\n",
      "                              '明し，3 章でこれにアクティブステレオ法を組み込ん\\n'\n",
      "                              'だ動的 3 時限形状計測手法を提案し，人の腹部に適\\n'\n",
      "                              '用した実験結果を述べ，4 章で結論をまとめる．2  モアレトポグラフィ2.1  '\n",
      "                              'モアレ法すだれを二枚重ねると，元のすだれにない新しい縞模様が現れる場合がある．これをモアレ縞と言い，細かな縞どうしの干渉によって，より周波数の低い縞模様が見える現象である．そして，この干渉縞を使っ\\n'\n",
      "                              'て計測を行う手法がモアレ法である．図 1(a)の等間隔の基準格子に，その格子が少し\\n'\n",
      "                              '変形した図 1(b)の試料格子を重ねると，図 1(c)のよう\\n'\n",
      "                              'に元の格子にない，より周波数の低い新たなモアレ\\n'\n",
      "                              '縞が発生する．Copyright © SSII 2019. All Rights '\n",
      "                              'Reserved.- IS1-07 '\n",
      "                              '-基準格子の黒い線と試料格子の黒い線が重なった部分，基準格子の白い線と試料格子の白い線が重なった部分に，白い線ができている。また，基準格子の黒い線と試料格子の白い線が重なった部分，基準格子の黒い線と試料格子の白い線が重なった部分に，黒い線ができている．これがモアレ縞である．\\n'\n",
      "                              'なお，図 1(b)の変形した試料格子をデジタルカメラな\\n'\n",
      "                              'どで撮影しても，図 1(d)に示すようなモアレ縞が発生\\n'\n",
      "                              'する場合がある．これは，後述するサンプリングモア\\n'\n",
      "                              'レ法で利用される．一つの連なるモアレ縞は変形量の等しい等変位線となっているので，このモアレ縞を解析することにより，試料格子の変位やひずみを解析できる．これをモアレ法と言う．また，プロジェクター等を用い，基準格子を三次元物体に投影し，その物体を基準格子と重ねると，モアレ縞が発生する．この干渉縞を解析することで，本研究の目的である三次元形状を計測する\\n'\n",
      "                              'ことができる．これをモアレトポクラフィと呼ぶ[3]．図 1  等変位線を示すモアレ縞の説明:  '\n",
      "                              '(a)  基準\\n'\n",
      "                              '格子，(b)  試料格子，(c)  図(a)と(b)の重ねあわせに\\n'\n",
      "                              'よって生じるモアレ縞，(d)  デジタルカメラで撮影され\\n'\n",
      "                              'た画像によって得られるモアレ縞，[2]より転載'},\n",
      "            'date': '2019-06-10 00:00:00',\n",
      "            'paper_title': '',\n",
      "            'pdf_name': 'IS1-07'},\n",
      " 'IS1-08': {'conf_name': 'SSII2019',\n",
      "            'content': {'序論': '油圧ショベルに搭載した３台の単眼カメラの画像をリアルタイムに画像認識し、人らしい像があればモニタ表示と音で知らせる機能を開発した。動作イメージを図１に示す。油圧ショベルは人と比べて大型で、重量が大きく動きも速いうえ、走行だけでなく旋回動作もある。周辺に作業者や障害物が混在する現場では、安全確保のため、確実かつ広範囲の周辺確認が求められる。しかしながら、車体の左前方にある運転室からは、エンジンフードやカウンターウェイトが視界を遮るため、特に車体後方と右側方にオペレータから直接目視できない死角が多い。そこでミラーやカメラ\\n'\n",
      "                              'で周辺確認を可能にする必要がある。従来機能の画像合成処理[1]  '\n",
      "                              '[2]は、油圧ショベルの後方、右側方、左側方に、広角、高感度でダイナミックレンジが広い単眼カメラを３台搭載し、それらの画像をリアルタイムに合成して運転室内のモニタに表示する事で、油圧ショベルの後方２７０度をひと目で確認可能にした。カメラ配置と合成画像の例を図２に示す。ＦＰＧＡによるパイプライン処理で、フレームレート低下なく画像を合成表示する。車体のごく近傍から地平線の上空までカバーする事で大型の物体も全体を映し出せる視野の広さ、旋回動作を伴う油圧ショベルに好適な円形画像、直感的な分かりやすさが特徴である。２０１１年に油圧ショベルのオプションとして\\n'\n",
      "                              '販売を開始、その後標準装備とした。しかしながら、モニタ確認のタイミングはオペレータによって異なるため、例えば作業に集中してモニタから目を離しているすきに、周辺の作業者が油圧ショベルに接近してしまう状況が想定される。そこで、カメラ画像を認識して、人らしい像があればモニタ表示と音で知らせることで、オペレータに周辺確認のきっかけを与える機能を開発した。既設の単眼カメラの画像認識のみで、ローコストで簡便なシステム構成としながら、合成映像がカバーする範囲全体を画像認識する事が目的である。本稿ではこれらを実現するにあたCopyright '\n",
      "                              '© SSII 2019. All Rights Reserved.- IS1-08 '\n",
      "                              '-っての技術課題と解決方策、および実際の動作事例\\n'\n",
      "                              'を紹介する。2  '\n",
      "                              '目標・課題開発目標は以下とした。本章では、目標達成のための技術課題を説明する。目標１.  '\n",
      "                              '画像認識のみによる人らしさ評価 \\n'\n",
      "                              '目標２.  ３方向のカメラ画像を毎秒１０回以上認識 \\n'\n",
      "                              '目標３.  小型で安価な車載装置2.1  画像上での人の見かけ変化 \\n'\n",
      "                              '背景と服装の色のコントラスト、上半身と下半身で色が異なる服装、携行品、カメラに対する位置や向き、ポーズなど、画像上の人の見かけは多様に変化する。また、人の身長よりも高い油圧ショベルの車体上面にカメラを設置するため、人がカメラに接近した場合と離れた場合では、像の大きさだけでなく、頭と体の像の比率など見かけが変化する。画像の例を図３に示す。本開発では想定する人を歩行者に限定したが、それでもあらゆる見かけ変化を想定して人らしさを数\\n'\n",
      "                              '値化するアルゴリズムの手動設計は困難である。2.2  広角カメラ画像の歪み \\n'\n",
      "                              '後方カメラと側方カメラの境界部も隙間無く撮影するために広角カメラを採用し、車体のごく近傍から遠方までをカバーするために斜め下向きに設置する。これにより視野の左右端では物体の像が傾いて映り、視野の下端には車体の像が映りこむ場合がある。画像の例を図４に示す。人らしさを評価するために像を囲む注目領域を設定すると、一部が画像範囲外や\\n'\n",
      "                              '車体の像に及び、画像情報が欠損する。2.3  画像認識処理サイクルの高速化と安定化 \\n'\n",
      "                              '計算回数が多い画像認識処理を安定した時間サイクルで実行し続ける必要がある。ＦＰＧＡでハード化して処理時間のばらつきを低減するが、ローコストな'},\n",
      "            'date': '2019-06-10 00:00:00',\n",
      "            'paper_title': '',\n",
      "            'pdf_name': 'IS1-08'},\n",
      " 'IS1-09': {'conf_name': 'SSII2019',\n",
      "            'content': {'序論': '畳み込みニューラルネットワーク  (CNN)  を用いた\\n'\n",
      "                              'セマンティックセグメンテーションはコンピュータビジョンにおける基本的な問題の一つである．本稿では，\\n'\n",
      "                              'Encoder-Decoder 構 造 の ネ ッ ト ワ ー ク に 導 入 す る\\n'\n",
      "                              'Class の観点からの Attention 機構を提案する．  Class\\n'\n",
      "                              'の観点からの Attention 機構では，クラス領域を学習\\n'\n",
      "                              'しながら復元された特徴情報に注目する．これにより各クラスのセグメンテーションに重要な特徴情報に焦点を当てるようになるため，より正確に結果を生成す\\n'\n",
      "                              'ることが可能となる．本稿では CamVid データセットを\\n'\n",
      "                              '用いて評価し，従来手法よりも高い精度が得られた．1  '\n",
      "                              'はじめに画像内の各画素に対してクラス推定を行うセマン\\n'\n",
      "                              'ティックセグメンテーション[2,  3,  5]は，コンピュータビ\\n'\n",
      "                              'ジョンにおける基本的な問題の一つであり，自動運転や医学など様々な分野に応用され始めている．近年，画像認識問題において非常に高い認識精度を\\n'\n",
      "                              '実現した畳み込みニューラルネットワーク(CNN)[1]に\\n'\n",
      "                              '基づいた Encoder-Decoder 構造を採用した手法が数\\n'\n",
      "                              '多く提案されている．従来のセマンティックセグメンテーション手法では，あるクラスに属する物体の一部を異なるクラスであると誤って識別してしまうことがある．これは画像内に存在する各物体を画素単位で学習していたため，クラス間の区別が上手く出来ていないことが原因であると考えられる．この問題を対処する\\n'\n",
      "                              'ため，Encoder-Decoder 構造のネットワークに導入す\\n'\n",
      "                              'る Class の観点からの Attention 機構を提案する．Class の観点からの '\n",
      "                              'Attention 機構は，セグメンテー\\n'\n",
      "                              'ションのために各クラス領域を学習しながら，それらを用いて特徴情報に注目する工程である．これにより重要な特徴情報のみ逐次焦点を当てるようになるた\\n'\n",
      "                              'め，より正確に結果を生成することが可能となる．実験では，車載カメラにより撮影された画像を 11 '\n",
      "                              'クCopyright © SSII 2019. All Rights Reserved.- '\n",
      "                              'IS1-09 -堀田  一弘ラスでラベル付けされた CamVid データセット[4]を使\\n'\n",
      "                              '用し，評価指標には IoU(Intersection over Union) [5]\\n'\n",
      "                              'を用いた．その結果，提案手法は従来のセグメンテ\\n'\n",
      "                              'ーション手法よりも高い精度を得ることができた．本論文は以下のように構成される．2 節では関連\\n'\n",
      "                              '研究，3 節では提案手法について述べる．また，4 節\\n'\n",
      "                              'で評価実験の結果を示し，5 節にまとめを述べる．'},\n",
      "            'date': '2019-06-10 00:00:00',\n",
      "            'paper_title': '',\n",
      "            'pdf_name': 'IS1-09'},\n",
      " 'IS1-10': {'conf_name': 'SSII2019',\n",
      "            'content': {'序論': '自転車競技を始めとした広域で高速に動くスポーツ\\n'\n",
      "                              'において, ユーザへの情報提示並びに誤差蓄積のない光\\n'\n",
      "                              '学的な姿勢推定を一つのシステムで同時に行うことは\\n'\n",
      "                              '一般に困難である. 本稿では, ベクタ型レーザ投影によっ\\n'\n",
      "                              'て人への情報提示と高速カメラの姿勢推定のためのマー\\n'\n",
      "                              'カー提示を両立させる手法を検討する. これは, 人への\\n'\n",
      "                              '提示曲線を時空間的に分割することで高速カメラから\\n'\n",
      "                              'はマーカとして利用できるが, 人間にはマーカであるこ\\n'\n",
      "                              'とを知覚されにくい描画を実現するものである. 実験で\\n'\n",
      "                              'はスクリーンへ提案手法で描画される円を投影し, 静止\\n'\n",
      "                              '状態の高速カメラから撮像した動画を用いてカメラの\\n'\n",
      "                              '姿勢推定を行い, 姿勢推定精度を評価した.1 '\n",
      "                              'はじめにスポーツにおける身体・使用機材のセンシングとフィー\\n'\n",
      "                              'ドバック技術が, 競技力向上を目的として重要性を増し\\n'\n",
      "                              'ている. 自転車競技タイムトライアル種目においては,\\n'\n",
      "                              '選手と機材の物理的・生理学的なモデルからペース配\\n'\n",
      "                              '分を最適化できることが知られている [1]. 中でもトラッ\\n'\n",
      "                              'ク種目においては, 路面抵抗を一定とみなすことができ,\\n'\n",
      "                              '路面のトポロジも事前に調べられることから, 物理モデ\\n'\n",
      "                              'ルによって非常に正確な予測ができる可能性がある [2].\\n'\n",
      "                              '一方で高速に周回しているという性格上, 自転車はほと\\n'\n",
      "                              'んど傾いているため, 地面に対する自転車の姿勢推定が\\n'\n",
      "                              'モデルの入力として重要となる.これらの最適化は従来オフラインで行われ, 選手は事\\n'\n",
      "                              '前に算出された数値を競技前に記憶することによって活\\n'\n",
      "                              '用してきた. 一方で, 競技者に音声 [3] や触覚振動 [4] に\\n'\n",
      "                              'よって即時フィードバック [5][6] を与えれば, より効率\\n'\n",
      "                              '的な競技結果の向上が期待される. 本研究ではこれらを\\n'\n",
      "                              'トラックで実現するために, 高速 (~20m=s) かつ広範囲\\n'\n",
      "                              '(~100m 四方) で移動する自転車の姿勢推定と, 乗車して\\n'\n",
      "                              'いる人間への情報提示を同時に実現するためのマーカ\\n'\n",
      "                              'を提案する.このマーカを利用する系は, 将来的に図 1 に示す構\\n'\n",
      "                              '成を想定している. 環境側に設置するレーザプロジェクCopyright © SSII '\n",
      "                              '2019. All Rights Reserved.- IS1-10 -図 1 '\n",
      "                              '将来的な全体像図 2 ベクタ型レーザプロジェクションの例タ, 投影された提示画像, '\n",
      "                              'ユーザを含む移動体（自転車）\\n'\n",
      "                              'に取り付ける高速カメラからなる. ベクタ型レーザプロ\\n'\n",
      "                              'ジェクションとは, ガルバノミラーに代表される機構に\\n'\n",
      "                              'よってレーザの光軸を高速に制御して描くことのでき\\n'\n",
      "                              'る線分を用いた画像投影手法を指し, 図 2 に例を示す.\\n'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              '姿勢推定を行うためのマーカは, 情報提示のための画像\\n'\n",
      "                              '中に埋め込まれ, ユーザに意識されることなく, 移動体\\n'\n",
      "                              'にとりつけた小型の高速カメラからはデコードするこ\\n'\n",
      "                              'とができる. 本論文では, このマーカの埋め込み手法と,\\n'\n",
      "                              '静止状態における姿勢推定の安定性の評価を行う.'},\n",
      "            'date': '2019-06-10 00:00:00',\n",
      "            'paper_title': 'ベクタ型レーザ投影における自己位置推定のためのマーカ埋め込み手法の検討',\n",
      "            'pdf_name': 'IS1-10'},\n",
      " 'IS1-11': {'conf_name': 'SSII2019',\n",
      "            'content': {'序論': '固有画像分解は，入力画像を照明成分と反射率成分\\n'\n",
      "                              'に分解する手法である．反射率成分を正確に推定する\\n'\n",
      "                              'ことは，環境光による外乱を最小限に抑えることに相当\\n'\n",
      "                              'する．画像を照明成分と反射率成分の積として表現する\\n'\n",
      "                              'Retinex 理論を基礎として，近年では畳み込みニューラ\\n'\n",
      "                              'ルネットワーク (CNN) を用いた手法が提案されている．\\n'\n",
      "                              '正解画像を大量に用意することが著しく困難なこの問題\\n'\n",
      "                              '設定において，人工的に合成した画像を用いる従来手法\\n'\n",
      "                              'では，その結果に色ムラやにじみなどの不自然さが見ら\\n'\n",
      "                              'れた．本研究では，Encoder-Decoder 構造の CNN と，\\n'\n",
      "                              'その入力に Generative Adversarial Networks(GAN) に\\n'\n",
      "                              'よって生成した画像群を用いる枠組みを提案する．CNN\\n'\n",
      "                              '構造の最適化に加え，実世界における環境光のデータ\\n'\n",
      "                              '分布に基づき生成した画像群を入力とすることで，低\\n'\n",
      "                              '光量のテスト画像に対して，従来手法と比較してより自\\n'\n",
      "                              '然で視認性の高い反射率画像を得た．セマンティック・\\n'\n",
      "                              'セグメンテーションによる評価実験では，本手法で得\\n'\n",
      "                              'た反射率画像を用いて学習およびテストを行うことで，\\n'\n",
      "                              '環境光が画素値に与える悪影響が緩和され，識別精度\\n'\n",
      "                              'が向上することを確認した．2 はじめに一般物体認識やセマンティック・セグメンテーション\\n'\n",
      "                              'をはじめとするコンピュータビジョンのタスク全般に\\n'\n",
      "                              'おいて，その精度に悪影響をもたらす外乱として，シー\\n'\n",
      "                              'ンの照明状況が挙げられる．画像を通して観測される\\n'\n",
      "                              '物体の色情報は照明状況に強く依存し，環境変化が激\\n'\n",
      "                              'しい実空間において問題となる．特に，環境光の乏し\\n'\n",
      "                              'い暗部あるいは逆光条件下において物体の色情報は大\\n'\n",
      "                              'きく失われ，有効な画像特徴を抽出するにあたって障\\n'\n",
      "                              '害となる．そのため，画像の視認性を改善させる画像\\n'\n",
      "                              '処理技術への需要は高く，古くから活発に研究されて\\n'\n",
      "                              'いる分野である．\\n'\n",
      "                              '\\u3000一方，人間の視覚にはこのような外乱に適応する能\\n'\n",
      "                              '力が備わっており，異なる照明状況下においても同様に\\n'\n",
      "                              '物体を知覚できることが知られている．例えば，赤い\\n'\n",
      "                              'リンゴを明るい部屋と暗い部屋で撮影した場合を考えCopyright © SSII 2019. '\n",
      "                              'All Rights Reserved.- IS1-11 -(a) 入力画像 S(b) '\n",
      "                              '反射率画像 R(c) 照明画像 I図 1: 固有画像分解ると，リンゴの領域の RGB '\n",
      "                              '画素値は部屋の明暗によっ\\n'\n",
      "                              'て大きく異なるはずだが，人間はどちらの環境におい\\n'\n",
      "                              'てもリンゴは同じく赤いものであるとして知覚できる．\\n'\n",
      "                              'この視覚特性は色恒常性と呼ばれ，物体の色や明るさ\\n'\n",
      "                              'をその周辺との分光反射率の比のみで知覚することで，\\n'\n",
      "                              '変化する照明状況に対して見え方が自動的に補正され\\n'\n",
      "                              'るという性質をあらわしている．\\n'\n",
      "                              '\\u3000この人間が持つ色恒常性をコンピュータビジョンに\\n'\n",
      "                              '応用する手法として，固有画像分解 (図 1) が挙げられ\\n'\n",
      "                              'る．シーンで撮影された入力画像 (a) を，物体の反射\\n'\n",
      "                              '率を RGB 値に変換した反射率画像 (b) と，物体の色成\\n'\n",
      "                              '分を一切持たず環境光のみに依存する照明画像 (c) に分\\n'\n",
      "                              '解する．反射率画像を正確に推定することは，環境光\\n'\n",
      "                              'による外乱の影響を最小限に抑えることと同義であり，\\n'\n",
      "                              'コンピュータビジョンにおいては，固有画像分解によっ\\n'\n",
      "                              'て人間の色恒常性のようなロバスト性を実現できると\\n'\n",
      "                              '考えられる．\\n'\n",
      "                              '\\u3000多くの有用な固有画像分解手法は Retinex 理論 [1] [2]\\n'\n",
      "                              'を基礎にしている．Retinex は Retina (網膜) と Cor-\\n'\n",
      "                              'tex(大脳皮質) を合わせた造語で，人間の脳による光や\\n'\n",
      "                              '色の知覚をモデル化する．Retinex 理論では，入力画像\\n'\n",
      "                              'S と反射率画像 R，照明画像 I の関係を次の式であら\\n'\n",
      "                              'わす．S = R・I(1)式 (1) は 2 つの未知変数を持つ不良設定問題であるた\\n'\n",
      "                              'め，1 枚の入力画像から Retinex 理論による固有画像分\\n'\n",
      "                              '解を行うためには，何らかの仮定を設ける必要がある．\\n'\n",
      "                              '実用上は，照明成分の勾配に滑らかさを仮定して，入\\n'\n",
      "                              '力画像に平滑化フィルタを畳み込んだ結果を照明画像'},\n",
      "            'date': '2019-06-10 00:00:00',\n",
      "            'paper_title': 'CNN を用いた固有画像分解による低光量画像の視認性改善',\n",
      "            'pdf_name': 'IS1-11'},\n",
      " 'IS1-12': {'conf_name': 'SSII2019',\n",
      "            'content': {'序論': 'デジタル画像処理技術は幅広い分野において様々な\\n'\n",
      "                              '用途で活用されるようになり，様々なアプリケーショ\\n'\n",
      "                              'ンが登場している．多くのアプリケーションにおいて，\\n'\n",
      "                              '高品質な画像の撮像は高性能化に不可欠である．しか\\n'\n",
      "                              'し，カメラの CCD の微細化や画像の高画素化が進んで\\n'\n",
      "                              'おり，回折現象によるボケの発生，そして画素あたりの\\n'\n",
      "                              'ノイズレベルの増加による画像の品質低下に繋がって\\n'\n",
      "                              'いる．そこで，多くのアプリケーションの高性能化に\\n'\n",
      "                              'おいては画像のノイズ除去やボケ除去アルゴリズムの\\n'\n",
      "                              '高精度化が重要となる．また，ノイズ除去やボケ除去\\n'\n",
      "                              'の結果はアプリケーション全体の基盤となるため，全体\\n'\n",
      "                              'の処理のボトルネックとなることが多い．しかし，ノ\\n'\n",
      "                              'イズ除去やボケ除去には処理精度と計算コストの間に\\n'\n",
      "                              'トレードオフがあり，数多く存在する高精度な処理手\\n'\n",
      "                              '法は計算コストが高いという問題点を持つ．そのため，\\n'\n",
      "                              'リアルタイムな動画像処理を行うことが多くなった現\\n'\n",
      "                              '代においては，処理精度と計算コストのバランスが良\\n'\n",
      "                              'い手法の検討が不可欠である．ノイズ除去手法においては BM3D [1] が '\n",
      "                              'state-of-the-\\n'\n",
      "                              'arts の性能を持つ手法として知られている．そして，こ\\n'\n",
      "                              'の BM3D の簡易版である離散コサイン変換 (Discrete\\n'\n",
      "                              'Cosine Transform: DCT) を利用した，DCT デノイジ\\n'\n",
      "                              'ング [2] はノイズ除去精度と計算コストのバランスに優\\n'\n",
      "                              'れた手法である．そこで，本研究ではノイズ除去精度が高く実用的な\\n'\n",
      "                              'ノイズ除去手法の実現を目指し，DCT デノイジングの\\n'\n",
      "                              '高速化を行った．本概要ではまず，高速 DCT アルゴリ\\n'\n",
      "                              'ズムである AAN [3] の適用，そして実装上の高速化手\\n'\n",
      "                              '法について提案 DCT デノイジングの高速化について説\\n'\n",
      "                              '明する．'},\n",
      "            'date': '2019-06-10 00:00:00',\n",
      "            'paper_title': '冗長 DCT による高効率な周波数フィルタリング',\n",
      "            'pdf_name': 'IS1-12'},\n",
      " 'IS1-13': {'conf_name': 'SSII2019',\n",
      "            'content': {'序論': 'カメラと 3D LiDAR のセンサフュージョンにより，セ\\n'\n",
      "                              'ンサ単体の歩行者認識より性能が高く，かつ車載マイコンによる実用的なシステムを可能とすべく，本開\\n'\n",
      "                              '発を行った[1]．一般的に，歩行者は奥行き方向，横向き方向それぞれ類似した動作であるが，我々はより複雑な動作\\n'\n",
      "                              '(荷物を運ぶ，しゃがみなど)の場合の人物も認識でき\\n'\n",
      "                              'るシステムの開発を目指している。このため，識別処理により性能が高いものが必要になり，かつ処理時間の課題が発生することが容易に想定できたため，識別処理にディープラーニングを選定し，さらにこれ\\n'\n",
      "                              'を  FPGA へ搭載することで，これらの課題を解決した．'},\n",
      "            'date': '2019-06-10 00:00:00',\n",
      "            'paper_title': '車載向け FPGA 搭載に向けたコンパクトな Residual Network による人物検知',\n",
      "            'pdf_name': 'IS1-13'},\n",
      " 'IS1-14': {'conf_name': 'SSII2019',\n",
      "            'content': {'序論': '現在，日本では土砂災害が多発している．土砂災害\\n'\n",
      "                              'の発生後にさらなる被害の拡大を阻止するためには迅\\n'\n",
      "                              '速な復旧工事が必要であり，迅速な復旧工事のために\\n'\n",
      "                              'は，建設機械を使用する必要がある．土砂災害の現場\\n'\n",
      "                              'で建設機械を活用するためには，最初に，現場での建\\n'\n",
      "                              '設機械の走破性を素早く調査する必要がある. 走破性\\n'\n",
      "                              'の調査については，走破性の指標の 1 つであるコーン\\n'\n",
      "                              '指数を測定して行うことが多い [1]．しかし，災害現場\\n'\n",
      "                              'では，二次災害の危険性が存在し，現場に人が立ち入\\n'\n",
      "                              'ることは難しいため，無人で走破性を調査することが\\n'\n",
      "                              '望ましい．無人で走破性を調査する先行研究には，無\\n'\n",
      "                              '人地上車両（UGV）にコーン指数を測定する機器を搭\\n'\n",
      "                              '載して遠隔操作した研究がある [2] [3]．しかし，この\\n'\n",
      "                              '手法では，走破性の調査に多くの時間が必要となるだ\\n'\n",
      "                              'けでなく，さらに，UGV が進入できない場所の調査は\\n'\n",
      "                              '不可能である．従って，この手法では適用可能な土砂\\n'\n",
      "                              '災害が限定されてしまう可能性が大きい．一方，画像\\n'\n",
      "                              'を使用して走破性を判定することが可能となれば，短\\n'\n",
      "                              '時間での判定が可能となるだけでなく，さらに UGV や\\n'\n",
      "                              '人の進入が困難な場所の走破性についても，その外側\\n'\n",
      "                              'から撮影した画像さえあれば判定が可能となる．画像\\n'\n",
      "                              'を使用して走破性を判定する先行研究には，可視近赤\\n'\n",
      "                              '外，短波長赤外，長波長赤外の波長を撮影出来るカメ\\n'\n",
      "                              'ラを使用した研究がある [4] [5]．しかし，これらの先行\\n'\n",
      "                              '研究では，含水比と走破性の関係にのみ注目しており，\\n'\n",
      "                              '走破性に影響すると考えられる土壌の種類には，注目\\n'\n",
      "                              'していない．そこで，本研究では，画像から土壌の種類の判別と含\\n'\n",
      "                              '水比の推定の双方を行うことによって，土壌の走破性\\n'\n",
      "                              'を判定することを目的とする．なお，一般的な RGB 画\\n'\n",
      "                              '像では土壌の種類の判別ならびに，含水比の推定を同\\n'\n",
      "                              '時に行うことが不可能であると考えられるので，ハイ\\n'\n",
      "                              'パースペクトル画像を使用することとした．ハイパー\\n'\n",
      "                              'スペクトル画像の分類には，最尤推定法や多変量解析Copyright © SSII 2019. '\n",
      "                              'All Rights Reserved.- IS1-14 '\n",
      "                              '-が使用されることが多い．しかし，ニューラルネット\\n'\n",
      "                              'ワークの方が，学習データやラベルの定義に左右され\\n'\n",
      "                              'にくく [6]，重要な特徴量を自動で探索できることが知\\n'\n",
      "                              'られている [7]．そこで，本研究では, ニューラルネッ\\n'\n",
      "                              'トワークを利用し，土壌のハイパースペクトル画像を\\n'\n",
      "                              '分類することとした．本稿では，土壌の走破性を判定\\n'\n",
      "                              'する手法を提案すると共に，複数の土壌を用いて実施\\n'\n",
      "                              'した走破性判定試験について述べる．'},\n",
      "            'date': '2019-06-10 00:00:00',\n",
      "            'paper_title': 'ハイパースペクトル画像を用いた土壌の走破性の判定',\n",
      "            'pdf_name': 'IS1-14'},\n",
      " 'IS1-15': {'conf_name': 'SSII2019',\n",
      "            'content': {'序論': '安心安全な社会の実現のために，防犯や捜索など様々\\n'\n",
      "                              'な応用を目的として複数カメラを用いた広域見守りシ\\n'\n",
      "                              'ステムが必要とされている．このシステムは高精度な\\n'\n",
      "                              '人物対応付けの手法によって実現される．人物対応付\\n'\n",
      "                              'けには人物画像から抽出された人物に固有の特徴量を\\n'\n",
      "                              '使用し，特徴量間の距離を総当たりで計算する．そのた\\n'\n",
      "                              'めカメラ台数や被写体人数の変化により，処理負荷が\\n'\n",
      "                              '大きく増減する．このシステムにスケーラビリティを\\n'\n",
      "                              '持たせるため，クラウド上の計算サーバを用いてサー\\n'\n",
      "                              'バ上で人物対応付けを行うことが考えられる．しかし，\\n'\n",
      "                              '人物対応付けに使用する特徴量は，人物を特定できる\\n'\n",
      "                              'ため個人情報に該当する．よってクラウド上の計算サー\\n'\n",
      "                              'バを用いる場合，個人情報である特徴量を暗号化し，第\\n'\n",
      "                              '三者からはアクセスできない形で取り扱うことが求め\\n'\n",
      "                              'られる．人物対応付けをクラウド上の計算サーバで安全に行\\n'\n",
      "                              'うことを目指し，特徴量を準同型暗号 [1] により保護す\\n'\n",
      "                              'ることを考える．準同型暗号を用いることで，暗号化さ\\n'\n",
      "                              'れた特徴量をサーバ上で復号化することなく，距離計\\n'\n",
      "                              '算を行うことができる．準同型暗号を用いたパターン\\n'\n",
      "                              '認識の手法として，主成分分析への適用例 [2] や，深層\\n'\n",
      "                              '学習への適用例 [3] が報告されている．本稿では，特徴\\n'\n",
      "                              '量間の距離計算に準同型暗号を適用するシステムにつ\\n'\n",
      "                              'いて議論する．暗号化された人物対応付けの流れを図 1\\n'\n",
      "                              'に示す．検出した人物画像から特徴量を抽出し，その\\n'\n",
      "                              '特徴量を準同型暗号により保護してからクラウドサー\\n'\n",
      "                              'バ上へ送り距離計算を行う．準同型暗号を施して計算\\n'\n",
      "                              'を行う場合，暗号化せずに計算を行った場合と比較し\\n'\n",
      "                              'て処理時間が増大してしまう．そのため距離計算の回\\n'\n",
      "                              '数を減らす工夫が必要となる．距離計算の回数は，人\\n'\n",
      "                              '物対応付けに使用する人物画像の枚数によって決まる．\\n'\n",
      "                              '人物画像の枚数は，一人の人物に対してカメラ視野内\\n'\n",
      "                              'に存在している間に増加していく．本稿では，人物対応付け精度を保ったままカメラ視野\\n'\n",
      "                              '内で多数獲得される同一人物の画像枚数を削減し，準Copyright © SSII 2019. '\n",
      "                              'All Rights Reserved.- IS1-15 -図 1 '\n",
      "                              '特徴量を保護した人物対応付け同型暗号を用いて特徴量を保護する人物対応付けシス\\n'\n",
      "                              'テムを開発する．そのために各地点で見え方が類似し\\n'\n",
      "                              'た人物画像を選択することを指針とし，人物画像選択\\n'\n",
      "                              'のための基準を作成し，検出した全ての人物画像から\\n'\n",
      "                              '基準に沿う画像のみを選択する．基準には，人物の姿\\n'\n",
      "                              '勢を用いる．基準姿勢を用いて人物画像を選択するこ\\n'\n",
      "                              'とで，人物対応付け精度を保ったままで人物画像枚数\\n'\n",
      "                              'の削減が可能であるか確認をするために実験を行った．\\n'\n",
      "                              '以下，2 章では画像選択の関連研究について述べる．次\\n'\n",
      "                              'に 3 章では提案システムで用いる人物画像選択の手法\\n'\n",
      "                              'について述べ，4 章で人物画像選択を用いた提案システ\\n'\n",
      "                              'ムについて述べる．そして 5 章で独自データセットを\\n'\n",
      "                              '用いた人物画像選択の評価実験について述べる．最後\\n'\n",
      "                              'に，6 章でまとめる．'},\n",
      "            'date': '2019-06-10 00:00:00',\n",
      "            'paper_title': '個人情報が保護された人物対応付けにおける',\n",
      "            'pdf_name': 'IS1-15'},\n",
      " 'IS1-20': {'conf_name': 'SSII2019',\n",
      "            'content': {'序論': '製造・物流分野での労働力安定供給に向け，人の物理的な非定型作業を代替できるロボットの開発が求められている．さまざまな作業環境での代替実現には，作業環境の照明状況によらずに種々の物体を\\n'\n",
      "                              '認識できる必要がある．そこで，本研究では，画像\\n'\n",
      "                              'の局所的な鮮明度が照明条件によって変わること\\n'\n",
      "                              'に着目し，局所鮮明度に応じて対象物の類似度\\n'\n",
      "                              '評価方法を適切に自動選択する認識アーキテク\\n'\n",
      "                              'チャを開発した．倉庫作業を模擬した実験系を組\\n'\n",
      "                              'み，撮像画像内の複数対象物の照明条件がそれ\\n'\n",
      "                              'ぞれ異なる状況下において，従来手法は認識率\\n'\n",
      "                              'が 90%未満であるのに対し，提案手法では 98%\\n'\n",
      "                              '以上の認識率を達成できることを確認した．1  '\n",
      "                              '背景・目的近年，先進国を中心として，消費者ニーズの多様化に伴い，多種多様な製品・商品を扱う工場・倉庫と，そこでの従業員の物理的作業が急増してきている．今後，この人手不足の傾向に拍車が掛かることが予想される中，工場・倉庫内作業の自動化技術に対する期待が高まっている．与えられた状況を理解し，その状況に対応するための多様な非定型作業をこなすことができる自律作業ロボットが求められている．本研究では，このような自律作業ロボットの認識技術の向上を目的とする．視覚センサを用いて対象となる物品を認識することで，物品に対する高度な作業を可能と\\n'\n",
      "                              'することをめざす．対象物品の位置姿勢を認識するための有用な手法の一つとして，局所的な模様の類似度を評価する\\n'\n",
      "                              '手法が挙げられる[1]．この方法では，あらかじめ作\\n'\n",
      "                              '成したマスタデータと撮像して得た対象物の間で局所的な模様情報の類似度を計算することで多種多様\\n'\n",
      "                              'な物体の位置姿勢推定を可能とする．一方，模様の比較による物体認識の大きな技術課Copyright '\n",
      "                              '© SSII 2019. All Rights Reserved.- IS1-20 '\n",
      "                              '-題の一つとして，照明や影の映りこみによって対象物の認識精度が低下することが挙げられる．照明や影の映り込みによって物体の模様が不鮮明になると模様特徴が変化してしまい，結果として位置姿勢推定に失敗することがしばしば生じる．特に，認識結果に基づいて，ロボットが対象物品の把持動作を実施する場合には，位置姿勢推定の誤りによって，対象物品あるいはロボットの破損につながる恐れがある．この問題を解決する方法として，照明映り込み部分の模様を鮮明にするための画像修正技術も提案されているが，模様にグラデーションがある物体には適用で\\n'\n",
      "                              'きないなど，その利用範囲は限定的である[2]．そこで，本研究では，照明変動によらずに対象物品の位置姿勢を正しく推定することを目的とし，画像の局所領域ごとに模様の鮮明度合いを計算し，その鮮明度に応じて適切な類似度評価方法を選択・実行\\n'\n",
      "                              'する認識アーキテクチャを提案する．'},\n",
      "            'date': '2019-06-10 00:00:00',\n",
      "            'paper_title': '',\n",
      "            'pdf_name': 'IS1-20'}}\n"
     ]
    }
   ],
   "source": [
    "all_paper_dict = {}\n",
    "for paper_dict in dir_pdf_parser.parse_dict():\n",
    "    all_paper_dict.update(paper_dict)\n",
    "    \n",
    "pprint.pprint(all_paper_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### jsonへの保存 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-08T14:51:25.497668Z",
     "start_time": "2020-05-08T14:51:24.779067Z"
    }
   },
   "outputs": [],
   "source": [
    "save_path = Path(\"./papers.json\")\n",
    "with open(save_path,\"w\",encoding=\"utf-8\") as f:\n",
    "    json.dump(all_paper_dict,f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### カウント"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-08T15:01:04.979313Z",
     "start_time": "2020-05-08T15:01:04.877503Z"
    }
   },
   "outputs": [],
   "source": [
    "dir_path = Path(\"E:\\pdf_python\\PDFs\")\n",
    "start_patterns = {\"序論\":re.compile(\"[1-9]*( |　)*(背景|はじめに|Abstract|序論|概要|Introduction)\")}  # これが当てはまらないものも多い\n",
    "end_patterns = {\"序論\":re.compile(\"[2-9]+( |　)*(関連研究|提案手法|従来手法|従来研究)\")}  # これが当てはまらないものも多い\n",
    "count_patterns = [re.compile(\"ディープラーニング|深層学習\"),\n",
    "                  re.compile(\"CNN|ニューラルネットワーク\"),\n",
    "                  re.compile(\"VAE|変分オートエンコーダ\"),\n",
    "                  re.compile(\"GAN\")\n",
    "                 ]\n",
    "\n",
    "conference_name = \"SSII2019\"\n",
    "title_position_number = 2\n",
    "parse_page_numbers = [0]  # 正直これが一番重要(1枚目まで確認)\n",
    "date = datetime.datetime(2019, 6, 10, 0, 0, 0)\n",
    "pdf_paper_parser = PdfParserCount(count_patterns=count_patterns,\n",
    "                                  conference_name=conference_name,\n",
    "                                  start_patterns=start_patterns,\n",
    "                                  end_patterns=end_patterns,\n",
    "                                  title_position_number=title_position_number,\n",
    "                                  parse_page_numbers=parse_page_numbers,\n",
    "                                  date=date\n",
    "                                  )\n",
    "max_iter = 5\n",
    "\n",
    "dir_pdf_parser = DirectoryPdfParser(dir_path=dir_path,\n",
    "                                    pdf_parser=pdf_paper_parser,\n",
    "                                    max_iter=max_iter\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T10:31:04.161961Z",
     "start_time": "2020-05-06T10:31:04.083482Z"
    }
   },
   "source": [
    "#### paper_listのソート "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-08T15:27:49.983264Z",
     "start_time": "2020-05-08T15:25:20.853116Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9bb7259831b4968b130976afdf0aad4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=19.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "all_paper_list = []\n",
    "for paper_list in dir_pdf_parser.parse_paper_list():\n",
    "    all_paper_list.extend(paper_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-08T15:27:50.082998Z",
     "start_time": "2020-05-08T15:27:50.013184Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[IS1-13\n",
      "車載向け FPGA 搭載に向けたコンパクトな Residual Network による人物検知\n",
      "OrderedDict([(re.compile('ディープラーニング|深層学習'), 1), (re.compile('CNN|ニューラルネットワーク'), 0), (re.compile('VAE|変分オートエンコーダ'), 0), (re.compile('GAN'), 0)])\n",
      "2019-06-10 00:00:00, IS1-09\n",
      "\n",
      "OrderedDict([(re.compile('ディープラーニング|深層学習'), 0), (re.compile('CNN|ニューラルネットワーク'), 4), (re.compile('VAE|変分オートエンコーダ'), 0), (re.compile('GAN'), 0)])\n",
      "2019-06-10 00:00:00, IS1-11\n",
      "CNN を用いた固有画像分解による低光量画像の視認性改善\n",
      "OrderedDict([(re.compile('ディープラーニング|深層学習'), 0), (re.compile('CNN|ニューラルネットワーク'), 3), (re.compile('VAE|変分オートエンコーダ'), 0), (re.compile('GAN'), 1)])\n",
      "2019-06-10 00:00:00, IS1-03\n",
      "超音波厚さ測定の効率化のためのエコー検出手法\n",
      "OrderedDict([(re.compile('ディープラーニング|深層学習'), 0), (re.compile('CNN|ニューラルネットワーク'), 2), (re.compile('VAE|変分オートエンコーダ'), 0), (re.compile('GAN'), 0)])\n",
      "2019-06-10 00:00:00, IS1-06\n",
      "ドローンによる牧場空撮画像における乳牛の個体識別\n",
      "OrderedDict([(re.compile('ディープラーニング|深層学習'), 0), (re.compile('CNN|ニューラルネットワーク'), 2), (re.compile('VAE|変分オートエンコーダ'), 0), (re.compile('GAN'), 0)])\n",
      "2019-06-10 00:00:00, IS1-02\n",
      "VAEGAN の再構成誤差と Discriminator の ROI を活用した異常検出\n",
      "OrderedDict([(re.compile('ディープラーニング|深層学習'), 0), (re.compile('CNN|ニューラルネットワーク'), 0), (re.compile('VAE|変分オートエンコーダ'), 7), (re.compile('GAN'), 8)])\n",
      "2019-06-10 00:00:00, IS1-20\n",
      "\n",
      "OrderedDict([(re.compile('ディープラーニング|深層学習'), 0), (re.compile('CNN|ニューラルネットワーク'), 0), (re.compile('VAE|変分オートエンコーダ'), 0), (re.compile('GAN'), 0)])\n",
      "2019-06-10 00:00:00, IS1-04\n",
      "歩行者群分割\n",
      "OrderedDict([(re.compile('ディープラーニング|深層学習'), 0), (re.compile('CNN|ニューラルネットワーク'), 0), (re.compile('VAE|変分オートエンコーダ'), 0), (re.compile('GAN'), 0)])\n",
      "2019-06-10 00:00:00, IS1-05\n",
      "\n",
      "OrderedDict([(re.compile('ディープラーニング|深層学習'), 0), (re.compile('CNN|ニューラルネットワーク'), 0), (re.compile('VAE|変分オートエンコーダ'), 0), (re.compile('GAN'), 0)])\n",
      "2019-06-10 00:00:00, IS1-07\n",
      "\n",
      "OrderedDict([(re.compile('ディープラーニング|深層学習'), 0), (re.compile('CNN|ニューラルネットワーク'), 0), (re.compile('VAE|変分オートエンコーダ'), 0), (re.compile('GAN'), 0)])\n",
      "2019-06-10 00:00:00, IS1-08\n",
      "\n",
      "OrderedDict([(re.compile('ディープラーニング|深層学習'), 0), (re.compile('CNN|ニューラルネットワーク'), 0), (re.compile('VAE|変分オートエンコーダ'), 0), (re.compile('GAN'), 0)])\n",
      "2019-06-10 00:00:00, IS1-10\n",
      "ベクタ型レーザ投影における自己位置推定のためのマーカ埋め込み手法の検討\n",
      "OrderedDict([(re.compile('ディープラーニング|深層学習'), 0), (re.compile('CNN|ニューラルネットワーク'), 0), (re.compile('VAE|変分オートエンコーダ'), 0), (re.compile('GAN'), 0)])\n",
      "2019-06-10 00:00:00, IS1-12\n",
      "冗長 DCT による高効率な周波数フィルタリング\n",
      "OrderedDict([(re.compile('ディープラーニング|深層学習'), 0), (re.compile('CNN|ニューラルネットワーク'), 0), (re.compile('VAE|変分オートエンコーダ'), 0), (re.compile('GAN'), 0)])\n",
      "2019-06-10 00:00:00, IS1-14\n",
      "ハイパースペクトル画像を用いた土壌の走破性の判定\n",
      "OrderedDict([(re.compile('ディープラーニング|深層学習'), 0), (re.compile('CNN|ニューラルネットワーク'), 0), (re.compile('VAE|変分オートエンコーダ'), 0), (re.compile('GAN'), 0)])\n",
      "2019-06-10 00:00:00, IS1-15\n",
      "個人情報が保護された人物対応付けにおける\n",
      "OrderedDict([(re.compile('ディープラーニング|深層学習'), 0), (re.compile('CNN|ニューラルネットワーク'), 0), (re.compile('VAE|変分オートエンコーダ'), 0), (re.compile('GAN'), 0)])\n",
      "2019-06-10 00:00:00]\n"
     ]
    }
   ],
   "source": [
    "all_paper_list.sort(key=lambda paper_counter: tuple(paper_counter.counters.values()),reverse=True)  # OrderdDictなのでvalues順に並べればよい\n",
    "print(all_paper_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdf_py37",
   "language": "python",
   "name": "pdf_py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "202.542px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
