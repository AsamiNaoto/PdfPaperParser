{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDFパーサーの使い方 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下のサイトを参考にしました．  \n",
    "[【PDFMiner】PDFからテキストの抽出](https://qiita.com/mczkzk/items/894110558fb890c930b5)  \n",
    "[Programming with PDFMine](https://www.unixuser.org/~euske/python/pdfminer/programming.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T14:37:46.345938Z",
     "start_time": "2020-05-05T14:37:44.532878Z"
    }
   },
   "outputs": [],
   "source": [
    "from pdfminer.converter import PDFPageAggregator\n",
    "from pdfminer.layout import LAParams, LTContainer, LTTextBox\n",
    "from pdfminer.pdfinterp import PDFPageInterpreter, PDFResourceManager\n",
    "from pdfminer.pdfpage import PDFPage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T14:37:46.364742Z",
     "start_time": "2020-05-05T14:37:46.354766Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LayoutオブジェクトからLTTextBoxのリストを取得する関数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`device`オブジェクトの`get_result`メソッドが返す`layout`オブジェクトのうち，`LTTextBox`(テキストが入っている)のみ取り出し，リストにする．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T14:37:46.415607Z",
     "start_time": "2020-05-05T14:37:46.381695Z"
    }
   },
   "outputs": [],
   "source": [
    "def find_textboxes_recursively(layout):\n",
    "    \"\"\"\n",
    "    再帰的にテキストボックス（LTTextBox）を探して、テキストボックスのリストを取得する。\n",
    "    \"\"\"\n",
    "    # LTTextBoxを継承するオブジェクトの場合は1要素のリストを返す。\n",
    "    if isinstance(layout, LTTextBox):\n",
    "        text_boxes = [layout]\n",
    "        return text_boxes  # 返すのはリスト\n",
    "\n",
    "    # LTContainerを継承するオブジェクトは子要素を含むので、再帰的に探す。\n",
    "    if isinstance(layout, LTContainer):\n",
    "        text_boxes = []\n",
    "        for child in layout:\n",
    "            text_boxes.extend(find_textboxes_recursively(child))  # 再帰的にリストをextend\n",
    "            \n",
    "        return text_boxes\n",
    "\n",
    "    return []  # 何も取得できなかった場合は空リストを返す"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## パースに必要なクラスの作成 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T14:37:46.471459Z",
     "start_time": "2020-05-05T14:37:46.448516Z"
    }
   },
   "outputs": [],
   "source": [
    "# Layout Analysisのパラメーターを設定。縦書きの検出を有効にする。\n",
    "laparams = LAParams(detect_vertical=True)\n",
    "\n",
    "# 共有のリソースを管理するリソースマネージャーを作成。\n",
    "resource_manager = PDFResourceManager(caching=False)  # この引数によってエラーが出なくなる\n",
    "\n",
    "# ページを集めるPageAggregatorオブジェクトを作成。\n",
    "device = PDFPageAggregator(resource_manager, laparams=laparams)\n",
    "\n",
    "# Interpreterオブジェクトを作成。\n",
    "interpreter = PDFPageInterpreter(resource_manager, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二段組専用のソート方法 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T14:37:46.520326Z",
     "start_time": "2020-05-05T14:37:46.486416Z"
    }
   },
   "outputs": [],
   "source": [
    "class Sort2Column():\n",
    "    def __init__(self, layout_x0, layout_x1):\n",
    "        self.half_x = (layout_x0 + layout_x1)/2\n",
    "    \n",
    "    def __call__(self, text_box):\n",
    "        if text_box.x0 < self.half_x:\n",
    "            left_or_right = -1  # it mean left\n",
    "            \n",
    "        else:\n",
    "            left_or_right = 1  # it mean right\n",
    "            \n",
    "        return (left_or_right, -text_box.y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T14:37:46.609090Z",
     "start_time": "2020-05-05T14:37:46.534287Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([0,2,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ファイルを読み込み，パースを行う"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "qiitaの記事では，documentオブジェクトは必要ない`PDFPage.get_pages`メソッドを利用する．このメソッドはファイルオブジェクトを引数にとる．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T14:48:25.676555Z",
     "start_time": "2020-05-05T14:48:25.651851Z"
    }
   },
   "outputs": [],
   "source": [
    "file_path = Path(\"./PDFs/IS1-20.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T14:48:33.896232Z",
     "start_time": "2020-05-05T14:48:25.691516Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      "IS1-20\n",
      "SO1-20\n",
      "x0:15.0,x1:69.36\n",
      "y0:810.2,y1:843.32\n",
      "------------------\n",
      "第25回画像センシングシンポジウム\n",
      "x0:297.5,x1:435.693\n",
      "y0:825.98,y1:836.248\n",
      "------------------\n",
      "\n",
      "x0:67.224,x1:70.15968000000001\n",
      "y0:786.9408,y1:796.8144\n",
      "------------------\n",
      "画像の局所的な鮮明度合いを用いた照明変動にロバストな物体認識技術\n",
      "x0:112.58,x1:485.62\n",
      "y0:740.908,y1:753.808\n",
      "------------------\n",
      "矢野  泰樹†  木村  宣隆†  \n",
      "†株式会社  日立製作所\n",
      "x0:230.81,x1:379.39\n",
      "y0:692.908,y1:723.808\n",
      "------------------\n",
      "E-mail: taiki.yano.xt@hitachi.com\n",
      "x0:214.37,x1:383.83\n",
      "y0:674.908,y1:685.816\n",
      "------------------\n",
      "Abstract\n",
      "x0:151.46,x1:195.17\n",
      "y0:643.948,y1:654.856\n",
      "------------------\n",
      "製造・物流分野での労働力安定供給に向け，人の\n",
      "x0:67.224,x1:287.12544\n",
      "y0:621.65104,y1:632.21104\n",
      "------------------\n",
      "物理的な非定型作業を代替できるロボットの開発が\n",
      "x0:56.64,x1:287.03144\n",
      "y0:605.5710399999999,y1:616.13104\n",
      "------------------\n",
      "求められている．さまざまな作業環境での代替実現\n",
      "x0:56.64,x1:286.96304\n",
      "y0:589.58104,y1:600.1410400000001\n",
      "------------------\n",
      "には，作業環境の照明状況によらずに種々の物体を\n",
      "認識できる必要がある．そこで，本研究では，画像\n",
      "の局所的な鮮明度が照明条件によって変わること\n",
      "に着目し，局所鮮明度に応じて対象物の類似度\n",
      "評価方法を適切に自動選択する認識アーキテク\n",
      "チャを開発した．倉庫作業を模擬した実験系を組\n",
      "み，撮像画像内の複数対象物の照明条件がそれ\n",
      "ぞれ異なる状況下において，従来手法は認識率\n",
      "が 90%未満であるのに対し，提案手法では 98%\n",
      "以上の認識率を達成できることを確認した．\n",
      "x0:56.64,x1:287.11304\n",
      "y0:428.7172,y1:584.18104\n",
      "------------------\n",
      "\n",
      "x0:67.224,x1:70.4448\n",
      "y0:413.52103999999997,y1:424.08104\n",
      "------------------\n",
      "1  背景・目的\n",
      "x0:58.2,x1:151.22\n",
      "y0:387.81800000000004,y1:400.718\n",
      "------------------\n",
      "近年，先進国を中心として，消費者ニーズの多様\n",
      "x0:67.224,x1:287.21000000000004\n",
      "y0:365.52103999999997,y1:376.08104\n",
      "------------------\n",
      "化に伴い，多種多様な製品・商品を扱う工場・倉庫と，\n",
      "x0:56.64,x1:294.10184\n",
      "y0:349.56104,y1:360.12104\n",
      "------------------\n",
      "そこでの従業員の物理的作業が急増してきている．\n",
      "x0:56.64,x1:287.14184\n",
      "y0:333.60103999999995,y1:344.16103999999996\n",
      "------------------\n",
      "今後，この人手不足の傾向に拍車が掛かることが予\n",
      "x0:56.64,x1:286.93248000000006\n",
      "y0:317.52103999999997,y1:328.08104\n",
      "------------------\n",
      "想される中，工場・倉庫内作業の自動化技術に対す\n",
      "x0:56.64,x1:286.7846400000001\n",
      "y0:301.56104,y1:312.12104\n",
      "------------------\n",
      "る期待が高まっている．与えられた状況を理解し，そ\n",
      "x0:56.64,x1:287.05136\n",
      "y0:285.60103999999995,y1:296.16103999999996\n",
      "------------------\n",
      "の状況に対応するための多様な非定型作業をこなす\n",
      "x0:56.64,x1:287.0744\n",
      "y0:269.52103999999997,y1:280.08104\n",
      "------------------\n",
      "ことができる自律作業ロボットが求められている．本研\n",
      "x0:56.64,x1:287.21\n",
      "y0:253.53104000000002,y1:264.09104\n",
      "------------------\n",
      "究では，このような自律作業ロボットの認識技術の向\n",
      "x0:56.64,x1:287.09044\n",
      "y0:237.57104,y1:248.13104\n",
      "------------------\n",
      "上を目的とする．視覚センサを用いて対象となる物品\n",
      "x0:56.64,x1:287.21\n",
      "y0:221.49104,y1:232.05104\n",
      "------------------\n",
      "を認識することで，物品に対する高度な作業を可能と\n",
      "することをめざす．\n",
      "x0:56.64,x1:287.06496\n",
      "y0:189.0008,y1:216.09104000000002\n",
      "------------------\n",
      "対象物品の位置姿勢を認識するための有用な手\n",
      "x0:67.224,x1:287.21\n",
      "y0:173.49104,y1:184.05104\n",
      "------------------\n",
      "法の一つとして，局所的な模様の類似度を評価する\n",
      "手法が挙げられる[1]．この方法では，あらかじめ作\n",
      "成したマスタデータと撮像して得た対象物の間で局\n",
      "x0:56.64,x1:287.18888\n",
      "y0:125.49104,y1:168.09104000000002\n",
      "------------------\n",
      "所的な模様情報の類似度を計算することで多種多様\n",
      "な物体の位置姿勢推定を可能とする．\n",
      "x0:56.64,x1:287.09000000000003\n",
      "y0:92.9808,y1:120.09103999999999\n",
      "------------------\n",
      "一方，模様の比較による物体認識の大きな技術課\n",
      "x0:67.224,x1:287.15408\n",
      "y0:77.47103999999999,y1:88.03103999999999\n",
      "------------------\n",
      "\n",
      "x0:67.224,x1:70.15968000000001\n",
      "y0:49.780800000000006,y1:59.6544\n",
      "------------------\n",
      "Copyright © SSII 2019. All Rights Reserved.\n",
      "x0:15.0,x1:187.99200000000005\n",
      "y0:3.98,y1:14.248\n",
      "------------------\n",
      "- IS1-20 -\n",
      "x0:278.92,x1:316.07349999999997\n",
      "y0:3.98,y1:14.248\n",
      "------------------\n",
      "題の一つとして，照明や影の映りこみによって対象物\n",
      "x0:308.35,x1:538.72696\n",
      "y0:653.5710399999999,y1:664.13104\n",
      "------------------\n",
      "の認識精度が低下することが挙げられる．照明や影\n",
      "x0:308.35,x1:538.87312\n",
      "y0:637.61104,y1:648.1710400000001\n",
      "------------------\n",
      "の映り込みによって物体の模様が不鮮明になると模\n",
      "x0:308.35,x1:538.78\n",
      "y0:621.65104,y1:632.21104\n",
      "------------------\n",
      "様特徴が変化してしまい，結果として位置姿勢推定\n",
      "x0:308.35,x1:538.85392\n",
      "y0:605.5710399999999,y1:616.13104\n",
      "------------------\n",
      "に失敗することがしばしば生じる．特に，認識結果に\n",
      "x0:308.35,x1:538.6311999999999\n",
      "y0:589.58104,y1:600.1410400000001\n",
      "------------------\n",
      "基づいて，ロボットが対象物品の把持動作を実施す\n",
      "x0:308.35,x1:538.5368799999999\n",
      "y0:573.62104,y1:584.18104\n",
      "------------------\n",
      "る場合には，位置姿勢推定の誤りによって，対象物\n",
      "x0:308.35,x1:538.5263199999999\n",
      "y0:557.54104,y1:568.10104\n",
      "------------------\n",
      "品あるいはロボットの破損につながる恐れがある．こ\n",
      "x0:308.35,x1:538.82224\n",
      "y0:541.58104,y1:552.1410400000001\n",
      "------------------\n",
      "の問題を解決する方法として，照明映り込み部分の\n",
      "x0:308.35,x1:538.76464\n",
      "y0:525.62104,y1:536.18104\n",
      "------------------\n",
      "模様を鮮明にするための画像修正技術も提案されて\n",
      "x0:308.35,x1:538.80016\n",
      "y0:509.54103999999995,y1:520.10104\n",
      "------------------\n",
      "いるが，模様にグラデーションがある物体には適用で\n",
      "きないなど，その利用範囲は限定的である[2]．\n",
      "x0:308.35,x1:538.64248\n",
      "y0:477.05080000000004,y1:504.14104\n",
      "------------------\n",
      "そこで，本研究では，照明変動によらずに対象物\n",
      "x0:318.91,x1:538.64536\n",
      "y0:461.54103999999995,y1:472.10103999999995\n",
      "------------------\n",
      "品の位置姿勢を正しく推定することを目的とし，画像\n",
      "x0:308.35,x1:538.7799999999999\n",
      "y0:445.58104,y1:456.14104\n",
      "------------------\n",
      "の局所領域ごとに模様の鮮明度合いを計算し，その\n",
      "x0:308.35,x1:538.6465599999999\n",
      "y0:429.62104,y1:440.18104\n",
      "------------------\n",
      "鮮明度に応じて適切な類似度評価方法を選択・実行\n",
      "する認識アーキテクチャを提案する．\n",
      "x0:308.35,x1:538.7838399999999\n",
      "y0:396.76904,y1:424.08104\n",
      "------------------\n",
      "\n",
      "x0:318.91,x1:321.55\n",
      "y0:380.80904,y1:390.40808\n",
      "------------------\n",
      "2  従来手法\n",
      "x0:309.91,x1:390.91\n",
      "y0:355.778,y1:368.678\n",
      "------------------\n",
      "局所的な模様の類似度から対象物品の位置姿勢\n",
      "を推定する手法は，主に以下の 3 つのステップにし\n",
      "たがって認識を実行する（図  1）[1]．\n",
      "x0:308.35,x1:538.8059199999999\n",
      "y0:300.99080000000004,y1:344.16103999999996\n",
      "------------------\n",
      "i)  局所特徴の取得 \n",
      "局所的な模様の情報を取得するためには，特徴\n",
      "x0:318.91,x1:538.8999999999999\n",
      "y0:269.52103999999997,y1:296.16103999999996\n",
      "------------------\n",
      "的な模様箇所を示す特徴点の抽出と，各特徴点に\n",
      "x0:308.35,x1:538.67152\n",
      "y0:253.53104000000002,y1:264.09104\n",
      "------------------\n",
      "おける局所的な模様情報を表現する特徴量の記述\n",
      "が必要となる[3]-[5]．あらかじめ，認識対象とする物\n",
      "体を複数方向から撮像して得た特徴点と特徴量を物\n",
      "体の 3 次元モデルの対応箇所に紐づけたマスタデー\n",
      "タを作成しておく．認識時には，マスタデータに登録\n",
      "x0:308.35,x1:538.90288\n",
      "y0:173.49104,y1:248.13104\n",
      "------------------\n",
      "したものと同じ種類の特徴点抽出手法と特徴量記述\n",
      "手法を利用してシーン画像(RGBD 画像)から模様特\n",
      "徴を取得する．\n",
      "x0:308.35,x1:538.7819199999999\n",
      "y0:124.9208,y1:168.09104000000002\n",
      "------------------\n",
      "ii)  特徴点マッチング \n",
      "次に，シーン画像から得た特徴点とマスタデータ\n",
      "の特徴点の間で特徴量が最も似通った特徴点組を\n",
      "x0:308.35,x1:538.72888\n",
      "y0:76.90079999999999,y1:120.09103999999999\n",
      "-------pages---------\n",
      "------------------\n",
      "IS1-20\n",
      "SO1-20\n",
      "x0:15.0,x1:69.36\n",
      "y0:810.2,y1:843.32\n",
      "------------------\n",
      "第25回画像センシングシンポジウム\n",
      "x0:297.5,x1:435.693\n",
      "y0:825.98,y1:836.248\n",
      "------------------\n",
      "\n",
      "x0:67.224,x1:70.15968000000001\n",
      "y0:786.9408,y1:796.8144\n",
      "------------------\n",
      "\n",
      "x0:287.69,x1:290.62568\n",
      "y0:487.1308,y1:497.0044\n",
      "------------------\n",
      "図  1  特徴点マッチングを利用した認識の概要\n",
      "x0:67.224,x1:276.70568\n",
      "y0:471.05080000000004,y1:482.18104\n",
      "------------------\n",
      "\n",
      "x0:67.224,x1:70.15968000000001\n",
      "y0:454.73080000000004,y1:464.6044\n",
      "------------------\n",
      "作成する．特徴点組の作成方法の一つとして，マス\n",
      "x0:56.64,x1:286.97472\n",
      "y0:439.58104,y1:450.14104\n",
      "------------------\n",
      "タデータの特徴点ごとに特徴量が最も近いシーン上\n",
      "の特徴点を選択する方法が挙げられる．\n",
      "x0:56.64,x1:286.7846400000001\n",
      "y0:406.9508,y1:434.16103999999996\n",
      "------------------\n",
      "iii)  RANSAC による位置姿勢推定 \n",
      "ii)で求めた特徴点組には，誤った特徴点の対応\n",
      "関係も含まれている．そのような誤った特徴点組の影\n",
      "響を除外するため，RANSAC と呼ばれる手法を用い\n",
      "て位置姿勢を推定する[6]．まず，上記で得た特徴点\n",
      "組からランダムに数組を選択し，これらの特徴点間距\n",
      "離の総和が最短となるようにマスタデータの 3D モデ\n",
      "ルの位置姿勢を変換する．姿勢変換後，全特徴点組\n",
      "x0:56.64,x1:287.13296\n",
      "y0:279.60103999999995,y1:402.12104\n",
      "------------------\n",
      "の特徴点間距離を計算し，その距離が閾値以内とな\n",
      "x0:56.64,x1:287.25480000000005\n",
      "y0:263.52103999999997,y1:274.08104\n",
      "------------------\n",
      "る特徴点組数をその位置姿勢でのスコアとする．そし\n",
      "x0:56.64,x1:287.13544\n",
      "y0:247.53104000000002,y1:258.09104\n",
      "------------------\n",
      "て，この処理を複数回繰り返し，最もスコアが高い位\n",
      "x0:56.64,x1:287.21\n",
      "y0:231.57104,y1:242.13104\n",
      "------------------\n",
      "置姿勢を認識結果として出力する．なお，最高スコア\n",
      "x0:56.64,x1:287.12839999999994\n",
      "y0:215.49104,y1:226.05104\n",
      "------------------\n",
      "が予め定めた閾値より低い場合は，誤った推定結果\n",
      "と判断して認識結果から除外する．\n",
      "x0:56.64,x1:287.01704\n",
      "y0:183.0008,y1:210.09104000000002\n",
      "------------------\n",
      "なお，より認識精度を高めるために，前処理として\n",
      "認識対象とするシーン局所領域を抽出する手法[7]\n",
      "を使用することや，あるいは，後処理としてマスタデ\n",
      "ータの 3D モデルとシーン点群との間の詳細位置合\n",
      "わせ[8]を実施することも多い．\n",
      "x0:56.64,x1:287.21768000000003\n",
      "y0:102.96079999999999,y1:178.05104\n",
      "------------------\n",
      "\n",
      "x0:67.224,x1:70.15968000000001\n",
      "y0:49.780800000000006,y1:59.6544\n",
      "------------------\n",
      "Copyright © SSII 2019. All Rights Reserved.\n",
      "x0:15.0,x1:187.99200000000005\n",
      "y0:3.98,y1:14.248\n",
      "------------------\n",
      "- IS1-20 -\n",
      "x0:278.92,x1:316.07349999999997\n",
      "y0:3.98,y1:14.248\n",
      "------------------\n",
      "3  従来手法の問題点\n",
      "x0:309.79,x1:438.94\n",
      "y0:741.868,y1:754.768\n",
      "------------------\n",
      "SIFT[3]に代表されるような表現能力の高い特徴量\n",
      "はその識別性能が高いため，2  -  i)の局所特徴の取\n",
      "得，およびその後の 2 - ii)の特徴点マッチングを実施\n",
      "する上でよく用いられる．一方，照明変動に対して特\n",
      "x0:308.35,x1:538.9\n",
      "y0:671.5710399999999,y1:730.13104\n",
      "------------------\n",
      "徴量が変化しやすいため，照明変動が生じた局所領\n",
      "x0:308.35,x1:538.78\n",
      "y0:655.61104,y1:666.1710400000001\n",
      "------------------\n",
      "域においては，適切な特徴点組が生成されないおそ\n",
      "れがある．2  -  iii)の RANSAC での位置姿勢の評価\n",
      "は，この特徴点組を利用するため，適切な特徴点組\n",
      "x0:308.35,x1:538.90576\n",
      "y0:607.61104,y1:650.21104\n",
      "------------------\n",
      "数の減少によってスコアが低下した結果，対象物品\n",
      "x0:308.35,x1:538.75312\n",
      "y0:591.62104,y1:602.18104\n",
      "------------------\n",
      "の認識が困難となることや，あるいは，スコアの低下\n",
      "x0:308.35,x1:538.8318399999999\n",
      "y0:575.54104,y1:586.10104\n",
      "------------------\n",
      "に合わせて閾値を下げると，誤った位置姿勢も認識\n",
      "結果として出力してしまう可能性がある．\n",
      "x0:308.35,x1:538.69456\n",
      "y0:543.0508,y1:570.1410400000001\n",
      "------------------\n",
      "一 方 ，照 明 変 動 に 対 してよりロ バ スト な特 徴 量\n",
      "[4][5]を利用して特徴点マッチングを実施した場合で\n",
      "も，このような特徴量はその識別性能が低いため，誤\n",
      "x0:308.35,x1:538.78\n",
      "y0:495.62104,y1:538.10104\n",
      "------------------\n",
      "った特徴点組が多数生成されてしまい，結果として，\n",
      "正しい認識結果が得られない可能性がある．\n",
      "x0:308.35,x1:538.71664\n",
      "y0:463.0108,y1:490.10103999999995\n",
      "------------------\n",
      "\n",
      "x0:318.91,x1:321.84568\n",
      "y0:446.81080000000003,y1:456.6844\n",
      "------------------\n",
      "4  局所鮮明度に基づく特徴切替手法\n",
      "x0:309.79,x1:523.2760000000001\n",
      "y0:421.85,y1:434.678\n",
      "------------------\n",
      "3 の従来手法の問題点を解決するため，識別能力\n",
      "の高い特徴量と照明変動に対してロバストな特徴量\n",
      "x0:308.35,x1:538.9076799999999\n",
      "y0:383.52103999999997,y1:410.16103999999996\n",
      "------------------\n",
      "の両方を用いて類似度を評価することが考えられる．\n",
      "x0:308.35,x1:538.83184\n",
      "y0:367.56104,y1:378.12104\n",
      "------------------\n",
      "しかし，両者の利点を活かした類似度評価を実施し\n",
      "x0:308.35,x1:538.69528\n",
      "y0:351.60103999999995,y1:362.16103999999996\n",
      "------------------\n",
      "ないと，照明変動が生じた領域の類似度を適切に評\n",
      "x0:308.35,x1:538.5052000000001\n",
      "y0:335.52103999999997,y1:346.08104\n",
      "------------------\n",
      "価できないことによる認識失敗や，あるいは，類似度\n",
      "x0:308.35,x1:538.47352\n",
      "y0:319.56104,y1:330.12104\n",
      "------------------\n",
      "評価の信頼度低下による誤認識につながってしまう．\n",
      "x0:308.35,x1:538.83184\n",
      "y0:303.60103999999995,y1:314.16103999999996\n",
      "------------------\n",
      "そのため，対象物が受けた照明の影響に応じて類似\n",
      "x0:308.35,x1:538.62136\n",
      "y0:287.52103999999997,y1:298.08104\n",
      "------------------\n",
      "度評価に使用する特徴を適切に切り替えることが求\n",
      "められる．\n",
      "x0:308.35,x1:538.65304\n",
      "y0:255.0008,y1:282.12104\n",
      "------------------\n",
      "ここで，照明条件の画像への影響は局所的な模様\n",
      "x0:318.91,x1:538.8748\n",
      "y0:239.49104,y1:250.05104\n",
      "------------------\n",
      "の鮮明度合いの変化に現れることに着目する．影や\n",
      "x0:308.35,x1:538.8999999999999\n",
      "y0:223.53104000000002,y1:234.09104000000002\n",
      "------------------\n",
      "照明の映り込みが無い領域では，対象物の模様が\n",
      "x0:308.35,x1:538.54744\n",
      "y0:207.57104,y1:218.13104\n",
      "------------------\n",
      "鮮明に見えるため，識別能力の高い特徴を用いて類\n",
      "x0:308.35,x1:538.69528\n",
      "y0:191.49104,y1:202.05104\n",
      "------------------\n",
      "似度評価が可能である．一方，影や照明の映り込み\n",
      "x0:308.35,x1:538.61848\n",
      "y0:175.53104000000002,y1:186.09104000000002\n",
      "------------------\n",
      "により模様の鮮明度が低下した領域では，照明変動\n",
      "x0:308.35,x1:538.60024\n",
      "y0:159.57104,y1:170.13104\n",
      "------------------\n",
      "に対してロバストな特徴を使用することで，照明変動\n",
      "の影響を受けにくくなる． \n",
      "上記の議論をもとに，本研究では，画像の局所的な\n",
      "x0:308.35,x1:538.8174399999999\n",
      "y0:111.57104,y1:154.05104\n",
      "------------------\n",
      "鮮明度に応じて照明変動が生じた領域を推定し，領\n",
      "域ごとに適切な特徴種類を利用して類似度を評価す\n",
      "x0:308.35,x1:540.3956800000001\n",
      "y0:78.9408,y1:106.05503999999999\n",
      "-------pages---------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      "IS1-20\n",
      "SO1-20\n",
      "x0:15.0,x1:69.36\n",
      "y0:810.2,y1:843.32\n",
      "------------------\n",
      "第25回画像センシングシンポジウム\n",
      "x0:297.5,x1:435.693\n",
      "y0:825.98,y1:836.248\n",
      "------------------\n",
      "\n",
      "x0:67.224,x1:70.15968000000001\n",
      "y0:786.9408,y1:796.8144\n",
      "------------------\n",
      "図  2  提案手法の概要\n",
      "x0:126.14,x1:230.98568\n",
      "y0:567.0508,y1:578.18104\n",
      "------------------\n",
      "\n",
      "x0:67.224,x1:70.15968000000001\n",
      "y0:550.7307999999999,y1:560.6043999999999\n",
      "------------------\n",
      "る方法を提案する  (図  2)．これにより，照明変動が\n",
      "生じた物品に対しても，誤認識を増加させることなく\n",
      "x0:56.64,x1:287.00048\n",
      "y0:519.62104,y1:546.1410400000001\n",
      "------------------\n",
      "正しく認識することが可能になる．以下に，その詳細\n",
      "な処理方法を記述する．\n",
      "x0:56.64,x1:286.76352000000014\n",
      "y0:487.0108,y1:514.10104\n",
      "------------------\n",
      "A)  フーリエ変換を利用した局所鮮明度の算出 \n",
      "まず始めに局所的な模様の鮮明度合いを定量化\n",
      "x0:67.224,x1:286.86143999999996\n",
      "y0:455.54103999999995,y1:482.18104\n",
      "------------------\n",
      "する必要がある．本研究では，画像の局所領域に対\n",
      "x0:56.64,x1:287.1044\n",
      "y0:439.58104,y1:450.14104\n",
      "------------------\n",
      "して離散フーリエ変換を実行して得られた各周波数\n",
      "x0:56.64,x1:287.06311999999997\n",
      "y0:423.60103999999995,y1:434.16103999999996\n",
      "------------------\n",
      "の振幅を正規化し，その分散を局所鮮明度として定\n",
      "x0:56.64,x1:286.9448\n",
      "y0:407.52103999999997,y1:418.08104\n",
      "------------------\n",
      "義する．また，画像の局所領域をその領域での局所\n",
      "x0:56.64,x1:287.03312000000005\n",
      "y0:391.56104,y1:402.12104\n",
      "------------------\n",
      "鮮明度に応じて，模様が鮮明である高鮮明度領域，\n",
      "x0:56.64,x1:287.06888000000004\n",
      "y0:375.60103999999995,y1:386.16103999999996\n",
      "------------------\n",
      "模様が不鮮明である中鮮明度領域，模様がほとんど\n",
      "見られない低鮮明度領域の 3 つの領域に区分する．\n",
      "x0:56.64,x1:289.90568\n",
      "y0:342.99080000000004,y1:370.08104\n",
      "------------------\n",
      "B)  鮮明度に応じた特徴種類の切替 \n",
      "2 - iii)で述べた RANSAC による位置姿勢評価で\n",
      "は，特徴点間の幾何的情報のみを用いて評価してい\n",
      "x0:56.64,x1:287.18696\n",
      "y0:295.56104,y1:338.16103999999996\n",
      "------------------\n",
      "たが，本手法では，この姿勢評価時に模様が不鮮明\n",
      "x0:56.64,x1:287.05544000000003\n",
      "y0:279.60103999999995,y1:290.16103999999996\n",
      "------------------\n",
      "となった局所領域の模様特徴の類似度を，照明変動\n",
      "x0:56.64,x1:287.0756\n",
      "y0:263.52103999999997,y1:274.08104\n",
      "------------------\n",
      "に対してよりロバストな特徴を利用して再度評価しな\n",
      "x0:56.64,x1:287.13524\n",
      "y0:247.53104000000002,y1:258.09104\n",
      "------------------\n",
      "おす．まず，マスタデータの全特徴点のうち，推定さ\n",
      "x0:56.64,x1:286.81616\n",
      "y0:231.57104,y1:242.13104\n",
      "------------------\n",
      "れた姿勢のもとで視認可能である特徴点をシーン画\n",
      "x0:56.64,x1:286.7952\n",
      "y0:215.49104,y1:226.05104\n",
      "------------------\n",
      "像に投影し，投影先が中鮮明度領域に属する特徴\n",
      "x0:56.64,x1:286.94384\n",
      "y0:199.53104000000002,y1:210.09104000000002\n",
      "------------------\n",
      "点を取得する．その後，得られた特徴点ごとに，再評\n",
      "x0:56.64,x1:287.09000000000003\n",
      "y0:183.57104,y1:194.13104\n",
      "------------------\n",
      "価用の特徴量を利用して模様特徴の類似度を算出\n",
      "x0:56.64,x1:286.91312\n",
      "y0:167.49104,y1:178.05104\n",
      "------------------\n",
      "し，その値が閾値以内に入っていた場合に，あらかじ\n",
      "x0:56.64,x1:287.01608\n",
      "y0:151.53104000000002,y1:162.09104000000002\n",
      "------------------\n",
      "め定めた値をスコアに加算する．なお，高鮮明度領\n",
      "域において，再度 SIFT 特徴の類似度を評価するこ\n",
      "とも考えられるが，本研究では，マッチング処理と比\n",
      "x0:56.64,x1:287.09\n",
      "y0:103.53103999999999,y1:146.13104\n",
      "------------------\n",
      "較情報が一部重複すること，また，計算コストの削減\n",
      "の観点から省略した．\n",
      "x0:56.64,x1:286.8480000000001\n",
      "y0:70.90079999999999,y1:98.11104\n",
      "------------------\n",
      "\n",
      "x0:67.224,x1:70.15968000000001\n",
      "y0:49.780800000000006,y1:59.6544\n",
      "------------------\n",
      "Copyright © SSII 2019. All Rights Reserved.\n",
      "x0:15.0,x1:187.99200000000005\n",
      "y0:3.98,y1:14.248\n",
      "------------------\n",
      "- IS1-20 -\n",
      "x0:278.92,x1:316.07349999999997\n",
      "y0:3.98,y1:14.248\n",
      "------------------\n",
      "5  実験結果\n",
      "x0:309.91,x1:390.91\n",
      "y0:741.868,y1:754.768\n",
      "------------------\n",
      "i)  実験方法 \n",
      "本実験は，倉庫作業での認識を想定し，RGBD カ\n",
      "メラを図  3(a)のように固定設置した条件で行った．認\n",
      "識対象物品上面の最短距離は約 200[mm]であり，\n",
      "カメラは鉛直下向きを向くように取り付けた．RGBD\n",
      "カメラは，Intel  RealSenseTM  Camera  (SR300) \n",
      "を用い，解像度は 640×480 とした．認識対象物は\n",
      "図  4 で，実際に撮像した画像の一例を図  3(b)に示\n",
      "す．なお，物品サイズは 50×50×100[mm]である． \n",
      "本実験では，3 つの照明条件（通常，暗所，強光）\n",
      "が含まれる計 56 シーンに対して本認識アーキテクチ\n",
      "ャを用いた場合の認識率を評価した．ここで図  3(b)\n",
      "の左下のように模様が鮮明に映っている照明条件\n",
      "を通常，左上のように全体が暗く画像のコントラスト\n",
      "が低下している照明条件を暗所，右上のように照\n",
      "明の映り込みによって，模様の一部が見えづらくな\n",
      "っている照明条件を強光とし，本基準をもとに各物\n",
      "品の照明条件を人手で決定した．また，Ground \n",
      "truth となる位置姿勢は，人手による位置合わせによ\n",
      "って算出し，認識率の算出方法は，Drost ら[9]の方\n",
      "法を採用した．なお，本実験の目的は，誤認識を出\n",
      "x0:308.35,x1:541.6033600000001\n",
      "y0:399.60103999999995,y1:730.13104\n",
      "------------------\n",
      "\n",
      "x0:298.25,x1:301.18568\n",
      "y0:586.1308,y1:596.0044\n",
      "------------------\n",
      "さずに対象物品の位置姿勢を正しく推定できるか評\n",
      "x0:308.35,x1:538.5368799999999\n",
      "y0:383.52103999999997,y1:394.08104\n",
      "------------------\n",
      "価することとし，誤認識が生じない範囲で認識率が最\n",
      "大となるようにパラメータを調整した．\n",
      "x0:308.35,x1:538.7519199999999\n",
      "y0:351.0308,y1:378.12104\n",
      "------------------\n",
      "提案手法で使用する特徴点マッチング時の特徴\n",
      "点抽出手法および特徴量記述手法はともに SIFT を\n",
      "使用し，中鮮明度領域での模様類似度再評価する\n",
      "際の特徴量は HOG を使用した．シーン画像から\n",
      "HOG 特徴を求める際は，マスタデータと同サイズか\n",
      "つ同方向を向くように，シーン画像上の対象領域を\n",
      "x0:308.35,x1:538.9288\n",
      "y0:255.57104,y1:346.08104\n",
      "------------------\n",
      "変形して，特徴量を取得した．また，スコアの重みとし\n",
      "て[SIFT での一致時のスコア, HOG での一致時のス\n",
      "コア] = [1.0, 0.5]とした．提案手法の前処理である局\n",
      "所領域抽出は BING[7]を，後処理である詳細位置\n",
      "合わせは ICP[8]を利用した． \n",
      "比較手法として，2 の従来手法で SIFT を利用する場\n",
      "合(SIFT マッチング)と，4 の提案手法において，高\n",
      "鮮明度領域および低鮮明度領域を含む全領域で\n",
      "HOG による模様特徴の再評価を実施した場合（全\n",
      "領域 HOG 評価）の 2 種類の手法を評価した．\n",
      "x0:308.35,x1:538.91728\n",
      "y0:94.92479999999999,y1:250.05104\n",
      "-------pages---------\n",
      "------------------\n",
      "IS1-20\n",
      "SO1-20\n",
      "x0:15.0,x1:69.36\n",
      "y0:810.2,y1:843.32\n",
      "------------------\n",
      "第25回画像センシングシンポジウム\n",
      "x0:297.5,x1:435.693\n",
      "y0:825.98,y1:836.248\n",
      "------------------\n",
      "\n",
      "x0:67.224,x1:70.15968000000001\n",
      "y0:786.9408,y1:796.8144\n",
      "------------------\n",
      "\n",
      "x0:283.25,x1:286.18568\n",
      "y0:630.3208,y1:640.1944\n",
      "------------------\n",
      "図  3 (a)  実験環境，  (b)  撮像画像\n",
      "x0:67.224,x1:229.30568\n",
      "y0:615.0808,y1:626.21104\n",
      "------------------\n",
      "\n",
      "x0:264.41,x1:267.34568\n",
      "y0:499.0108,y1:508.88439999999997\n",
      "------------------\n",
      "図  4 (a)  物品 1,    (b)  物品 2\n",
      "x0:67.224,x1:203.62568\n",
      "y0:487.0108,y1:498.14104\n",
      "------------------\n",
      "\n",
      "x0:289.13,x1:292.06568\n",
      "y0:394.4708,y1:404.34439999999995\n",
      "------------------\n",
      "図  5  (a)  局所鮮明度，(b)  認識結果(提案手法),\n",
      "x0:67.584,x1:289.54566\n",
      "y0:375.0308,y1:386.16103999999996\n",
      "------------------\n",
      "(c)認識結果(従来手法)\n",
      "x0:120.26,x1:226.18568\n",
      "y0:358.9508,y1:370.08104\n",
      "------------------\n",
      "\n",
      "x0:56.64,x1:59.57568\n",
      "y0:342.7508,y1:352.6244\n",
      "------------------\n",
      "ii)  実験結果\n",
      "x0:67.224,x1:133.15568\n",
      "y0:326.87239999999997,y1:338.16103999999996\n",
      "------------------\n",
      "図  5 に提案手法による認識結果を示す．図  5(a)は，\n",
      "図  4(b)の画像に対して提案手法を適用した際に得\n",
      "られた局所鮮明度領域の画像である．なお，赤 \n",
      "色は高鮮明度領域を，黄色は中鮮明度領域を，黒\n",
      "x0:56.64,x1:294.10188\n",
      "y0:263.52103999999997,y1:322.08104\n",
      "------------------\n",
      "色は低鮮明度領域を示す．この図から，本研究で定\n",
      "x0:56.64,x1:286.9008\n",
      "y0:247.53104000000002,y1:258.09104\n",
      "------------------\n",
      "義した局所鮮明度を用いることで，照明変動によって\n",
      "x0:56.64,x1:287.05920000000003\n",
      "y0:231.57104,y1:242.13104\n",
      "------------------\n",
      "模様が不鮮明となった領域を区分できることを確認し\n",
      "た．また，図  5(b)(c)は提案手法と従来手法それぞれ\n",
      "の認識結果であり，赤枠は推定された対象物品の位\n",
      "x0:56.64,x1:287.04864000000003\n",
      "y0:183.57104,y1:226.05104\n",
      "------------------\n",
      "置姿勢を表す．この結果から見て取れるように，従来\n",
      "x0:56.64,x1:286.8057600000001\n",
      "y0:167.49104,y1:178.05104\n",
      "------------------\n",
      "手法で認識が困難であった暗所に置かれた物品に\n",
      "対しても，提案手法では HOG による追加検証を実\n",
      "施することで正しく認識できている．\n",
      "x0:56.64,x1:287.1044\n",
      "y0:118.9208,y1:162.09104000000002\n",
      "------------------\n",
      "また，表  1 に各手法の認識結果を示す．全照明\n",
      "条件において，提案手法の認識率が最も高く，従来\n",
      "手法である SIFT のみを用いて評価した場合の認\n",
      "x0:56.64,x1:289.30568\n",
      "y0:70.90079999999999,y1:114.09103999999999\n",
      "------------------\n",
      "\n",
      "x0:67.224,x1:70.15968000000001\n",
      "y0:49.780800000000006,y1:59.6544\n",
      "------------------\n",
      "Copyright © SSII 2019. All Rights Reserved.\n",
      "x0:15.0,x1:187.99200000000005\n",
      "y0:3.98,y1:14.248\n",
      "------------------\n",
      "- IS1-20 -\n",
      "x0:278.92,x1:316.07349999999997\n",
      "y0:3.98,y1:14.248\n",
      "------------------\n",
      "表  1  認識結果  上：物品 1,  中：物品 2,  下：計\n",
      "x0:323.83,x1:536.55568\n",
      "y0:743.0007999999999,y1:754.13104\n",
      "------------------\n",
      "全領域\n",
      "x0:441.34,x1:475.83567999999997\n",
      "y0:726.5608,y1:737.69104\n",
      "------------------\n",
      "提案 \n",
      "手法\n",
      "x0:498.1,x1:522.0356800000001\n",
      "y0:710.4807999999999,y1:737.69104\n",
      "------------------\n",
      "SIFT \n",
      "マ ッ チ ン グ\n",
      "(従来手法)\n",
      "x0:377.47,x1:430.55512000000004\n",
      "y0:694.5208,y1:736.1944\n",
      "------------------\n",
      "\n",
      "x0:308.35,x1:311.28568\n",
      "y0:726.3208,y1:736.1944\n",
      "------------------\n",
      "HOG \n",
      "評価\n",
      "x0:441.34,x1:469.35568\n",
      "y0:694.5208,y1:720.1143999999999\n",
      "------------------\n",
      "通 常 条 件 \n",
      "(82  ピース) \n",
      "暗所条件 \n",
      "(99  ピース) \n",
      "強光条件 \n",
      "(52  ピース) \n",
      "計   \n",
      "(233  ピース)\n",
      "x0:308.35,x1:369.72568\n",
      "y0:563.4508,y1:688.13104\n",
      "------------------\n",
      "93.9%\n",
      "x0:377.47,x1:409.56568\n",
      "y0:676.7608,y1:686.6344\n",
      "------------------\n",
      "90.2%\n",
      "x0:441.34,x1:473.43568\n",
      "y0:676.7608,y1:686.6344\n",
      "------------------\n",
      "100.0%\n",
      "x0:498.1,x1:536.07568\n",
      "y0:676.7608,y1:686.6344\n",
      "------------------\n",
      "\n",
      "x0:441.34,x1:444.27567999999997\n",
      "y0:660.8008,y1:670.6744\n",
      "------------------\n",
      "81.3%\n",
      "x0:377.47,x1:409.56568\n",
      "y0:644.2407999999999,y1:654.1143999999999\n",
      "------------------\n",
      "76.5%\n",
      "x0:441.34,x1:473.43568\n",
      "y0:644.2407999999999,y1:654.1143999999999\n",
      "------------------\n",
      "97.1%\n",
      "x0:498.1,x1:530.19568\n",
      "y0:644.2407999999999,y1:654.1143999999999\n",
      "------------------\n",
      "63.3%\n",
      "x0:377.47,x1:409.56568\n",
      "y0:611.8408,y1:621.7144\n",
      "------------------\n",
      "59.1%\n",
      "x0:441.34,x1:473.43568\n",
      "y0:611.8408,y1:621.7144\n",
      "------------------\n",
      "93.9%\n",
      "x0:498.1,x1:530.19568\n",
      "y0:611.8408,y1:621.7144\n",
      "------------------\n",
      "82.0%\n",
      "x0:377.47,x1:409.56568\n",
      "y0:579.2908,y1:589.1644\n",
      "------------------\n",
      "77.7%\n",
      "x0:441.34,x1:473.43568\n",
      "y0:579.2908,y1:589.1644\n",
      "------------------\n",
      "97.4%\n",
      "x0:498.1,x1:530.19568\n",
      "y0:579.2908,y1:589.1644\n",
      "------------------\n",
      "\n",
      "x0:308.35,x1:311.28568\n",
      "y0:530.2108,y1:556.6444\n",
      "------------------\n",
      "全領域\n",
      "x0:441.34,x1:475.83567999999997\n",
      "y0:530.4508,y1:541.58104\n",
      "------------------\n",
      "提案 \n",
      "手法\n",
      "x0:498.1,x1:522.0356800000001\n",
      "y0:514.4907999999999,y1:541.58104\n",
      "------------------\n",
      "SIFT \n",
      "マ ッ チ ン グ\n",
      "(従来手法)\n",
      "x0:377.47,x1:430.55512000000004\n",
      "y0:498.5308,y1:540.0844\n",
      "------------------\n",
      "HOG \n",
      "評価\n",
      "x0:441.34,x1:469.35568\n",
      "y0:498.5308,y1:524.1243999999999\n",
      "------------------\n",
      "通常条件 \n",
      "(84  ピース) \n",
      "暗所条件 \n",
      "(75  ピース) \n",
      "強光条件 \n",
      "(53  ピース) \n",
      "計 \n",
      "(212  ピース)\n",
      "x0:308.35,x1:369.00568\n",
      "y0:367.4708,y1:492.14104\n",
      "------------------\n",
      "100.0%\n",
      "x0:377.47,x1:415.44568\n",
      "y0:480.7708,y1:490.64439999999996\n",
      "------------------\n",
      "98.9 %\n",
      "x0:441.34,x1:476.43568\n",
      "y0:480.7708,y1:490.64439999999996\n",
      "------------------\n",
      "100.0%\n",
      "x0:498.1,x1:536.07568\n",
      "y0:480.7708,y1:490.64439999999996\n",
      "------------------\n",
      "92.0%\n",
      "x0:377.47,x1:409.56568\n",
      "y0:448.2508,y1:458.1244\n",
      "------------------\n",
      "97.3%\n",
      "x0:441.34,x1:473.43568\n",
      "y0:448.2508,y1:458.1244\n",
      "------------------\n",
      "100.0%\n",
      "x0:498.1,x1:536.07568\n",
      "y0:448.2508,y1:458.1244\n",
      "------------------\n",
      "74.0%\n",
      "x0:377.47,x1:409.56568\n",
      "y0:415.7108,y1:425.58439999999996\n",
      "------------------\n",
      "74.0%\n",
      "x0:441.34,x1:473.43568\n",
      "y0:415.7108,y1:425.58439999999996\n",
      "------------------\n",
      "98.0%\n",
      "x0:498.1,x1:530.19568\n",
      "y0:415.7108,y1:425.58439999999996\n",
      "------------------\n",
      "91.0%\n",
      "x0:377.47,x1:409.56568\n",
      "y0:383.1908,y1:393.0644\n",
      "------------------\n",
      "92.5%\n",
      "x0:441.34,x1:473.43568\n",
      "y0:383.1908,y1:393.0644\n",
      "------------------\n",
      "99.5%\n",
      "x0:498.1,x1:530.19568\n",
      "y0:383.1908,y1:393.0644\n",
      "------------------\n",
      "\n",
      "x0:308.35,x1:311.28568\n",
      "y0:334.23080000000004,y1:360.6644\n",
      "------------------\n",
      "全領域\n",
      "x0:441.34,x1:475.83567999999997\n",
      "y0:334.4708,y1:345.60103999999995\n",
      "------------------\n",
      "提案 \n",
      "手法\n",
      "x0:498.1,x1:522.0356800000001\n",
      "y0:318.5108,y1:345.60103999999995\n",
      "------------------\n",
      "SIFT \n",
      "マ ッ チ ン グ\n",
      "(従来手法)\n",
      "x0:377.47,x1:430.55512000000004\n",
      "y0:302.43080000000003,y1:344.1044\n",
      "------------------\n",
      "HOG \n",
      "評価\n",
      "x0:441.34,x1:469.35568\n",
      "y0:302.43080000000003,y1:328.14439999999996\n",
      "------------------\n",
      "通常条件 \n",
      "(166  ピース) \n",
      "暗所条件 \n",
      "(174  ピース) \n",
      "強光条件 \n",
      "(105  ピース) \n",
      "計 \n",
      "(445  ピース)\n",
      "x0:308.35,x1:369.00568\n",
      "y0:171.4808,y1:296.16103999999996\n",
      "------------------\n",
      "97.0%\n",
      "x0:377.47,x1:409.56568\n",
      "y0:284.79080000000005,y1:294.6644\n",
      "------------------\n",
      "94.7%\n",
      "x0:441.34,x1:473.43568\n",
      "y0:284.79080000000005,y1:294.6644\n",
      "------------------\n",
      "100.0%\n",
      "x0:498.1,x1:536.07568\n",
      "y0:284.79080000000005,y1:294.6644\n",
      "------------------\n",
      "85.9%\n",
      "x0:377.47,x1:409.56568\n",
      "y0:252.2408,y1:262.1144\n",
      "------------------\n",
      "85.3%\n",
      "x0:441.34,x1:473.43568\n",
      "y0:252.2408,y1:262.1144\n",
      "------------------\n",
      "98.3%\n",
      "x0:498.1,x1:530.19568\n",
      "y0:252.2408,y1:262.1144\n",
      "------------------\n",
      "68.7%\n",
      "x0:377.47,x1:409.56568\n",
      "y0:219.7208,y1:229.5944\n",
      "------------------\n",
      "66.7%\n",
      "x0:441.34,x1:473.43568\n",
      "y0:219.7208,y1:229.5944\n",
      "------------------\n",
      "96.0%\n",
      "x0:498.1,x1:530.19568\n",
      "y0:219.7208,y1:229.5944\n",
      "------------------\n",
      "86.3%\n",
      "x0:377.47,x1:409.56568\n",
      "y0:187.2008,y1:197.0744\n",
      "------------------\n",
      "84.7%\n",
      "x0:441.34,x1:473.43568\n",
      "y0:187.2008,y1:197.0744\n",
      "------------------\n",
      "98.4%\n",
      "x0:498.1,x1:530.19568\n",
      "y0:187.2008,y1:197.0744\n",
      "------------------\n",
      "\n",
      "x0:318.91,x1:321.84568\n",
      "y0:154.6808,y1:164.55440000000002\n",
      "------------------\n",
      "識率が 86.3%であったのに対して，提案手法では\n",
      "98%以上となった．一方，鮮明度によらずに全領域\n",
      "を HOG 特徴で再評価した場合は誤認識をなくすた\n",
      "めにパラメータを厳しく設定する必要があり，その結\n",
      "x0:308.35,x1:538.7797599999999\n",
      "y0:91.51104,y1:150.09104000000002\n",
      "------------------\n",
      "果，従来手法よりも認識率が低下した．このこと\n",
      "x0:308.35,x1:538.90384\n",
      "y0:75.55104,y1:86.11104\n",
      "-------pages---------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      "IS1-20\n",
      "SO1-20\n",
      "x0:15.0,x1:69.36\n",
      "y0:810.2,y1:843.32\n",
      "------------------\n",
      "第25回画像センシングシンポジウム\n",
      "x0:297.5,x1:435.693\n",
      "y0:825.98,y1:836.248\n",
      "------------------\n",
      "\n",
      "x0:67.224,x1:70.15968000000001\n",
      "y0:786.9408,y1:796.8144\n",
      "------------------\n",
      "から，鮮明度に応じて再評価する領域を適切に選\n",
      "択する必要があると考えられる．\n",
      "x0:56.64,x1:287.18592\n",
      "y0:727.0408,y1:754.13104\n",
      "------------------\n",
      "\n",
      "x0:56.64,x1:59.57568\n",
      "y0:710.8408,y1:720.7144\n",
      "------------------\n",
      "6  まとめ\n",
      "x0:58.2,x1:127.22\n",
      "y0:685.828,y1:698.728\n",
      "------------------\n",
      "本研究では，種々の照明条件のもとでの対象物品認\n",
      "x0:56.64,x1:287.12255999999996\n",
      "y0:663.65104,y1:674.21104\n",
      "------------------\n",
      "識を可能とするために，画像の局所的な鮮明度合に\n",
      "x0:56.64,x1:286.77408\n",
      "y0:647.5710399999999,y1:658.13104\n",
      "------------------\n",
      "応じて模様の類似度評価に使用する特徴種類を適\n",
      "x0:56.64,x1:287.21\n",
      "y0:631.61104,y1:642.1710400000001\n",
      "------------------\n",
      "切に選択する認識アーキテクチャを開発した．提案\n",
      "x0:56.64,x1:287.09000000000003\n",
      "y0:615.65104,y1:626.21104\n",
      "------------------\n",
      "手法では，画像の局所領域ごとに使用する特徴種類\n",
      "x0:56.64,x1:287.02752000000004\n",
      "y0:599.5710399999999,y1:610.13104\n",
      "------------------\n",
      "を選択するため，影や照明の映り込みによって，局所\n",
      "x0:56.64,x1:287.0380800000001\n",
      "y0:583.58104,y1:594.1410400000001\n",
      "------------------\n",
      "的に照明条件が変化する場合においても，その領域\n",
      "x0:56.64,x1:286.9958400000001\n",
      "y0:567.62104,y1:578.18104\n",
      "------------------\n",
      "の類似度を評価するために有用な特徴種類を適切\n",
      "x0:56.64,x1:286.82687999999996\n",
      "y0:551.54104,y1:562.10104\n",
      "------------------\n",
      "に選択することができる．また，倉庫作業を模擬した\n",
      "x0:56.64,x1:287.10824\n",
      "y0:535.58104,y1:546.1410400000001\n",
      "------------------\n",
      "認識実験の結果から，提案手法によって，照明変動\n",
      "x0:56.64,x1:287.21000000000004\n",
      "y0:519.62104,y1:530.18104\n",
      "------------------\n",
      "が生じた場合に従来手法より高い認識率が得られる\n",
      "ことを確認した．\n",
      "x0:56.64,x1:286.97648000000004\n",
      "y0:487.0108,y1:514.10104\n",
      "------------------\n",
      "今後は，特徴種類の切替に使用する閾値などの\n",
      "x0:67.224,x1:286.872\n",
      "y0:471.62104,y1:482.18104\n",
      "------------------\n",
      "パラメータを自動調整する手法の検討を進める予定\n",
      "である．\n",
      "x0:56.64,x1:287.09000000000003\n",
      "y0:439.0108,y1:466.10103999999995\n",
      "------------------\n",
      "参\n",
      "x0:56.64,x1:68.64\n",
      "y0:398.678,y1:432.6644\n",
      "------------------\n",
      "考文献\n",
      "x0:68.64,x1:107.66\n",
      "y0:397.778,y1:410.678\n",
      "------------------\n",
      "[1]  J.   Tang,   S.  Miller,  A.  Singh,  and  P.\n",
      "x0:67.224,x1:289.8692\n",
      "y0:374.6324,y1:385.92104\n",
      "------------------\n",
      "Abbeel,  \"A  textured  object  recognition\n",
      "x0:88.224,x1:289.77216\n",
      "y0:358.7108,y1:368.58439999999996\n",
      "------------------\n",
      "pipeline for color and depth image data.\"\n",
      "x0:88.224,x1:289.76160000000004\n",
      "y0:342.7508,y1:352.6244\n",
      "------------------\n",
      "Robotics and Automation (ICRA), 2012\n",
      "x0:87.53766864,x1:292.3872595200001\n",
      "y0:326.79080000000005,y1:336.6644\n",
      "------------------\n",
      "IEEE International Conference on. IEEE,\n",
      "x0:87.53766864,x1:292.78664\n",
      "y0:310.7108,y1:320.58439999999996\n",
      "------------------\n",
      "2012.\n",
      "x0:88.224,x1:117.43568\n",
      "y0:294.7508,y1:304.6244\n",
      "------------------\n",
      "[2]  W.  Ren,  T.  Jiandong,  and  T.  Yandong,\n",
      "x0:67.224,x1:289.7616\n",
      "y0:278.6324,y1:288.6644\n",
      "------------------\n",
      "\"Specular  Reflection  Separation  With\n",
      "x0:88.224,x1:289.79328\n",
      "y0:262.7108,y1:272.58439999999996\n",
      "------------------\n",
      "Color-Lines\n",
      "x0:88.224,x1:147.38864\n",
      "y0:246.7208,y1:256.5944\n",
      "------------------\n",
      "Constraint.\"\n",
      "x0:172.43696,x1:235.01552\n",
      "y0:246.7208,y1:256.5944\n",
      "------------------\n",
      "IEEE\n",
      "x0:259.40366864,x1:292.51597952\n",
      "y0:246.7208,y1:256.5944\n",
      "------------------\n",
      "Transactions on Image Processing  26.5,\n",
      "x0:87.53766864,x1:289.90376\n",
      "y0:230.7608,y1:240.6344\n",
      "------------------\n",
      "2017.\n",
      "x0:88.224,x1:117.43568\n",
      "y0:214.6808,y1:224.55440000000002\n",
      "------------------\n",
      "[3]  D.  G.  Lowe,  \"Distinctive  image  features\n",
      "x0:67.224,x1:289.8038400000001\n",
      "y0:198.5624,y1:208.5944\n",
      "------------------\n",
      "from\n",
      "x0:88.224,x1:113.96928000000001\n",
      "y0:182.7608,y1:192.6344\n",
      "------------------\n",
      "scale-invariant\n",
      "x0:135.50112000000001,x1:211.36592\n",
      "y0:182.7608,y1:192.6344\n",
      "------------------\n",
      "keypoints.\"\n",
      "x0:232.89776,x1:289.82671999999997\n",
      "y0:182.7608,y1:192.6344\n",
      "------------------\n",
      "International journal of computer vision\n",
      "x0:87.53766864,x1:289.90568\n",
      "y0:166.6808,y1:176.55440000000002\n",
      "------------------\n",
      "60.2, 2004.\n",
      "x0:88.224,x1:143.71568\n",
      "y0:150.7208,y1:160.5944\n",
      "------------------\n",
      "[4]  N.  Dalal,  and  T.  Bill,  \"Histograms  of\n",
      "x0:67.224,x1:289.7193600000001\n",
      "y0:134.6024,y1:144.6344\n",
      "------------------\n",
      "oriented gradients for human detection.\"\n",
      "x0:88.224,x1:289.82496000000003\n",
      "y0:118.68079999999999,y1:128.5544\n",
      "------------------\n",
      "Computer  Vision  and  Pattern\n",
      "x0:87.53766864,x1:292.41893952\n",
      "y0:102.7208,y1:112.59440000000001\n",
      "------------------\n",
      "Recognition,  2005. CVPR 2005.  IEEE\n",
      "x0:87.53766864,x1:292.37669952000005\n",
      "y0:86.7408,y1:96.6144\n",
      "------------------\n",
      "Computer Society Conference on. Vol.  1.\n",
      "x0:87.53766864,x1:289.87976\n",
      "y0:70.6608,y1:80.5344\n",
      "------------------\n",
      "\n",
      "x0:67.224,x1:70.15968000000001\n",
      "y0:49.780800000000006,y1:59.6544\n",
      "------------------\n",
      "Copyright © SSII 2019. All Rights Reserved.\n",
      "x0:15.0,x1:187.99200000000005\n",
      "y0:3.98,y1:14.248\n",
      "------------------\n",
      "- IS1-20 -\n",
      "x0:278.92,x1:316.07349999999997\n",
      "y0:3.98,y1:14.248\n",
      "------------------\n",
      "IEEE, 2005.\n",
      "x0:339.91,x1:402.00568\n",
      "y0:742.7608,y1:752.6344\n",
      "------------------\n",
      "[5]  T.  Ojala,  M.  Pietikäinen,  and  D.\n",
      "x0:318.91,x1:541.47928\n",
      "y0:726.6424000000001,y1:736.6744\n",
      "------------------\n",
      "Harwood,  \"Performance  evaluation  of\n",
      "x0:339.91,x1:541.5186400000001\n",
      "y0:710.8408,y1:720.7144\n",
      "------------------\n",
      "texture  measures  with  classification\n",
      "x0:339.91,x1:541.4792800000001\n",
      "y0:694.7608,y1:704.6344\n",
      "------------------\n",
      "based  on  Kullback  discrimination  of\n",
      "x0:339.91,x1:541.4581600000001\n",
      "y0:678.8008,y1:688.6744\n",
      "------------------\n",
      "distributions\",  Proceedings of the 12th\n",
      "x0:339.91,x1:544.12317952\n",
      "y0:662.8408,y1:672.7144\n",
      "------------------\n",
      "IAPR  International  Conference  on\n",
      "x0:339.22366864,x1:544.06269952\n",
      "y0:646.7608,y1:656.6344\n",
      "------------------\n",
      "Pattern Recognition (ICPR), 1994.\n",
      "x0:339.22366864,x1:508.83567999999997\n",
      "y0:630.8008,y1:640.6744\n",
      "------------------\n",
      "[6]  M.  A.  Fischler,  and  C.  B.  Robert,\n",
      "x0:318.91,x1:546.5797600000001\n",
      "y0:614.6824,y1:624.7144\n",
      "------------------\n",
      "\"Random sample consensus: a paradigm\n",
      "x0:339.91,x1:541.55056\n",
      "y0:598.7608,y1:608.6344\n",
      "------------------\n",
      "for  model  fitting  with  applications  to\n",
      "x0:339.91,x1:541.4264800000001\n",
      "y0:582.7708,y1:592.6444\n",
      "------------------\n",
      "image\n",
      "x0:339.91,x1:372.35032\n",
      "y0:566.8108,y1:576.6844\n",
      "------------------\n",
      "analysis\n",
      "x0:388.9612,x1:431.9404\n",
      "y0:566.8108,y1:576.6844\n",
      "------------------\n",
      "and\n",
      "x0:448.58296000000007,x1:469.87192000000005\n",
      "y0:566.8108,y1:576.6844\n",
      "------------------\n",
      "automated\n",
      "x0:486.48280000000005,x1:541.4792800000001\n",
      "y0:566.8108,y1:576.6844\n",
      "------------------\n",
      "cartography.\"  Communications  of  the\n",
      "x0:339.91,x1:544.1222195200002\n",
      "y0:550.7307999999999,y1:560.6043999999999\n",
      "------------------\n",
      "ACM 24.6, 1981.\n",
      "x0:339.22366864,x1:423.36568\n",
      "y0:534.7708,y1:544.6444\n",
      "------------------\n",
      "[7]  M. M. Cheng, Z. Zhang, W. Y. Lin, and P.\n",
      "x0:318.91,x1:541.4293600000001\n",
      "y0:518.6524000000001,y1:528.6844\n",
      "------------------\n",
      "Torr,\n",
      "x0:339.91,x1:365.65528\n",
      "y0:502.73080000000004,y1:512.6044\n",
      "------------------\n",
      "\"BING:\n",
      "x0:381.31,x1:419.99128\n",
      "y0:502.73080000000004,y1:512.6044\n",
      "------------------\n",
      "Binarized\n",
      "x0:435.6412,x1:486.07576\n",
      "y0:502.73080000000004,y1:512.6044\n",
      "------------------\n",
      "normed\n",
      "x0:501.72568,x1:541.4946400000001\n",
      "y0:502.73080000000004,y1:512.6044\n",
      "------------------\n",
      "gradients  for  objectness  estimation  at\n",
      "x0:339.91,x1:541.5004000000001\n",
      "y0:486.7708,y1:496.64439999999996\n",
      "------------------\n",
      "300fps.\"  Proceedings  of  the  IEEE\n",
      "x0:339.91,x1:544.1366195200002\n",
      "y0:470.81080000000003,y1:480.6844\n",
      "------------------\n",
      "conference  on  computer  vision  and\n",
      "x0:339.22366864,x1:544.1049395200001\n",
      "y0:454.73080000000004,y1:464.6044\n",
      "------------------\n",
      "pattern recognition. 2014.\n",
      "x0:339.22366864,x1:468.51568\n",
      "y0:438.7708,y1:448.64439999999996\n",
      "------------------\n",
      "[8]  P. J. Besl, and N. D. McKay, \"Method for\n",
      "x0:318.91,x1:541.47928\n",
      "y0:422.6324,y1:432.6644\n",
      "------------------\n",
      "registration  of  3-D  shapes.\"  Sensor\n",
      "x0:339.91,x1:544.20405952\n",
      "y0:406.7108,y1:416.58439999999996\n",
      "------------------\n",
      "Fusion IV: Control Paradigms and Data\n",
      "x0:339.22366864,x1:544.0415795200001\n",
      "y0:390.7508,y1:400.6244\n",
      "------------------\n",
      "Structures.  Vol.  1611.\n",
      "x0:339.22366864,x1:464.73016\n",
      "y0:374.79080000000005,y1:384.6644\n",
      "------------------\n",
      "International\n",
      "x0:473.54776000000004,x1:541.4802400000001\n",
      "y0:374.79080000000005,y1:384.6644\n",
      "------------------\n",
      "Society for Optics and Photonics, 1992.\n",
      "x0:339.91,x1:531.6356800000001\n",
      "y0:358.7108,y1:368.58439999999996\n",
      "------------------\n",
      "[9]  B. Drost, M. Ulrich, N. Navab, and S. Ilic,\n",
      "x0:318.91,x1:544.3727200000001\n",
      "y0:342.5924,y1:352.6244\n",
      "------------------\n",
      "\"Model  globally,  match  locally:  Efficient\n",
      "x0:339.91,x1:541.4687200000001\n",
      "y0:326.79080000000005,y1:336.6644\n",
      "------------------\n",
      "and  robust  3D  object  recognition.\"\n",
      "x0:339.91,x1:541.52152\n",
      "y0:310.7108,y1:320.58439999999996\n",
      "------------------\n",
      "Computer  Vision  and  Pattern\n",
      "x0:339.22366864,x1:544.1049395200001\n",
      "y0:294.7508,y1:304.6244\n",
      "------------------\n",
      "Recognition  (CVPR),  2010  IEEE\n",
      "x0:339.22366864,x1:544.0838195200002\n",
      "y0:278.79080000000005,y1:288.6644\n",
      "------------------\n",
      "Conference on. Ieee, 2010.\n",
      "x0:339.22366864,x1:469.71567999999996\n",
      "y0:262.7108,y1:272.58439999999996\n",
      "-------pages---------\n"
     ]
    }
   ],
   "source": [
    "with open(file_path, \"rb\") as f:\n",
    "    for page in PDFPage.get_pages(f):\n",
    "        interpreter.process_page(page)  # ページを処理する。\n",
    "        layout = device.get_result()  # LTPageオブジェクトを取得。\n",
    "        text_boxes = find_textboxes_recursively(layout)      \n",
    "\n",
    "        # text_boxの座標値毎にソート，複数キーのソート\n",
    "        #text_boxes.sort(key=lambda text_box: (-text_box.y1, text_box.x0))  # y1がy座標，x0がx座標らしい(画像座標なので，y1を負に)\n",
    "        #text_boxes.sort(key=lambda text_box: (text_box.x0, -text_box.y1)) # 正直二段組のデータでの取得は難しく，ある程度1段踏み前提\n",
    "        \n",
    "        # 二段組のソート\n",
    "        sort2column = Sort2Column(layout_x0=layout.x0, layout_x1=layout.x1)\n",
    "        text_boxes.sort(key=sort2column)\n",
    "        for box in text_boxes:\n",
    "            print(\"------------------\")\n",
    "            print(box.get_text().strip())  # 末尾の文字を削除\n",
    "            print(\"x0:{},x1:{}\".format(box.x0, box.x1))\n",
    "            print(\"y0:{},y1:{}\".format(box.y0, box.y1))\n",
    "            \n",
    "        print(\"-------pages---------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### documentオブジェクトを利用する場合 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdf_py37",
   "language": "python",
   "name": "pdf_py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
